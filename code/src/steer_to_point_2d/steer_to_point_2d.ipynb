{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96751412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1m┌ \u001B[22m\u001B[39m\u001B[36m\u001B[1mInfo: \u001B[22m\u001B[39mMeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "\u001B[36m\u001B[1m└ \u001B[22m\u001B[39mhttp://127.0.0.1:8701\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Init Bionic VTOL\n",
    "\n",
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position\n",
    "\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;\n",
    "using Distributions;\n",
    "\n",
    "using Plots;\n",
    "using Statistics;\n",
    "\n",
    "using BSON: @save, @load # save mode\n",
    "\n",
    "create_visualization();\n",
    "\n",
    "# indicates how many threads Julia was started with. This is important for the multi-threaded environment\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96af6ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2-element Vector{Vector{Float64}}:\n [35.0, 0.0, 20.0]\n [-7.0, 0.0, 4.0]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create Reinforcement Learning Environment\n",
    "\n",
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv # Parametric Constructor for a subtype of AbstractEnv\n",
    "    action_space::A # action space\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}} # observation space\n",
    "    state::Vector{T} # current state space\n",
    "    action::ACT # action space\n",
    "    done::Bool # done\n",
    "    t::T # time\n",
    "    rng::R # random number generator\n",
    "\n",
    "    name::String # for multible environments\n",
    "    visualization::Bool # visualization\n",
    "    realtime::Bool # realtime\n",
    "\n",
    "    x_previous::Vector{T} # previous position\n",
    "    x_W::Vector{T} # current position\n",
    "    v_B::Vector{T} # velocity\n",
    "    R_W::Matrix{T} # current rotation\n",
    "    ω_B::Vector{T} # rotation velocitiy\n",
    "    wind_W::Vector{T} # wind\n",
    "    Δt::T # simulation time step\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Extend the environment here.\n",
    "    # Everything you need additionaly in your environment also go in here.\n",
    "    # E.g. a trajectory\n",
    "\n",
    "    waypoints::Vector{Vector{T}} # waypoints\n",
    "    proximity_tolerance::T # proximity tolerance\n",
    "    max_v::T # maximum allowed velocity\n",
    "\n",
    "    ######################################################################\n",
    "end\n",
    "\n",
    "################################ TODO ################################\n",
    "# You can initialization global constants here.\n",
    "# E.g. a fixed point in the beginning of training (for testing/overfitting)\n",
    "# Define global constants for initial position and rotation\n",
    "const INITIAL_POSITION = [0.0, 0.0, 0.0];\n",
    "const INITIAL_ROTATION = [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0];\n",
    "const SAMPLE_WAYPOINTS = [[35.0, 0.0, 20.0], [-7.0, 0.0, 4.0]]\n",
    "######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a6873d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "# 2 methods for type constructor:\n[1] VtolEnv(; rng, name, visualization, realtime, kwargs...) in Main at In[3]:3\n[2] VtolEnv(action_space::A, observation_space::Space{Array{ClosedInterval{T}, 1}}, state::Vector{T}, action::ACT, done::Bool, t::T, rng::R, name::String, visualization::Bool, realtime::Bool, x_previous::Vector{T}, x_W::Vector{T}, v_B::Vector{T}, R_W::Matrix{T}, ω_B::Vector{T}, wind_W::Vector{T}, Δt::T, waypoints::Array{Vector{T}, 1}, proximity_tolerance::T, max_v::T) where {A, T, ACT, R<:AbstractRNG} in Main at In[2]:4",
      "text/html": "# 2 methods for type constructor:<ul><li> VtolEnv(; <i>rng, name, visualization, realtime, kwargs...</i>) in Main at In[3]:3</li> <li> VtolEnv(action_space::<b>A</b>, observation_space::<b>Space{Array{ClosedInterval{T}, 1}}</b>, state::<b>Vector{T}</b>, action::<b>ACT</b>, done::<b>Bool</b>, t::<b>T</b>, rng::<b>R</b>, name::<b>String</b>, visualization::<b>Bool</b>, realtime::<b>Bool</b>, x_previous::<b>Vector{T}</b>, x_W::<b>Vector{T}</b>, v_B::<b>Vector{T}</b>, R_W::<b>Matrix{T}</b>, ω_B::<b>Vector{T}</b>, wind_W::<b>Vector{T}</b>, Δt::<b>T</b>, waypoints::<b>Array{Vector{T}, 1}</b>, proximity_tolerance::<b>T</b>, max_v::<b>T</b>)<i> where {A, T, ACT, R<:AbstractRNG}</i> in Main at In[2]:4</li> </ul>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a keyword-based constructor for the type declared in the mutable struct typedef.\n",
    "# It could also be done with the macro Base.@kwdef.\n",
    "function VtolEnv(;\n",
    "    rng = Random.GLOBAL_RNG, # random number generation\n",
    "    name = \"vtol\",\n",
    "    visualization = false,\n",
    "    realtime = false,\n",
    "    kwargs...) # let the function take an arbitrary number of keyword arguments\n",
    "    \n",
    "    T = Float64; # explicit type which is used e.g. in state. Cannot be altered due to the poor matrix defininon.\n",
    "    A = Space{Vector{ClosedInterval{T}}};\n",
    "\n",
    "    action_space = Space(\n",
    "        ClosedInterval{T}[\n",
    "            0.0..2.0, # propeller 1\n",
    "            0.0..2.0, # propeller 2\n",
    "            ],\n",
    "    ) # propeller 1 and 2\n",
    "    \n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            ################################ TODO ################################\n",
    "            # Implement an observation space. \n",
    "            # Here is an example space. You can change it if desired.\n",
    "            # You have to extend it.\n",
    "            # Orientate yourself on the observation space from the paper.\n",
    "            \n",
    "            typemin(T)..typemax(T), # previous position along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), # previous position along z WORLD coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), # current position along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), # current position along z WORLD coordinates\n",
    "            \n",
    "            typemin(T)..typemax(T), # orientation along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), # orientation along z WORLD coordinates\n",
    "            \n",
    "            typemin(T)..typemax(T), # velocity along x BODY coordinates\n",
    "            typemin(T)..typemax(T), # velocity along z BODY coordinates\n",
    "            \n",
    "            typemin(T)..typemax(T), # rotational velocity along z BODY coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), # position of target along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), # position of target along y WORLD coordinates\n",
    "\n",
    "            ######################################################################\n",
    "            ], \n",
    "    )\n",
    "    \n",
    "    if visualization #visualizes VTOL\n",
    "        create_VTOL(name, actuators = true, color_vec=[1.0; 1.0; 0.6; 1.0]);\n",
    "    end\n",
    "\n",
    "    environment = VtolEnv(\n",
    "        action_space, # action space\n",
    "        state_space, # observation space\n",
    "        zeros(T, length(state_space)), # current state space\n",
    "        rand(action_space), # initialization action\n",
    "        false, # episode done \n",
    "        0.0, # time\n",
    "        rng, # random number generator  \n",
    "        \n",
    "        name,\n",
    "        visualization,\n",
    "        realtime,\n",
    "        \n",
    "        zeros(T, 3), # x_previous, previous position\n",
    "        zeros(T, 3), # x_W, current position\n",
    "        zeros(T, 3), # v_B, velocity\n",
    "        [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0], # R_W, current rotation, Float64... so T needs to be Float64\n",
    "        zeros(T, 3), # ω_B\n",
    "        zeros(T, 3), # wind_W\n",
    "        T(0.025), # simulation time step\n",
    "\n",
    "        ################################## TODO ##################################\n",
    "        # Initialization everything you need additionaly in your environment here.\n",
    "        SAMPLE_WAYPOINTS,\n",
    "        1e-5, # proximity tolerance\n",
    "        100.0, # maximum allowed velocity\n",
    "        \n",
    "        ##########################################################################\n",
    "    )\n",
    "\n",
    "    reset!(environment)\n",
    "    return environment\n",
    "end;\n",
    "\n",
    "methods(VtolEnv)\n",
    "\n",
    "\n",
    "# Just for explanation:\n",
    "# 1. A mutable Struct is created. A struct is a constructor and a constructor is a function that creates new objects.\n",
    "# 2. A outer keyword-based constructor method is added for the type declared in the mutable struct typedef before.'\n",
    "# So now we have a function with two methods. Julia will decide which method to call by multiple dispatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f7fb89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the RL interface\n",
    "\n",
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state\n",
    "\n",
    "global k_p = 5.0;\n",
    "global k_w = 0.01;\n",
    "global k_wp = 5.0;\n",
    "function computeReward(env::VtolEnv{A,T}) where {A,T}\n",
    "    reward = 0.0\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Implement the reward function.\n",
    "    # Orientate on the paper.\n",
    "    gates = env.waypoints;\n",
    "    n = length(gates);\n",
    "\n",
    "    function compute_distance(position::Vector{T})\n",
    "        l_min_index, phi_l = calculate_progress(gates, position);\n",
    "        reached_distance = 0.0;\n",
    "        for i in 1:(l_min_index-1)\n",
    "            reached_distance += (norm(gates[i+1] - gates[i]) + norm(phi_l - gates[l]));\n",
    "        end\n",
    "        return reached_distance;\n",
    "    end\n",
    "    s_pt1 = compute_distance(env.x_previous);\n",
    "    s_pt = compute_distance(env.x_W);\n",
    "    r_pt = s_pt - s_pt1;\n",
    "\n",
    "    function compute_ks()\n",
    "        factor = 2 * env.Δt * env.max_v;\n",
    "        sum = 0.0;\n",
    "        for i in 1:(n-1)\n",
    "            sum += norm(gates[i+1] - gates[i]);\n",
    "        end\n",
    "        return factor / sum;\n",
    "    end\n",
    "    k_s = compute_ks();\n",
    "\n",
    "    r_t = 0; # no obstacles\n",
    "    r_wp = 0 # for now no additional waypoints\n",
    "    w = norm(env.ω_B);\n",
    "\n",
    "    reward = k_p * r_pt + k_s * s_pt + k_wp * r_wp + r_t - k_w * w;\n",
    "    ################################################################################################\n",
    "\n",
    "    return reward\n",
    "end\n",
    "\n",
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = computeReward(env)\n",
    "\n",
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    # Visualize initial state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, [0.0; 0.0; 0.0; 0.0]);\n",
    "    end\n",
    "\n",
    "    env.x_W = [0.0; 0.0; 0.0];\n",
    "    env.v_B = [0.0; 0.0; 0.0];\n",
    "    env.R_W = Matrix(UnitQuaternion(RotZ(-pi/2.0)*RotY(-pi/2.0)*RotX(pi)));\n",
    "\n",
    "    env.ω_B = [0.0; 0.0; 0.0];\n",
    "    env.wind_W = [0.0; 0.0; 0.0];\n",
    "\n",
    "    env.t = 0.0;\n",
    "    env.action = [0.0, 0.0];\n",
    "    env.done = false;\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Reset environment.\n",
    "    # Is called if the training terminates\n",
    "    # (e.g. if drone crashes or successfully reaches point)\n",
    "    # HINT: Everything you added to your environment needs to be reseted.\n",
    "    #       Compare it with the initialization.\n",
    "\n",
    "    env.x_previous = [0.0; 0.0; 0.0]; # starting position\n",
    "    env.Δt = T(0.025); # Δ time\n",
    "\n",
    "    env.waypoints = generate_trajectory(2);\n",
    "    env.proximity_tolerance = 1e-5;\n",
    "    ######################################################################\n",
    "\n",
    "    nothing\n",
    "end;\n",
    "\n",
    "# defines a methods for a callable object.\n",
    "# So when a VtolEnv object is created, it has this method that can be called\n",
    "function (env::VtolEnv)(a)\n",
    "    # set the propeller trust and the two flaps 2D case\n",
    "    # flaps set to 0.0\n",
    "    next_action = [a[1], a[2], 0.0, 0.0]\n",
    "\n",
    "    _step!(env, next_action)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e9eb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "# 3 methods for callable object:\n[1] (env::VtolEnv)(a) in Main at In[4]:92\n[2] (env::AbstractEnv)(action) in ReinforcementLearningBase\n[3] (env::AbstractEnv)(action, player) in ReinforcementLearningBase",
      "text/html": "# 3 methods for callable object:<ul><li> (env::<b>VtolEnv</b>)(a) in Main at In[4]:92</li> <li> (env::<b>AbstractEnv</b>)(action) in ReinforcementLearningBase</li> <li> (env::<b>AbstractEnv</b>)(action, player) in ReinforcementLearningBase</li> </ul>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = VtolEnv();\n",
    "methods(env) # Just to explain which methods the object has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7d4727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[1mTest Summary:              | \u001B[22m\u001B[32m\u001B[1mPass  \u001B[22m\u001B[39m\u001B[36m\u001B[1mTotal  \u001B[22m\u001B[39m\u001B[0m\u001B[1mTime\u001B[22m\n",
      "random policy with VtolEnv | \u001B[32m2000  \u001B[39m\u001B[36m 2000  \u001B[39m\u001B[0m1.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": "Test.DefaultTestSet(\"random policy with VtolEnv\", Any[], 2000, false, false, true, 1.674726897430627e9, 1.674726898503099e9)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function _step!(env::VtolEnv, next_action)\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Implement step.\n",
    "    # HINT: This is relatet to your environment.\n",
    "    #       Compare to struct VtolEnv.\n",
    "    #       How does it change in every step.\n",
    "\n",
    "    env.state[1] = env.state[3]; # update previous x-coordinate\n",
    "    env.state[2] = env.state[4]; # update previous z-coordinate\n",
    "    env.x_previous = env.x_W;\n",
    "\n",
    "    ######################################################################\n",
    "\n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(env.v_B, env.R_W, env.wind_W);\n",
    "\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = vtol_model(v_in_wind_B, next_action, eth_vtol_param);\n",
    "\n",
    "    # Limit to 2D\n",
    "    force_B[3] = 0.0; # Body Z\n",
    "    env.v_B[3] = 0.0;\n",
    "    torque_B[1] = 0.0;\n",
    "    torque_B[2] = 0.0;  # Body X and Y\n",
    "    env.ω_B[1] = 0.0;\n",
    "    env.ω_B[2] = 0.0;\n",
    "\n",
    "    # integrate rigid body dynamics for Δt\n",
    "    env.x_W, env.v_B, env.R_W, env.ω_B, time = rigid_body_simple(torque_B, force_B, env.x_W, env.v_B, env.R_W, env.ω_B, env.t, env.Δt, eth_vtol_param);\n",
    "\n",
    "    if env.realtime\n",
    "        sleep(env.Δt); # just a dirty hack. this is of course slower than real time.\n",
    "    end\n",
    "\n",
    "    # Visualize the new state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, next_action);\n",
    "    end\n",
    "\n",
    "    env.t += env.Δt\n",
    "\n",
    "    env.state[3] = env.x_W[1]; # position along x\n",
    "    env.state[4] = env.x_W[3]; # position along z\n",
    "\n",
    "    env.state[5] = env.R_W[1,1]; # orientation along x\n",
    "    env.state[6] = env.R_W[3,1]; # orientation along z\n",
    "\n",
    "    env.state[7] = env.v_B[1]; # velocity along x BODY coordinates\n",
    "    env.state[8] = env.v_B[2]; # velocity along y BODY coordinates\n",
    "\n",
    "    env.state[9] = env.ω_B[3];  # rotational velocity along z BODY coordinates\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Implement step.\n",
    "    # HINT: This is relatet to your environment.\n",
    "    #       Compare to struct VtolEnv.\n",
    "    #       How does it change in every step.\n",
    "\n",
    "    env.state[10] = env.waypoints[1][1] - env.x_W[1] # position of target along x WORLD coordinates\n",
    "    env.state[11] = env.waypoints[1][3] - env.x_W[3] # position of target along z WORLD coordinates\n",
    "    ######################################################################\n",
    "\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Add termination criterias.\n",
    "    # Use many termination criteria so that you do not train unnecessarily in wrong areas.\n",
    "    env.done =\n",
    "        norm(env.ω_B) > 100.0 || # stop if body rate is too high\n",
    "        norm(env.v_B) > env.max_v || # stop if body is too fast\n",
    "        norm(env.waypoints[1] - env.x_W) < env.proximity_tolerance# target reached\n",
    "    ######################################################################\n",
    "\n",
    "    nothing\n",
    "end;\n",
    "\n",
    "RLBase.test_runnable!(env)\n",
    "\n",
    "# changed to 10s (5s before) per point and 5.0m too far off path (2.0 before)\n",
    "# Show an overview of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5683fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1m┌ \u001B[22m\u001B[39m\u001B[36m\u001B[1mInfo: \u001B[22m\u001B[39mThe GPU function is being called but the GPU is not accessible. \n",
      "\u001B[36m\u001B[1m└ \u001B[22m\u001B[39mDefaulting back to the CPU. (No action is required if you want to run on the CPU).\n"
     ]
    }
   ],
   "source": [
    "## Setup of a reinforcement learning experiment.\n",
    "\n",
    "seed = 123\n",
    "rng = StableRNG(seed)\n",
    "    N_ENV = 8\n",
    "    UPDATE_FREQ = 1024\n",
    "\n",
    "    vtol_envs = [\n",
    "        # use different names for the visualization\n",
    "        VtolEnv(; rng = StableRNG(hash(seed+i)), name = \"vtol$i\") for i in 1:N_ENV\n",
    "    ];\n",
    "    # define multiple environments for parallel training\n",
    "    env = MultiThreadEnv(vtol_envs)\n",
    "\n",
    "    # Define the function approximator\n",
    "    # (optional) TODO: change architecture\n",
    "    # TODO: research briefly what Actor Critic is\n",
    "    # (optional) TODO: change optimizer\n",
    "    # TODO: research what ADAM is\n",
    "    ns, na = length(state(env[1])), length(action_space(env[1]))\n",
    "    approximator = ActorCritic(\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                    Dense(ns, 16, tanh; initW = glorot_uniform(rng)),#\n",
    "                    Dense(16, 16, tanh; initW = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(Dense(16, na; initW = glorot_uniform(rng))),\n",
    "                    logσ = Chain(Dense(16, na; initW = glorot_uniform(rng))),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 16, tanh; initW = glorot_uniform(rng)),\n",
    "                    Dense(16, 16, tanh; initW = glorot_uniform(rng)),\n",
    "                    Dense(16, 1; initW = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(1e-3),\n",
    "            );\n",
    "\n",
    "        agent = Agent( # A wrapper of an AbstractPolicy\n",
    "        # AbstractPolicy: the policy to use\n",
    "        # (optional) TODO: change eventually\n",
    "        # TODO: research briefly what PPO is\n",
    "        policy = PPOPolicy(;\n",
    "                    approximator = approximator |> gpu,\n",
    "                    update_freq=UPDATE_FREQ,\n",
    "                    dist = Normal,\n",
    "                    # For parameters visit the docu: https://juliareinforcementlearning.org/docs/rlzoo/#ReinforcementLearningZoo.PPOPolicy\n",
    "                    ),\n",
    "\n",
    "        # AbstractTrajectory: used to store transitions between an agent and an environment source\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float64} => (ns, N_ENV),\n",
    "            action = Matrix{Float64} => (na, N_ENV),\n",
    "            action_log_prob = Vector{Float64} => (N_ENV,),\n",
    "            reward = Vector{Float64} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f158a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "function saveModel(t, agent, env)\n",
    "    model = cpu(agent.policy.approximator)   \n",
    "    f = joinpath(\"./RL_models/\", \"vtol_2D_ppo_$t.bson\") # TODO: save model here\n",
    "    @save f model\n",
    "    println(\"parameters at step $t saved to $f\")\n",
    "end;\n",
    "\n",
    "function loadModel()\n",
    "    f = joinpath(\"./RL_models/\", \"vtol_2D_ppo_1500000.bson\") # TODO: load model here\n",
    "    @load f model\n",
    "    return model\n",
    "end;\n",
    "\n",
    "function validate_policy(t, agent, env)\n",
    "    run(agent.policy, test_env, StopAfterEpisode(1), episode_test_reward_hook)\n",
    "    # the result of the hook\n",
    "    println(\"test reward at step $t: $(episode_test_reward_hook.rewards[end])\")\n",
    "\n",
    "end;\n",
    "\n",
    "episode_test_reward_hook = TotalRewardPerEpisode(;is_display_on_exit=false)\n",
    "# create a env only for reward test\n",
    "test_env = VtolEnv(;name = \"testVTOL\", visualization = true, realtime = true);\n",
    "\n",
    "# agent.policy.approximator = loadModel();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb737010",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   0%|                                         |  ETA: 11:55:50\u001B[39m9m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 10000: -50.27478665362884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   1%|▌                                        |  ETA: 0:53:54\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 20000: -45.72909637124421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   2%|▊                                        |  ETA: 0:36:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 30000: -42.665619303186496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   3%|█▏                                       |  ETA: 0:31:25\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 40000: -45.324463221226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   3%|█▎                                       |  ETA: 0:27:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 50000: -41.97500529008495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   4%|█▋                                       |  ETA: 0:24:22\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 60000: -46.571899335792686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   5%|█▉                                       |  ETA: 0:22:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 70000: -52.70711554473564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   5%|██                                       |  ETA: 0:22:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 80000: -45.54430806780489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   6%|██▍                                      |  ETA: 0:21:18\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 90000: -51.3644877061217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   6%|██▋                                      |  ETA: 0:22:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 100000 saved to ./RL_models/vtol_2D_ppo_100000.bson\n",
      "test reward at step 100000: -59.15290286351076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   7%|██▉                                      |  ETA: 0:21:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 110000: -48.761153947328275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   8%|███▏                                     |  ETA: 0:21:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 120000: -41.61552775071217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   9%|███▌                                     |  ETA: 0:20:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 130000: -48.38351695796337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   9%|███▉                                     |  ETA: 0:20:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 140000: -40.76593698681828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  10%|████                                     |  ETA: 0:20:05\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 150000: -56.355446545898474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  11%|████▍                                    |  ETA: 0:19:45\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 160000: -45.58778709711167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  11%|████▌                                    |  ETA: 0:19:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 170000: -36.90304340299312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  12%|████▉                                    |  ETA: 0:19:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 180000: -41.112838029595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  13%|█████▏                                   |  ETA: 0:18:40\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 190000: -49.14753902228853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  13%|█████▍                                   |  ETA: 0:18:45\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 200000 saved to ./RL_models/vtol_2D_ppo_200000.bson\n",
      "test reward at step 200000: -42.71605412576071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  14%|█████▋                                   |  ETA: 0:18:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 210000: -63.89094306647099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  15%|██████                                   |  ETA: 0:18:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 220000: -56.91880722666081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  15%|██████▎                                  |  ETA: 0:18:32\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 230000: -41.52158019000579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  16%|██████▌                                  |  ETA: 0:18:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 240000: -39.544196642336765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  16%|██████▊                                  |  ETA: 0:17:43\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 250000: -54.28467371255836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  17%|███████▏                                 |  ETA: 0:17:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 260000: -41.32903292994354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  18%|███████▎                                 |  ETA: 0:17:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 270000: -37.76508589776515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  18%|███████▋                                 |  ETA: 0:17:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 280000: -54.26100098313122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  19%|███████▉                                 |  ETA: 0:16:50\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 290000: -66.57751739262602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  20%|████████                                 |  ETA: 0:16:58\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 300000 saved to ./RL_models/vtol_2D_ppo_300000.bson\n",
      "test reward at step 300000: -38.96873069231807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  20%|████████▍                                |  ETA: 0:16:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 310000: -64.37266374932545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  21%|████████▊                                |  ETA: 0:16:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 320000: -37.39950839480728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  22%|█████████                                |  ETA: 0:16:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 330000: -63.60065383975396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  22%|█████████▏                               |  ETA: 0:16:22\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 340000: -53.31580251582374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  23%|█████████▌                               |  ETA: 0:16:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 350000: -43.04387729097994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  24%|█████████▊                               |  ETA: 0:16:05\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 360000: -57.795397070401464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  25%|██████████▏                              |  ETA: 0:16:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 370000: -45.89490817529486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  25%|██████████▎                              |  ETA: 0:16:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 380000: -40.51217953277088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  26%|██████████▋                              |  ETA: 0:15:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 390000: -60.732307905191234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  26%|██████████▊                              |  ETA: 0:15:50\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 400000 saved to ./RL_models/vtol_2D_ppo_400000.bson\n",
      "test reward at step 400000: -50.7151441235099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  27%|███████████▏                             |  ETA: 0:15:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 410000: -58.55582824309753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  28%|███████████▌                             |  ETA: 0:15:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 420000: -36.70584901348142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  28%|███████████▋                             |  ETA: 0:15:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 430000: -40.61745119610154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  29%|████████████                             |  ETA: 0:15:13\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 440000: -44.37809624066083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  30%|████████████▎                            |  ETA: 0:14:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 450000: -66.14595980485464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  30%|████████████▍                            |  ETA: 0:15:10\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 460000: -38.78766731239758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  31%|████████████▉                            |  ETA: 0:14:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 470000: -57.58311538278573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  32%|█████████████                            |  ETA: 0:14:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 480000: -55.15131824802601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  33%|█████████████▍                           |  ETA: 0:14:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 490000: -57.75341169978245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  33%|█████████████▌                           |  ETA: 0:14:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 500000 saved to ./RL_models/vtol_2D_ppo_500000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  33%|█████████████▋                           |  ETA: 0:14:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 500000: -60.0951303405528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  34%|█████████████▉                           |  ETA: 0:14:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 510000: -56.2677253627292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  35%|██████████████▏                          |  ETA: 0:14:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 520000: -41.0265217219385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  35%|██████████████▍                          |  ETA: 0:14:22\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 530000: -41.777192861443595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  36%|██████████████▋                          |  ETA: 0:14:07\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 540000: -66.5650756085995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  37%|███████████████                          |  ETA: 0:13:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 550000: -54.72979030498178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  37%|███████████████▏                         |  ETA: 0:14:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 560000: -75.27466136806423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  38%|███████████████▌                         |  ETA: 0:13:55\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 570000: -94.41412869532019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  39%|███████████████▊                         |  ETA: 0:13:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 580000: -54.14733902521274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  39%|████████████████▏                        |  ETA: 0:13:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 590000: -80.16495435297732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  40%|████████████████▎                        |  ETA: 0:13:45\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 600000 saved to ./RL_models/vtol_2D_ppo_600000.bson\n",
      "test reward at step 600000: -73.51555059872143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  41%|████████████████▋                        |  ETA: 0:13:35\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 610000: -55.96550795290538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  41%|█████████████████                        |  ETA: 0:13:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 620000: -75.19042561331905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  42%|█████████████████▏                       |  ETA: 0:13:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 630000: -69.23088040663544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  43%|█████████████████▌                       |  ETA: 0:13:27\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 640000: -46.40646122923053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  43%|█████████████████▋                       |  ETA: 0:13:32\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 650000: -95.39180839155037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  44%|██████████████████                       |  ETA: 0:13:22\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 660000: -77.67538814294701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  45%|██████████████████▎                      |  ETA: 0:13:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 670000: -67.61109480301322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  45%|██████████████████▍                      |  ETA: 0:13:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 680000: -46.35516156127385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  46%|██████████████████▊                      |  ETA: 0:13:10\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 690000: -28.215517037657925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  47%|███████████████████▏                     |  ETA: 0:13:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 700000 saved to ./RL_models/vtol_2D_ppo_700000.bson\n",
      "test reward at step 700000: -53.96223963609493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  47%|███████████████████▍                     |  ETA: 0:13:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 710000: -20.763710341821984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  48%|███████████████████▋                     |  ETA: 0:12:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 720000: -49.329069756494334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  49%|███████████████████▉                     |  ETA: 0:12:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 730000: -148.64558851873298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  49%|████████████████████▏                    |  ETA: 0:12:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 740000: -24.64295813917705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  50%|████████████████████▍                    |  ETA: 0:12:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 750000: -16.613504858003836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  51%|████████████████████▊                    |  ETA: 0:12:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 760000: -34.68768157184957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  51%|████████████████████▉                    |  ETA: 0:12:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 770000: -127.672064188686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  52%|█████████████████████▎                   |  ETA: 0:12:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 780000: -25.37627783808094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  53%|█████████████████████▋                   |  ETA: 0:12:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 790000: -36.29644015498255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  53%|█████████████████████▊                   |  ETA: 0:12:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 800000 saved to ./RL_models/vtol_2D_ppo_800000.bson\n",
      "test reward at step 800000: -78.35944133541152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  54%|██████████████████████▏                  |  ETA: 0:12:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 810000: -97.21283068303984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  55%|██████████████████████▍                  |  ETA: 0:11:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 820000: -101.4099173126895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  55%|██████████████████████▌                  |  ETA: 0:11:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 830000: -100.86908503035167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  56%|██████████████████████▉                  |  ETA: 0:11:50\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 840000: -142.95694600464066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  57%|███████████████████████▎                 |  ETA: 0:11:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 850000: -62.36601245671032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  57%|███████████████████████▍                 |  ETA: 0:11:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 860000: -40.17638402378117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  58%|███████████████████████▋                 |  ETA: 0:11:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 870000: -36.3876457929037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  59%|████████████████████████                 |  ETA: 0:11:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 880000: -40.48054513439533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  59%|████████████████████████▎                |  ETA: 0:11:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 890000: -30.909801536633925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  60%|████████████████████████▌                |  ETA: 0:11:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 900000 saved to ./RL_models/vtol_2D_ppo_900000.bson\n",
      "test reward at step 900000: -41.95236418398319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  61%|████████████████████████▉                |  ETA: 0:11:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 910000: -32.8007289776613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  61%|█████████████████████████▏               |  ETA: 0:10:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 920000: -31.921678903256126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  62%|█████████████████████████▎               |  ETA: 0:10:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 930000: -24.6534601628189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  62%|█████████████████████████▋               |  ETA: 0:10:43\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 940000: -33.319661752552626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  63%|█████████████████████████▉               |  ETA: 0:10:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 950000: -37.73264745618545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  64%|██████████████████████████▎              |  ETA: 0:10:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 960000: -50.24704789818437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  65%|██████████████████████████▌              |  ETA: 0:10:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 970000: -144.46489242179524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  65%|██████████████████████████▋              |  ETA: 0:10:10\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 980000: -62.3105549810656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  66%|███████████████████████████              |  ETA: 0:09:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 990000: -43.8124426081122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  66%|███████████████████████████▎             |  ETA: 0:09:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1000000 saved to ./RL_models/vtol_2D_ppo_1000000.bson\n",
      "test reward at step 1000000: -36.423195552701024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  67%|███████████████████████████▌             |  ETA: 0:09:40\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1010000: -38.98372542105567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  68%|███████████████████████████▉             |  ETA: 0:09:27\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1020000: -53.79793434140324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  68%|████████████████████████████             |  ETA: 0:09:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1030000: -50.746734782654414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  69%|████████████████████████████▍            |  ETA: 0:09:13\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1040000: -93.50829640031576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  70%|████████████████████████████▋            |  ETA: 0:09:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1050000: -41.991210404796185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  70%|████████████████████████████▉            |  ETA: 0:08:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1060000: -41.6485728004321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  71%|█████████████████████████████▏           |  ETA: 0:08:43\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1070000: -75.26139416914073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  72%|█████████████████████████████▌           |  ETA: 0:08:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1080000: -60.664045963256406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  72%|█████████████████████████████▋           |  ETA: 0:08:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1090000: -27.255111972282343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  73%|██████████████████████████████           |  ETA: 0:08:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1100000 saved to ./RL_models/vtol_2D_ppo_1100000.bson\n",
      "test reward at step 1100000: -10.88137253665415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  74%|██████████████████████████████▍          |  ETA: 0:07:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1110000: -30.079675434089506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  74%|██████████████████████████████▌          |  ETA: 0:07:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1120000: -94.22128405822103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  75%|██████████████████████████████▉          |  ETA: 0:07:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1130000: -80.57152550354046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  76%|███████████████████████████████▏         |  ETA: 0:07:25\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1140000: -38.75345325847724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  76%|███████████████████████████████▍         |  ETA: 0:07:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1150000: -49.12264128050768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  77%|███████████████████████████████▋         |  ETA: 0:07:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1160000: -47.96604434641086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  78%|████████████████████████████████         |  ETA: 0:06:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1170000: -103.07248509070898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  78%|████████████████████████████████▏        |  ETA: 0:06:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1180000: -33.25697814822748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  79%|████████████████████████████████▌        |  ETA: 0:06:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1190000: -16.764546879229766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  80%|████████████████████████████████▋        |  ETA: 0:06:27\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1200000 saved to ./RL_models/vtol_2D_ppo_1200000.bson\n",
      "test reward at step 1200000: -74.83208364025333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  80%|█████████████████████████████████        |  ETA: 0:06:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1210000: -43.165029192725115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  81%|█████████████████████████████████▍       |  ETA: 0:05:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1220000: -25.88033053609702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  82%|█████████████████████████████████▌       |  ETA: 0:05:50\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1230000: -39.26254230274295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  83%|█████████████████████████████████▉       |  ETA: 0:05:35\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1240000: -52.472041107537656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  83%|██████████████████████████████████       |  ETA: 0:05:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1250000: -40.21263511761763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  84%|██████████████████████████████████▍      |  ETA: 0:05:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1260000: -56.4535397860294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  85%|██████████████████████████████████▋      |  ETA: 0:04:58\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1270000: -30.733724073440058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  85%|██████████████████████████████████▉      |  ETA: 0:04:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1280000: -32.9794655068414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  86%|███████████████████████████████████▏     |  ETA: 0:04:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1290000: -44.998178704352576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  87%|███████████████████████████████████▌     |  ETA: 0:04:21\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1300000 saved to ./RL_models/vtol_2D_ppo_1300000.bson\n",
      "test reward at step 1300000: -34.85566001351934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  87%|███████████████████████████████████▋     |  ETA: 0:04:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1310000: -18.173911182846705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  88%|████████████████████████████████████     |  ETA: 0:03:58\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1320000: -27.021494931997548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  88%|████████████████████████████████████▎    |  ETA: 0:03:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1330000: -21.316458327958625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  89%|████████████████████████████████████▌    |  ETA: 0:03:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1340000: -26.872916075673775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  90%|████████████████████████████████████▉    |  ETA: 0:03:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1350000: -55.44033140892242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  90%|█████████████████████████████████████▏   |  ETA: 0:03:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1360000: -30.24095233791148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  91%|█████████████████████████████████████▍   |  ETA: 0:02:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1370000: -19.10420048879143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  92%|█████████████████████████████████████▋   |  ETA: 0:02:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1380000: -27.43936045205613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  92%|█████████████████████████████████████▉   |  ETA: 0:02:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1390000: -45.627268228289395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  93%|██████████████████████████████████████▎  |  ETA: 0:02:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1400000 saved to ./RL_models/vtol_2D_ppo_1400000.bson\n",
      "test reward at step 1400000: -59.618658490783226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  94%|██████████████████████████████████████▍  |  ETA: 0:02:07\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1410000: -47.39150240390369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  95%|██████████████████████████████████████▊  |  ETA: 0:01:50\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1420000: -34.4971637031474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  95%|██████████████████████████████████████▉  |  ETA: 0:01:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1430000: -32.69411697896636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  96%|███████████████████████████████████████▎ |  ETA: 0:01:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1440000: -10.492743358391515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  97%|███████████████████████████████████████▋ |  ETA: 0:01:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1450000: -40.14593122832273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  97%|███████████████████████████████████████▊ |  ETA: 0:01:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1460000: -22.913371864121466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  98%|████████████████████████████████████████▏|  ETA: 0:00:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1470000: -15.256762935618685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  99%|████████████████████████████████████████▌|  ETA: 0:00:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1480000: -20.85740307786948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  99%|████████████████████████████████████████▋|  ETA: 0:00:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1490000: -20.73658127612667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress: 100%|█████████████████████████████████████████| Time: 0:34:03\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1500000 saved to ./RL_models/vtol_2D_ppo_1500000.bson\n",
      "test reward at step 1500000: -21.91746931900879\n"
     ]
    }
   ],
   "source": [
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(1_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000), \n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49a302a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip070\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip070)\" d=\"\nM0 1600 L2400 1600 L2400 0 L0 0  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip071\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip070)\" d=\"\nM209.029 1486.45 L2352.76 1486.45 L2352.76 47.2441 L209.029 47.2441  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip072\">\n    <rect x=\"209\" y=\"47\" width=\"2145\" height=\"1440\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip072)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  256.127,1486.45 256.127,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip072)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  934.779,1486.45 934.779,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip072)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1613.43,1486.45 1613.43,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip072)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  2292.08,1486.45 2292.08,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  209.029,1486.45 2352.76,1486.45 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  256.127,1486.45 256.127,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  934.779,1486.45 934.779,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1613.43,1486.45 1613.43,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2292.08,1486.45 2292.08,1467.55 \n  \"/>\n<path clip-path=\"url(#clip070)\" d=\"M256.127 1517.37 Q252.516 1517.37 250.687 1520.93 Q248.882 1524.47 248.882 1531.6 Q248.882 1538.71 250.687 1542.27 Q252.516 1545.82 256.127 1545.82 Q259.761 1545.82 261.567 1542.27 Q263.395 1538.71 263.395 1531.6 Q263.395 1524.47 261.567 1520.93 Q259.761 1517.37 256.127 1517.37 M256.127 1513.66 Q261.937 1513.66 264.993 1518.27 Q268.071 1522.85 268.071 1531.6 Q268.071 1540.33 264.993 1544.94 Q261.937 1549.52 256.127 1549.52 Q250.317 1549.52 247.238 1544.94 Q244.183 1540.33 244.183 1531.6 Q244.183 1522.85 247.238 1518.27 Q250.317 1513.66 256.127 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M909.479 1514.29 L927.835 1514.29 L927.835 1518.22 L913.761 1518.22 L913.761 1526.7 Q914.78 1526.35 915.798 1526.19 Q916.817 1526 917.835 1526 Q923.622 1526 927.002 1529.17 Q930.381 1532.34 930.381 1537.76 Q930.381 1543.34 926.909 1546.44 Q923.437 1549.52 917.118 1549.52 Q914.942 1549.52 912.673 1549.15 Q910.428 1548.78 908.02 1548.04 L908.02 1543.34 Q910.104 1544.47 912.326 1545.03 Q914.548 1545.58 917.025 1545.58 Q921.03 1545.58 923.367 1543.48 Q925.705 1541.37 925.705 1537.76 Q925.705 1534.15 923.367 1532.04 Q921.03 1529.94 917.025 1529.94 Q915.15 1529.94 913.275 1530.35 Q911.423 1530.77 909.479 1531.65 L909.479 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M949.594 1517.37 Q945.983 1517.37 944.154 1520.93 Q942.349 1524.47 942.349 1531.6 Q942.349 1538.71 944.154 1542.27 Q945.983 1545.82 949.594 1545.82 Q953.228 1545.82 955.034 1542.27 Q956.863 1538.71 956.863 1531.6 Q956.863 1524.47 955.034 1520.93 Q953.228 1517.37 949.594 1517.37 M949.594 1513.66 Q955.404 1513.66 958.46 1518.27 Q961.539 1522.85 961.539 1531.6 Q961.539 1540.33 958.46 1544.94 Q955.404 1549.52 949.594 1549.52 Q943.784 1549.52 940.705 1544.94 Q937.65 1540.33 937.65 1531.6 Q937.65 1522.85 940.705 1518.27 Q943.784 1513.66 949.594 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M1573.04 1544.91 L1580.68 1544.91 L1580.68 1518.55 L1572.37 1520.21 L1572.37 1515.95 L1580.63 1514.29 L1585.31 1514.29 L1585.31 1544.91 L1592.95 1544.91 L1592.95 1548.85 L1573.04 1548.85 L1573.04 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M1612.39 1517.37 Q1608.78 1517.37 1606.95 1520.93 Q1605.14 1524.47 1605.14 1531.6 Q1605.14 1538.71 1606.95 1542.27 Q1608.78 1545.82 1612.39 1545.82 Q1616.02 1545.82 1617.83 1542.27 Q1619.66 1538.71 1619.66 1531.6 Q1619.66 1524.47 1617.83 1520.93 Q1616.02 1517.37 1612.39 1517.37 M1612.39 1513.66 Q1618.2 1513.66 1621.26 1518.27 Q1624.33 1522.85 1624.33 1531.6 Q1624.33 1540.33 1621.26 1544.94 Q1618.2 1549.52 1612.39 1549.52 Q1606.58 1549.52 1603.5 1544.94 Q1600.45 1540.33 1600.45 1531.6 Q1600.45 1522.85 1603.5 1518.27 Q1606.58 1513.66 1612.39 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M1642.55 1517.37 Q1638.94 1517.37 1637.11 1520.93 Q1635.31 1524.47 1635.31 1531.6 Q1635.31 1538.71 1637.11 1542.27 Q1638.94 1545.82 1642.55 1545.82 Q1646.19 1545.82 1647.99 1542.27 Q1649.82 1538.71 1649.82 1531.6 Q1649.82 1524.47 1647.99 1520.93 Q1646.19 1517.37 1642.55 1517.37 M1642.55 1513.66 Q1648.36 1513.66 1651.42 1518.27 Q1654.5 1522.85 1654.5 1531.6 Q1654.5 1540.33 1651.42 1544.94 Q1648.36 1549.52 1642.55 1549.52 Q1636.74 1549.52 1633.66 1544.94 Q1630.61 1540.33 1630.61 1531.6 Q1630.61 1522.85 1633.66 1518.27 Q1636.74 1513.66 1642.55 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M2251.69 1544.91 L2259.33 1544.91 L2259.33 1518.55 L2251.02 1520.21 L2251.02 1515.95 L2259.28 1514.29 L2263.96 1514.29 L2263.96 1544.91 L2271.6 1544.91 L2271.6 1548.85 L2251.69 1548.85 L2251.69 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M2281.09 1514.29 L2299.45 1514.29 L2299.45 1518.22 L2285.37 1518.22 L2285.37 1526.7 Q2286.39 1526.35 2287.41 1526.19 Q2288.43 1526 2289.45 1526 Q2295.23 1526 2298.61 1529.17 Q2301.99 1532.34 2301.99 1537.76 Q2301.99 1543.34 2298.52 1546.44 Q2295.05 1549.52 2288.73 1549.52 Q2286.55 1549.52 2284.28 1549.15 Q2282.04 1548.78 2279.63 1548.04 L2279.63 1543.34 Q2281.71 1544.47 2283.94 1545.03 Q2286.16 1545.58 2288.64 1545.58 Q2292.64 1545.58 2294.98 1543.48 Q2297.32 1541.37 2297.32 1537.76 Q2297.32 1534.15 2294.98 1532.04 Q2292.64 1529.94 2288.64 1529.94 Q2286.76 1529.94 2284.89 1530.35 Q2283.03 1530.77 2281.09 1531.65 L2281.09 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M2321.2 1517.37 Q2317.59 1517.37 2315.76 1520.93 Q2313.96 1524.47 2313.96 1531.6 Q2313.96 1538.71 2315.76 1542.27 Q2317.59 1545.82 2321.2 1545.82 Q2324.84 1545.82 2326.64 1542.27 Q2328.47 1538.71 2328.47 1531.6 Q2328.47 1524.47 2326.64 1520.93 Q2324.84 1517.37 2321.2 1517.37 M2321.2 1513.66 Q2327.01 1513.66 2330.07 1518.27 Q2333.15 1522.85 2333.15 1531.6 Q2333.15 1540.33 2330.07 1544.94 Q2327.01 1549.52 2321.2 1549.52 Q2315.39 1549.52 2312.32 1544.94 Q2309.26 1540.33 2309.26 1531.6 Q2309.26 1522.85 2312.32 1518.27 Q2315.39 1513.66 2321.2 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip072)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  209.029,1360.75 2352.76,1360.75 \n  \"/>\n<polyline clip-path=\"url(#clip072)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  209.029,1164.19 2352.76,1164.19 \n  \"/>\n<polyline clip-path=\"url(#clip072)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  209.029,967.636 2352.76,967.636 \n  \"/>\n<polyline clip-path=\"url(#clip072)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  209.029,771.08 2352.76,771.08 \n  \"/>\n<polyline clip-path=\"url(#clip072)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  209.029,574.524 2352.76,574.524 \n  \"/>\n<polyline clip-path=\"url(#clip072)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  209.029,377.968 2352.76,377.968 \n  \"/>\n<polyline clip-path=\"url(#clip072)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  209.029,181.412 2352.76,181.412 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  209.029,1486.45 209.029,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  209.029,1360.75 227.926,1360.75 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  209.029,1164.19 227.926,1164.19 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  209.029,967.636 227.926,967.636 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  209.029,771.08 227.926,771.08 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  209.029,574.524 227.926,574.524 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  209.029,377.968 227.926,377.968 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  209.029,181.412 227.926,181.412 \n  \"/>\n<path clip-path=\"url(#clip070)\" d=\"M50.9921 1361.2 L80.6679 1361.2 L80.6679 1365.14 L50.9921 1365.14 L50.9921 1361.2 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M91.5706 1374.09 L99.2095 1374.09 L99.2095 1347.73 L90.8993 1349.39 L90.8993 1345.14 L99.1632 1343.47 L103.839 1343.47 L103.839 1374.09 L111.478 1374.09 L111.478 1378.03 L91.5706 1378.03 L91.5706 1374.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M133.769 1347.54 L121.964 1365.99 L133.769 1365.99 L133.769 1347.54 M132.543 1343.47 L138.422 1343.47 L138.422 1365.99 L143.353 1365.99 L143.353 1369.88 L138.422 1369.88 L138.422 1378.03 L133.769 1378.03 L133.769 1369.88 L118.168 1369.88 L118.168 1365.37 L132.543 1343.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M161.084 1346.55 Q157.473 1346.55 155.644 1350.11 Q153.839 1353.65 153.839 1360.78 Q153.839 1367.89 155.644 1371.45 Q157.473 1375 161.084 1375 Q164.718 1375 166.524 1371.45 Q168.353 1367.89 168.353 1360.78 Q168.353 1353.65 166.524 1350.11 Q164.718 1346.55 161.084 1346.55 M161.084 1342.84 Q166.894 1342.84 169.95 1347.45 Q173.029 1352.03 173.029 1360.78 Q173.029 1369.51 169.95 1374.12 Q166.894 1378.7 161.084 1378.7 Q155.274 1378.7 152.195 1374.12 Q149.14 1369.51 149.14 1360.78 Q149.14 1352.03 152.195 1347.45 Q155.274 1342.84 161.084 1342.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M50.9921 1164.64 L80.6679 1164.64 L80.6679 1168.58 L50.9921 1168.58 L50.9921 1164.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M91.5706 1177.54 L99.2095 1177.54 L99.2095 1151.17 L90.8993 1152.84 L90.8993 1148.58 L99.1632 1146.91 L103.839 1146.91 L103.839 1177.54 L111.478 1177.54 L111.478 1181.47 L91.5706 1181.47 L91.5706 1177.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M124.95 1177.54 L141.269 1177.54 L141.269 1181.47 L119.325 1181.47 L119.325 1177.54 Q121.987 1174.78 126.57 1170.15 Q131.177 1165.5 132.357 1164.16 Q134.603 1161.63 135.482 1159.9 Q136.385 1158.14 136.385 1156.45 Q136.385 1153.69 134.441 1151.96 Q132.519 1150.22 129.418 1150.22 Q127.219 1150.22 124.765 1150.99 Q122.334 1151.75 119.557 1153.3 L119.557 1148.58 Q122.381 1147.44 124.834 1146.87 Q127.288 1146.29 129.325 1146.29 Q134.695 1146.29 137.89 1148.97 Q141.084 1151.66 141.084 1156.15 Q141.084 1158.28 140.274 1160.2 Q139.487 1162.1 137.381 1164.69 Q136.802 1165.36 133.7 1168.58 Q130.598 1171.77 124.95 1177.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M161.084 1149.99 Q157.473 1149.99 155.644 1153.56 Q153.839 1157.1 153.839 1164.23 Q153.839 1171.33 155.644 1174.9 Q157.473 1178.44 161.084 1178.44 Q164.718 1178.44 166.524 1174.9 Q168.353 1171.33 168.353 1164.23 Q168.353 1157.1 166.524 1153.56 Q164.718 1149.99 161.084 1149.99 M161.084 1146.29 Q166.894 1146.29 169.95 1150.89 Q173.029 1155.48 173.029 1164.23 Q173.029 1172.95 169.95 1177.56 Q166.894 1182.14 161.084 1182.14 Q155.274 1182.14 152.195 1177.56 Q149.14 1172.95 149.14 1164.23 Q149.14 1155.48 152.195 1150.89 Q155.274 1146.29 161.084 1146.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M50.9921 968.088 L80.6679 968.088 L80.6679 972.023 L50.9921 972.023 L50.9921 968.088 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M91.5706 980.981 L99.2095 980.981 L99.2095 954.616 L90.8993 956.282 L90.8993 952.023 L99.1632 950.356 L103.839 950.356 L103.839 980.981 L111.478 980.981 L111.478 984.916 L91.5706 984.916 L91.5706 980.981 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M130.922 953.435 Q127.311 953.435 125.482 957 Q123.677 960.541 123.677 967.671 Q123.677 974.777 125.482 978.342 Q127.311 981.884 130.922 981.884 Q134.556 981.884 136.362 978.342 Q138.191 974.777 138.191 967.671 Q138.191 960.541 136.362 957 Q134.556 953.435 130.922 953.435 M130.922 949.731 Q136.732 949.731 139.788 954.338 Q142.867 958.921 142.867 967.671 Q142.867 976.398 139.788 981.004 Q136.732 985.588 130.922 985.588 Q125.112 985.588 122.033 981.004 Q118.978 976.398 118.978 967.671 Q118.978 958.921 122.033 954.338 Q125.112 949.731 130.922 949.731 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M161.084 953.435 Q157.473 953.435 155.644 957 Q153.839 960.541 153.839 967.671 Q153.839 974.777 155.644 978.342 Q157.473 981.884 161.084 981.884 Q164.718 981.884 166.524 978.342 Q168.353 974.777 168.353 967.671 Q168.353 960.541 166.524 957 Q164.718 953.435 161.084 953.435 M161.084 949.731 Q166.894 949.731 169.95 954.338 Q173.029 958.921 173.029 967.671 Q173.029 976.398 169.95 981.004 Q166.894 985.588 161.084 985.588 Q155.274 985.588 152.195 981.004 Q149.14 976.398 149.14 967.671 Q149.14 958.921 152.195 954.338 Q155.274 949.731 161.084 949.731 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M81.154 771.532 L110.83 771.532 L110.83 775.467 L81.154 775.467 L81.154 771.532 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M130.922 771.948 Q127.589 771.948 125.668 773.731 Q123.77 775.513 123.77 778.638 Q123.77 781.763 125.668 783.545 Q127.589 785.328 130.922 785.328 Q134.256 785.328 136.177 783.545 Q138.098 781.74 138.098 778.638 Q138.098 775.513 136.177 773.731 Q134.279 771.948 130.922 771.948 M126.246 769.957 Q123.237 769.217 121.547 767.157 Q119.881 765.096 119.881 762.133 Q119.881 757.99 122.82 755.583 Q125.783 753.175 130.922 753.175 Q136.084 753.175 139.024 755.583 Q141.964 757.99 141.964 762.133 Q141.964 765.096 140.274 767.157 Q138.607 769.217 135.621 769.957 Q139.001 770.744 140.876 773.036 Q142.774 775.328 142.774 778.638 Q142.774 783.661 139.695 786.346 Q136.64 789.031 130.922 789.031 Q125.205 789.031 122.126 786.346 Q119.07 783.661 119.07 778.638 Q119.07 775.328 120.969 773.036 Q122.867 770.744 126.246 769.957 M124.533 762.573 Q124.533 765.258 126.2 766.763 Q127.89 768.268 130.922 768.268 Q133.931 768.268 135.621 766.763 Q137.334 765.258 137.334 762.573 Q137.334 759.888 135.621 758.383 Q133.931 756.879 130.922 756.879 Q127.89 756.879 126.2 758.383 Q124.533 759.888 124.533 762.573 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M161.084 756.879 Q157.473 756.879 155.644 760.444 Q153.839 763.985 153.839 771.115 Q153.839 778.221 155.644 781.786 Q157.473 785.328 161.084 785.328 Q164.718 785.328 166.524 781.786 Q168.353 778.221 168.353 771.115 Q168.353 763.985 166.524 760.444 Q164.718 756.879 161.084 756.879 M161.084 753.175 Q166.894 753.175 169.95 757.782 Q173.029 762.365 173.029 771.115 Q173.029 779.842 169.95 784.448 Q166.894 789.031 161.084 789.031 Q155.274 789.031 152.195 784.448 Q149.14 779.842 149.14 771.115 Q149.14 762.365 152.195 757.782 Q155.274 753.175 161.084 753.175 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M81.154 574.975 L110.83 574.975 L110.83 578.911 L81.154 578.911 L81.154 574.975 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M131.501 572.661 Q128.353 572.661 126.501 574.813 Q124.672 576.966 124.672 580.716 Q124.672 584.443 126.501 586.619 Q128.353 588.772 131.501 588.772 Q134.649 588.772 136.478 586.619 Q138.33 584.443 138.33 580.716 Q138.33 576.966 136.478 574.813 Q134.649 572.661 131.501 572.661 M140.783 558.008 L140.783 562.267 Q139.024 561.434 137.219 560.994 Q135.436 560.554 133.677 560.554 Q129.047 560.554 126.594 563.679 Q124.163 566.804 123.816 573.124 Q125.182 571.11 127.242 570.045 Q129.302 568.957 131.779 568.957 Q136.987 568.957 139.996 572.128 Q143.029 575.276 143.029 580.716 Q143.029 586.04 139.881 589.258 Q136.732 592.475 131.501 592.475 Q125.506 592.475 122.334 587.892 Q119.163 583.286 119.163 574.559 Q119.163 566.364 123.052 561.503 Q126.941 556.619 133.492 556.619 Q135.251 556.619 137.033 556.966 Q138.839 557.313 140.783 558.008 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M161.084 560.323 Q157.473 560.323 155.644 563.887 Q153.839 567.429 153.839 574.559 Q153.839 581.665 155.644 585.23 Q157.473 588.772 161.084 588.772 Q164.718 588.772 166.524 585.23 Q168.353 581.665 168.353 574.559 Q168.353 567.429 166.524 563.887 Q164.718 560.323 161.084 560.323 M161.084 556.619 Q166.894 556.619 169.95 561.225 Q173.029 565.809 173.029 574.559 Q173.029 583.286 169.95 587.892 Q166.894 592.475 161.084 592.475 Q155.274 592.475 152.195 587.892 Q149.14 583.286 149.14 574.559 Q149.14 565.809 152.195 561.225 Q155.274 556.619 161.084 556.619 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M81.154 378.419 L110.83 378.419 L110.83 382.354 L81.154 382.354 L81.154 378.419 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M133.769 364.762 L121.964 383.211 L133.769 383.211 L133.769 364.762 M132.543 360.688 L138.422 360.688 L138.422 383.211 L143.353 383.211 L143.353 387.1 L138.422 387.1 L138.422 395.248 L133.769 395.248 L133.769 387.1 L118.168 387.1 L118.168 382.586 L132.543 360.688 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M161.084 363.767 Q157.473 363.767 155.644 367.331 Q153.839 370.873 153.839 378.003 Q153.839 385.109 155.644 388.674 Q157.473 392.215 161.084 392.215 Q164.718 392.215 166.524 388.674 Q168.353 385.109 168.353 378.003 Q168.353 370.873 166.524 367.331 Q164.718 363.767 161.084 363.767 M161.084 360.063 Q166.894 360.063 169.95 364.669 Q173.029 369.253 173.029 378.003 Q173.029 386.729 169.95 391.336 Q166.894 395.919 161.084 395.919 Q155.274 395.919 152.195 391.336 Q149.14 386.729 149.14 378.003 Q149.14 369.253 152.195 364.669 Q155.274 360.063 161.084 360.063 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M81.154 181.863 L110.83 181.863 L110.83 185.798 L81.154 185.798 L81.154 181.863 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M124.95 194.757 L141.269 194.757 L141.269 198.692 L119.325 198.692 L119.325 194.757 Q121.987 192.002 126.57 187.372 Q131.177 182.72 132.357 181.377 Q134.603 178.854 135.482 177.118 Q136.385 175.359 136.385 173.669 Q136.385 170.914 134.441 169.178 Q132.519 167.442 129.418 167.442 Q127.219 167.442 124.765 168.206 Q122.334 168.97 119.557 170.521 L119.557 165.798 Q122.381 164.664 124.834 164.085 Q127.288 163.507 129.325 163.507 Q134.695 163.507 137.89 166.192 Q141.084 168.877 141.084 173.368 Q141.084 175.497 140.274 177.419 Q139.487 179.317 137.381 181.909 Q136.802 182.581 133.7 185.798 Q130.598 188.993 124.95 194.757 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M161.084 167.21 Q157.473 167.21 155.644 170.775 Q153.839 174.317 153.839 181.446 Q153.839 188.553 155.644 192.118 Q157.473 195.659 161.084 195.659 Q164.718 195.659 166.524 192.118 Q168.353 188.553 168.353 181.446 Q168.353 174.317 166.524 170.775 Q164.718 167.21 161.084 167.21 M161.084 163.507 Q166.894 163.507 169.95 168.113 Q173.029 172.697 173.029 181.446 Q173.029 190.173 169.95 194.78 Q166.894 199.363 161.084 199.363 Q155.274 199.363 152.195 194.78 Q149.14 190.173 149.14 181.446 Q149.14 172.697 152.195 168.113 Q155.274 163.507 161.084 163.507 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip072)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  269.7,478.946 283.273,434.272 296.846,404.165 310.419,430.296 323.992,397.378 337.565,442.555 351.138,502.851 364.711,432.456 378.284,489.656 391.857,566.199 \n  405.431,464.071 419.004,393.845 432.577,460.359 446.15,385.495 459.723,538.706 473.296,432.884 486.869,347.532 500.442,388.905 514.015,467.868 527.588,404.661 \n  541.161,612.763 554.734,544.243 568.307,392.922 581.88,373.488 595.453,518.355 609.026,391.029 622.599,356.004 636.172,518.122 649.745,639.167 663.318,367.833 \n  676.892,617.498 690.465,352.411 704.038,609.911 717.611,508.833 731.184,407.883 744.757,552.858 758.33,435.902 771.903,383.001 785.476,581.721 799.049,483.274 \n  812.622,560.331 826.195,345.594 839.768,384.036 853.341,420.995 866.914,634.925 880.487,366.053 894.06,550.771 907.633,526.872 921.206,552.445 934.779,575.459 \n  948.353,537.844 961.926,388.056 975.499,395.434 989.072,639.044 1002.64,522.729 1016.22,724.64 1029.79,912.739 1043.36,517.005 1056.94,772.701 1070.51,707.352 \n  1084.08,534.874 1097.66,723.813 1111.23,665.243 1124.8,440.929 1138.38,922.348 1151.95,748.234 1165.52,649.324 1179.09,440.425 1192.67,262.152 1206.24,515.186 \n  1219.81,188.917 1233.39,469.652 1246.96,1445.72 1260.53,227.042 1274.11,148.13 1287.68,325.759 1301.25,1239.59 1314.82,234.249 1328.4,341.57 1341.97,754.957 \n  1355.54,940.245 1369.12,981.493 1382.69,976.177 1396.26,1389.81 1409.84,597.777 1423.41,379.701 1436.98,342.466 1450.56,382.691 1464.13,288.631 1477.7,397.155 \n  1491.27,307.215 1504.85,298.576 1518.42,227.145 1531.99,312.315 1545.57,355.685 1559.14,478.674 1572.71,1404.63 1586.29,597.232 1599.86,415.436 1613.43,342.816 \n  1627,367.98 1640.58,513.571 1654.15,483.585 1667.72,903.837 1681.3,397.537 1694.87,394.17 1708.44,724.51 1722.02,581.05 1735.59,252.714 1749.16,91.7956 \n  1762.74,280.473 1776.31,910.844 1789.88,776.697 1803.45,365.717 1817.03,467.623 1830.6,456.257 1844.17,997.832 1857.75,311.699 1871.32,149.614 1884.89,720.291 \n  1898.47,409.073 1912.04,239.203 1925.61,370.72 1939.19,500.541 1952.76,380.058 1966.33,539.67 1979.9,286.901 1993.48,308.971 2007.05,427.089 2020.62,327.41 \n  2034.2,163.465 2047.77,250.418 2061.34,194.35 2074.92,248.957 2088.49,529.712 2102.06,282.058 2115.63,172.608 2129.21,254.524 2142.78,433.272 2156.35,570.776 \n  2169.93,450.61 2183.5,323.887 2197.07,306.167 2210.65,87.9763 2224.22,379.402 2237.79,210.044 2251.37,134.796 2264.94,189.838 2278.51,188.651 2292.08,200.256 \n  \n  \"/>\n<path clip-path=\"url(#clip070)\" d=\"\nM2014.5 1438.47 L2281.3 1438.47 L2281.3 1334.79 L2014.5 1334.79  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2014.5,1438.47 2281.3,1438.47 2281.3,1334.79 2014.5,1334.79 2014.5,1438.47 \n  \"/>\n<polyline clip-path=\"url(#clip070)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2038.31,1386.63 2181.23,1386.63 \n  \"/>\n<path clip-path=\"url(#clip070)\" d=\"M2218.89 1406.32 Q2217.09 1410.95 2215.37 1412.36 Q2213.66 1413.78 2210.79 1413.78 L2207.39 1413.78 L2207.39 1410.21 L2209.89 1410.21 Q2211.65 1410.21 2212.62 1409.38 Q2213.59 1408.54 2214.77 1405.44 L2215.53 1403.5 L2205.05 1377.99 L2209.56 1377.99 L2217.66 1398.27 L2225.77 1377.99 L2230.28 1377.99 L2218.89 1406.32 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip070)\" d=\"M2237.57 1399.98 L2245.21 1399.98 L2245.21 1373.61 L2236.9 1375.28 L2236.9 1371.02 L2245.16 1369.35 L2249.84 1369.35 L2249.84 1399.98 L2257.48 1399.98 L2257.48 1403.91 L2237.57 1403.91 L2237.57 1399.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(episode_test_reward_hook.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb0d4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_visualization(); # closes the MeshCat visualization"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
