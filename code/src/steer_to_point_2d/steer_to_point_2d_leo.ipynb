{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1m┌ \u001B[22m\u001B[39m\u001B[36m\u001B[1mInfo: \u001B[22m\u001B[39mMeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "\u001B[36m\u001B[1m└ \u001B[22m\u001B[39mhttp://127.0.0.1:8700\n"
     ]
    }
   ],
   "source": [
    "## Init Bionic VTOL\n",
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position\n",
    "\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;\n",
    "using Distributions;\n",
    "\n",
    "using Plots;\n",
    "using Statistics;\n",
    "\n",
    "using BSON: @save, @load # save mode\n",
    "create_visualization();\n",
    "\n",
    "# indicates how many threads Julia was started with. This is important for the multi-threaded environment\n",
    "Threads.nthreads()\n",
    "### Create Reinforcement Learning Environment\n",
    "\n",
    "\n",
    "################################ TODO ################################\n",
    "# You can initialization global constants here.\n",
    "# E.g. a fixed point in the beginning of training (for testing/overfitting)\n",
    "# Define global constants for initial position and rotation\n",
    "\n",
    "#####\n",
    "##### first coordinate - red axis - x\n",
    "##### second coordinate - green axis - y\n",
    "##### third coordinate - blue axis - z\n",
    "#####\n",
    "\n",
    "const NUM_WAYPOINTS = 2;\n",
    "const INITIAL_POSITION = [0.0, 0.0, 0.0];\n",
    "const INITIAL_ROTATION = [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0];\n",
    "const SAMPLE_WAYPOINTS = [[0.0, 0.0, 0.0], [-10.0, 0.0, 5.0]];\n",
    "\n",
    "w_max = 25.0; # maximum rotational speed before getting punished\n",
    "timeout = 15.0; # simulation end time\n",
    "floor_level = -10.0; # as in aviation\n",
    "v_expected = 3.0; # maximum speed before getting punished\n",
    "\n",
    "######################################################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[1mTest Summary:              | \u001B[22m\u001B[32m\u001B[1mPass  \u001B[22m\u001B[39m\u001B[36m\u001B[1mTotal  \u001B[22m\u001B[39m\u001B[0m\u001B[1mTime\u001B[22m\n",
      "random policy with VtolEnv | \u001B[32m2000  \u001B[39m\u001B[36m 2000  \u001B[39m\u001B[0m1.1s\n",
      "13\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1m┌ \u001B[22m\u001B[39m\u001B[36m\u001B[1mInfo: \u001B[22m\u001B[39mThe GPU function is being called but the GPU is not accessible. \n",
      "\u001B[36m\u001B[1m└ \u001B[22m\u001B[39mDefaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "\u001B[32mProgress:   1%|▎                                        |  ETA: 1:27:30\u001B[39mm9m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 10000: -1197.3325044227252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   1%|▌                                        |  ETA: 0:50:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 20000: -1038.7529508396442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   2%|▊                                        |  ETA: 0:37:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 30000: -1246.2829955078248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   2%|█                                        |  ETA: 0:30:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 40000: -512.8447001673078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   3%|█▎                                       |  ETA: 0:26:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 50000: -810.9132105775715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   4%|█▌                                       |  ETA: 0:23:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 60000: -486.6981606521489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   5%|█▉                                       |  ETA: 0:21:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 70000: -1337.0246386182575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   5%|██▎                                      |  ETA: 0:20:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 80000: -505.7576277216737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   6%|██▍                                      |  ETA: 0:18:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 90000: -796.6275399345215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   6%|██▋                                      |  ETA: 0:18:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 100000 saved to ./RL_models_leo/vtol_2D_ppo_100000.bson\n",
      "test reward at step 100000: -1599.157016475404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   7%|██▉                                      |  ETA: 0:18:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 110000: -1065.3396966569037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   8%|███▎                                     |  ETA: 0:17:22\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 120000: -993.3467525948479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   9%|███▌                                     |  ETA: 0:16:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 130000: -868.7459682443944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   9%|███▋                                     |  ETA: 0:17:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 140000: -785.8268964929946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  10%|████                                     |  ETA: 0:16:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 150000: -619.7765239427064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  11%|████▍                                    |  ETA: 0:16:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 160000: -701.0046956373168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  11%|████▋                                    |  ETA: 0:16:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 170000: -952.1791522386694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  12%|████▉                                    |  ETA: 0:18:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 180000: -556.3426254486329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  12%|█████▏                                   |  ETA: 0:17:40\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 190000: -1091.3635393211264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  13%|█████▍                                   |  ETA: 0:18:35\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 200000 saved to ./RL_models_leo/vtol_2D_ppo_200000.bson\n",
      "test reward at step 200000: -853.1074952868696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  14%|█████▋                                   |  ETA: 0:19:13\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 210000: -305.7729248726722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  15%|██████                                   |  ETA: 0:19:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 220000: -1216.1264451583263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  15%|██████▏                                  |  ETA: 0:20:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 230000: -582.3048781811934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  16%|██████▌                                  |  ETA: 0:20:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 240000: -305.82752433729496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  17%|██████▊                                  |  ETA: 0:21:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 250000: -625.007725755052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  17%|███████▏                                 |  ETA: 0:21:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 260000: -301.4917257224193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  18%|███████▎                                 |  ETA: 0:22:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 270000: -439.0474593939486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  18%|███████▋                                 |  ETA: 0:22:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 280000: -291.1990764105893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  19%|███████▉                                 |  ETA: 0:22:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 290000: -309.78684856498944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  20%|████████                                 |  ETA: 0:23:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 300000 saved to ./RL_models_leo/vtol_2D_ppo_300000.bson\n",
      "test reward at step 300000: -297.3097718332196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  20%|████████▍                                |  ETA: 0:23:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 310000: -289.3037521006822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  21%|████████▋                                |  ETA: 0:23:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 320000: -410.52883492483954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  22%|█████████                                |  ETA: 0:23:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 330000: -669.4900395189534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  22%|█████████▏                               |  ETA: 0:23:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 340000: -293.74922902351034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  23%|█████████▌                               |  ETA: 0:23:40\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 350000: -284.74862530369666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  24%|█████████▊                               |  ETA: 0:23:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 360000: -293.6299949683434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  25%|██████████▏                              |  ETA: 0:23:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 370000: -275.76767050738925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  25%|██████████▍                              |  ETA: 0:24:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 380000: -309.020318694461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  26%|██████████▌                              |  ETA: 0:24:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 390000: -292.2594225864156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  26%|██████████▉                              |  ETA: 0:24:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 400000 saved to ./RL_models_leo/vtol_2D_ppo_400000.bson\n",
      "test reward at step 400000: -281.52386239200706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  27%|███████████▏                             |  ETA: 0:24:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 410000: -298.9992897056305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  28%|███████████▌                             |  ETA: 0:23:55\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 420000: -311.9471675992724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  29%|███████████▊                             |  ETA: 0:24:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 430000: -296.87891608674477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  29%|███████████▉                             |  ETA: 0:24:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 440000: -424.0984039241801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  30%|████████████▎                            |  ETA: 0:24:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 450000: -305.8866932546402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  31%|████████████▌                            |  ETA: 0:23:54\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 460000: -306.3811357550596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  31%|████████████▉                            |  ETA: 0:23:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 470000: -365.6583728829827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  32%|█████████████                            |  ETA: 0:23:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 480000: -287.3227330115013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  32%|█████████████▎                           |  ETA: 0:23:47\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 490000: -285.81378302744116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  33%|█████████████▋                           |  ETA: 0:23:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 500000 saved to ./RL_models_leo/vtol_2D_ppo_500000.bson\n",
      "test reward at step 500000: -287.2533245313659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  34%|█████████████▉                           |  ETA: 0:23:25\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 510000: -299.55208530978325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  35%|██████████████▎                          |  ETA: 0:23:47\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 520000: -288.76409930319505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  35%|██████████████▍                          |  ETA: 0:23:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 530000: -309.4157944055943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  36%|██████████████▋                          |  ETA: 0:23:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 540000: -348.1673438892387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  37%|███████████████                          |  ETA: 0:23:03\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 550000: -285.3389654396265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  37%|███████████████▎                         |  ETA: 0:22:50\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 560000: -288.626444347949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  38%|███████████████▌                         |  ETA: 0:22:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 570000: -302.0847876460862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  38%|███████████████▊                         |  ETA: 0:22:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 580000: -288.17687977988743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  39%|████████████████▏                        |  ETA: 0:22:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 590000: -293.46570326840134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  40%|████████████████▍                        |  ETA: 0:22:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 600000 saved to ./RL_models_leo/vtol_2D_ppo_600000.bson\n",
      "test reward at step 600000: -306.2957473303757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  40%|████████████████▌                        |  ETA: 0:22:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 610000: -313.60309991618107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  41%|████████████████▉                        |  ETA: 0:22:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 620000: -305.6976008393142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  42%|█████████████████▏                       |  ETA: 0:21:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 630000: -293.28354921464773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  43%|█████████████████▌                       |  ETA: 0:21:35\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 640000: -291.85322086933473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  43%|█████████████████▋                       |  ETA: 0:21:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 650000: -539.9859798490806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  44%|██████████████████                       |  ETA: 0:21:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 660000: -330.2203147996896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  45%|██████████████████▎                      |  ETA: 0:21:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 670000: -296.10276849605594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  45%|██████████████████▌                      |  ETA: 0:20:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 680000: -329.8205345653035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  46%|██████████████████▊                      |  ETA: 0:20:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 690000: -297.24732247682607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  46%|███████████████████                      |  ETA: 0:20:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 700000 saved to ./RL_models_leo/vtol_2D_ppo_700000.bson\n",
      "test reward at step 700000: -368.634642900835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  47%|███████████████████▍                     |  ETA: 0:20:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 710000: -623.5983668476264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  48%|███████████████████▋                     |  ETA: 0:20:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 720000: -440.5660626795307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  48%|███████████████████▉                     |  ETA: 0:19:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 730000: -404.4614084421256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  49%|████████████████████▏                    |  ETA: 0:19:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 740000: -325.6309808656399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  50%|████████████████████▌                    |  ETA: 0:19:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 750000: -383.70380413781123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  51%|████████████████████▊                    |  ETA: 0:19:10\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 760000: -308.5358217008225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  51%|████████████████████▉                    |  ETA: 0:19:10\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 770000: -347.0874097526751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  52%|█████████████████████▎                   |  ETA: 0:18:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 780000: -306.96794708073867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  53%|█████████████████████▋                   |  ETA: 0:18:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 790000: -327.82318044659223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  53%|█████████████████████▊                   |  ETA: 0:18:32\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 800000 saved to ./RL_models_leo/vtol_2D_ppo_800000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  53%|█████████████████████▉                   |  ETA: 0:18:30\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 800000: -360.77410992826043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  54%|██████████████████████                   |  ETA: 0:18:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 810000: -385.16540807058493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  55%|██████████████████████▍                  |  ETA: 0:17:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 820000: -284.3547148959763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  55%|██████████████████████▋                  |  ETA: 0:17:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 830000: -290.2267982916173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  56%|██████████████████████▉                  |  ETA: 0:17:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 840000: -975.6726507421355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  56%|███████████████████████▏                 |  ETA: 0:17:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 850000: -300.5723149290503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  57%|███████████████████████▌                 |  ETA: 0:17:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 860000: -279.6882836761858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  58%|███████████████████████▊                 |  ETA: 0:16:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 870000: -293.2979867821219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  58%|███████████████████████▉                 |  ETA: 0:16:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 880000: -373.646996810062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  59%|████████████████████████▎                |  ETA: 0:16:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 890000: -353.547255334514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  60%|████████████████████████▋                |  ETA: 0:16:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 900000 saved to ./RL_models_leo/vtol_2D_ppo_900000.bson\n",
      "test reward at step 900000: -287.0245633586159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  60%|████████████████████████▊                |  ETA: 0:15:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 910000: -281.4599163526231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  61%|█████████████████████████                |  ETA: 0:15:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 920000: -330.9677013464277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  62%|█████████████████████████▍               |  ETA: 0:15:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 930000: -291.54325849907025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  63%|█████████████████████████▋               |  ETA: 0:15:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 940000: -293.4289638695467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  63%|█████████████████████████▉               |  ETA: 0:14:58\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 950000: -292.1183606837019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  64%|██████████████████████████▏              |  ETA: 0:14:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 960000: -299.33925055744015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  64%|██████████████████████████▍              |  ETA: 0:14:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 970000: -293.69507915721033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  65%|██████████████████████████▊              |  ETA: 0:14:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 980000: -291.5350641727026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  66%|███████████████████████████              |  ETA: 0:13:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 990000: -294.14107430740586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  66%|███████████████████████████▏             |  ETA: 0:13:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1000000 saved to ./RL_models_leo/vtol_2D_ppo_1000000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  67%|███████████████████████████▍             |  ETA: 0:13:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1000000: -1405.4282010464915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  67%|███████████████████████████▌             |  ETA: 0:13:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1010000: -297.7400400847716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  68%|███████████████████████████▊             |  ETA: 0:13:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1020000: -288.5057541149078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  69%|████████████████████████████▏            |  ETA: 0:12:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1030000: -298.82980443771936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  69%|████████████████████████████▍            |  ETA: 0:12:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1040000: -362.4382054740018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  70%|████████████████████████████▋            |  ETA: 0:12:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1050000: -300.0905263195922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  70%|████████████████████████████▉            |  ETA: 0:12:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1060000: -299.8725757319008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  71%|█████████████████████████████▎           |  ETA: 0:11:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1070000: -1773.7851517962408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  72%|█████████████████████████████▌           |  ETA: 0:11:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1080000: -1508.8248101645356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  73%|█████████████████████████████▊           |  ETA: 0:11:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1090000: -287.8332229026755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  73%|██████████████████████████████           |  ETA: 0:11:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1100000 saved to ./RL_models_leo/vtol_2D_ppo_1100000.bson\n",
      "test reward at step 1100000: -290.5534518604674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  74%|██████████████████████████████▎          |  ETA: 0:10:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1110000: -995.2420076668521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  75%|██████████████████████████████▋          |  ETA: 0:10:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1120000: -295.28705669837296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  75%|██████████████████████████████▉          |  ETA: 0:10:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1130000: -283.7519338522494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  76%|███████████████████████████████          |  ETA: 0:10:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1140000: -1000.9546384411178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  76%|███████████████████████████████▍         |  ETA: 0:09:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1150000: -291.29726189029253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  77%|███████████████████████████████▋         |  ETA: 0:09:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1160000: -291.20210798221524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  78%|████████████████████████████████         |  ETA: 0:09:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1170000: -300.5153421182234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  79%|████████████████████████████████▎        |  ETA: 0:08:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1180000: -289.8766243415815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  79%|████████████████████████████████▍        |  ETA: 0:08:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1190000: -304.48347319475704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  80%|████████████████████████████████▊        |  ETA: 0:08:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1200000 saved to ./RL_models_leo/vtol_2D_ppo_1200000.bson\n",
      "test reward at step 1200000: -292.2104413438931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  81%|█████████████████████████████████        |  ETA: 0:07:58\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1210000: -734.3202119929924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  81%|█████████████████████████████████▎       |  ETA: 0:07:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1220000: -280.4239428878118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  82%|█████████████████████████████████▌       |  ETA: 0:07:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1230000: -284.83878709680295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  82%|█████████████████████████████████▊       |  ETA: 0:07:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1240000: -277.65275864969976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  83%|██████████████████████████████████▏      |  ETA: 0:06:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1250000: -288.58467598142494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  84%|██████████████████████████████████▍      |  ETA: 0:06:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1260000: -285.8182711894928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  85%|██████████████████████████████████▊      |  ETA: 0:06:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1270000: -1069.8390460129192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  85%|██████████████████████████████████▉      |  ETA: 0:06:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1280000: -275.75853331197715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  86%|███████████████████████████████████▏     |  ETA: 0:05:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1290000: -281.05412512008724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  87%|███████████████████████████████████▌     |  ETA: 0:05:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1300000 saved to ./RL_models_leo/vtol_2D_ppo_1300000.bson\n",
      "test reward at step 1300000: -283.43256272472036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  87%|███████████████████████████████████▊     |  ETA: 0:05:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1310000: -278.15828388291544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  88%|████████████████████████████████████     |  ETA: 0:05:07\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1320000: -284.8967622160238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  88%|████████████████████████████████████▎    |  ETA: 0:04:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1330000: -287.07775334906836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  89%|████████████████████████████████████▌    |  ETA: 0:04:30\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1340000: -276.75053134282547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  90%|████████████████████████████████████▉    |  ETA: 0:04:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1350000: -269.3930960721547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  91%|█████████████████████████████████████▏   |  ETA: 0:03:54\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1360000: -278.5873559647574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  91%|█████████████████████████████████████▍   |  ETA: 0:03:43\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1370000: -261.214736433941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  92%|█████████████████████████████████████▋   |  ETA: 0:03:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1380000: -264.8013814956391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  93%|██████████████████████████████████████   |  ETA: 0:03:05\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1390000: -246.27574247664242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  93%|██████████████████████████████████████▏  |  ETA: 0:02:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1400000 saved to ./RL_models_leo/vtol_2D_ppo_1400000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  93%|██████████████████████████████████████▎  |  ETA: 0:02:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1400000: -203.40915289291127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  94%|██████████████████████████████████████▍  |  ETA: 0:02:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1410000: -179.71581034679247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  95%|██████████████████████████████████████▊  |  ETA: 0:02:18\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1420000: -169.53532624863948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  95%|███████████████████████████████████████  |  ETA: 0:01:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1430000: -167.36192490721754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  96%|███████████████████████████████████████▍ |  ETA: 0:01:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1440000: -164.04741925011209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  96%|███████████████████████████████████████▌ |  ETA: 0:01:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1450000: -150.4595605411987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  97%|███████████████████████████████████████▉ |  ETA: 0:01:12\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1460000: -142.43224749535142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  98%|████████████████████████████████████████▏|  ETA: 0:00:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1470000: -136.58891248924556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  99%|████████████████████████████████████████▌|  ETA: 0:00:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1480000: -128.3653464157472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  99%|████████████████████████████████████████▋|  ETA: 0:00:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1490000: -126.21779551486578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress: 100%|█████████████████████████████████████████| Time: 0:41:58\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1500000 saved to ./RL_models_leo/vtol_2D_ppo_1500000.bson\n",
      "test reward at step 1500000: -134.93352085268606\n"
     ]
    }
   ],
   "source": [
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv # Parametric Constructor for a subtype of AbstractEnv\n",
    "    action_space::A # action space\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}} # observation space\n",
    "    state::Vector{T} # current state space\n",
    "    action::ACT # action space\n",
    "    done::Bool # done\n",
    "    t::T # time\n",
    "    rng::R # random number generator\n",
    "\n",
    "    name::String # for multible environments\n",
    "    visualization::Bool # visualization\n",
    "    realtime::Bool # realtime\n",
    "\n",
    "    x_previous::Vector{T} # previous position\n",
    "    x_W::Vector{T} # current position\n",
    "    v_B::Vector{T} # velocity\n",
    "    R_W::Matrix{T} # current rotation\n",
    "    w_B::Vector{T} # rotation velocitiy\n",
    "    wind_W::Vector{T} # wind\n",
    "    delta_t::T # simulation time step\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Extend the environment here.\n",
    "    # Everything you need additionaly in your environment also go in here.\n",
    "    # E.g. a trajectory\n",
    "\n",
    "    waypoints::Vector{Vector{T}} # waypoints\n",
    "    proximity_tolerance::T # proximity tolerance\n",
    "    v_min::T # minimum required velocity\n",
    "    v_max::T # maximum allowed velocity\n",
    "\n",
    "    ######################################################################\n",
    "end\n",
    "\n",
    "\n",
    "# define a keyword-based constructor for the type declared in the mutable struct typedef.\n",
    "# It could also be done with the macro Base.@kwdef.\n",
    "function VtolEnv(;\n",
    "    rng = Random.GLOBAL_RNG, # random number generation\n",
    "    name = \"vtol\",\n",
    "            visualization = false,\n",
    "    realtime = false,\n",
    "    kwargs...) # let the function take an arbitrary number of keyword arguments\n",
    "\n",
    "    T = Float64; # explicit type which is used e.g. in state. Cannot be altered due to the poor matrix defininon.\n",
    "    A = Space{Vector{ClosedInterval{T}}};\n",
    "\n",
    "    action_space = Space(\n",
    "        ClosedInterval{T}[\n",
    "            0.0..2.0, # propeller 1\n",
    "            0.0..2.0, # propeller 2\n",
    "            ],\n",
    "    ) # propeller 1 and 2\n",
    "\n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            ################################ TODO ################################\n",
    "            # Implement an observation space.\n",
    "            # Here is an example space. You can change it if desired.\n",
    "            # You have to extend it.\n",
    "            # Orientate yourself on the observation space from the paper.\n",
    "\n",
    "            typemin(T)..typemax(T), #1 previous position along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #2 previous position along z WORLD coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #3 current position along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #4 current position along z WORLD coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #5 orientation along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #6 orientation along z WORLD coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #7 velocity along x BODY coordinates\n",
    "            typemin(T)..typemax(T), #8 velocity along y BODY coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #9 rotational velocity along z BODY coordinates\n",
    "\n",
    "            #changed back to world for calculating guiding path easier\n",
    "            typemin(T)..typemax(T), #10 position of target along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #11 position of target along z WORLD coordinates\n",
    "\n",
    "            #changed so the drone knows the guiding path\n",
    "            typemin(T)..typemax(T), #12 position of previous WP along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #13 position of previous WP along z WORLD coordinates\n",
    "\n",
    "            ######################################################################\n",
    "            ],\n",
    "    )\n",
    "\n",
    "    if visualization #visualizes VTOL\n",
    "        create_VTOL(name, actuators = true, color_vec=[1.0; 1.0; 0.6; 1.0]);\n",
    "    end\n",
    "\n",
    "    environment = VtolEnv(\n",
    "        action_space, # action space\n",
    "        state_space, # observation space\n",
    "        zeros(T, length(state_space)), # current state space\n",
    "        rand(action_space), # initialization action\n",
    "        false, # episode done\n",
    "        0.0, # time\n",
    "        rng, # random number generator\n",
    "\n",
    "        name,\n",
    "        visualization,\n",
    "        realtime,\n",
    "\n",
    "        zeros(T, 3), # x_previous, previous position\n",
    "        zeros(T, 3), # x_W, current position\n",
    "        zeros(T, 3), # v_B, velocity\n",
    "        [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0], # R_W, current rotation\n",
    "        zeros(T, 3), # w_B\n",
    "        zeros(T, 3), # wind_W\n",
    "        T(0.02), # simulation time step\n",
    "\n",
    "        ################################## TODO ##################################\n",
    "        # Initialization everything you need additionaly in your environment here\n",
    "        SAMPLE_WAYPOINTS,\n",
    "        1e-5, # proximity tolerance\n",
    "        1.0, # minimum required velocity\n",
    "        20.0, # maximum allowed velocity\n",
    "        ##########################################################################\n",
    "    )\n",
    "\n",
    "    reset!(environment)\n",
    "    return environment\n",
    "end;\n",
    "\n",
    "methods(VtolEnv)\n",
    "\n",
    "\n",
    "# Just for explanation:\n",
    "# 1. A mutable Struct is created. A struct is a constructor and a constructor is a function that creates new objects.\n",
    "# 2. A outer keyword-based constructor method is added for the type declared in the mutable struct typedef before.'\n",
    "# So now we have a function with two methods. Julia will decide which method to call by multiple dispatch.\n",
    "\n",
    "## Define the RL interface\n",
    "\n",
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state\n",
    "\n",
    "\n",
    "function computeReward(env::VtolEnv{A,T}) where {A,T}\n",
    "    reward = 0.0\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Implement the reward function.\n",
    "    # Orientate on the paper.\n",
    "\n",
    "    # Hyperparameters\n",
    "    kp = 5.0;\n",
    "    kw = 0.5;\n",
    "    kwp = 25.0;\n",
    "    kv = 1.0;\n",
    "    # Stop perverse incentives\n",
    "    kb = 25.0;\n",
    "\n",
    "    # Gates and their length\n",
    "    gates = [[0.0, 0.0, 0.0], [env.state[10], 0.0, env.state[11]]];\n",
    "    n = length(gates);\n",
    "\n",
    "    # closest point on the guiding path phi\n",
    "    # its line-segment index lp\n",
    "    x_old = [env.state[1], 0.0, env.state[2]];\n",
    "    x_new = [env.state[3], 0.0, env.state[4]];\n",
    "    lp_old, phi_old = calculate_progress(gates, x_old);\n",
    "    lp_new, phi_new = calculate_progress(gates, x_new);\n",
    "\n",
    "    # previous time step spt_old\n",
    "    # current time step spt_new\n",
    "    spt_old = 0.0;\n",
    "    spt_new = 0.0;\n",
    "    for i in 1:(lp_old-1)\n",
    "        spt_old += (norm(gates[i+1] - gates[i]) + norm(phi_old - gates[lp_old]));\n",
    "    end\n",
    "    for i in 1:(lp_new-1)\n",
    "        spt_new += (norm(gates[i+1] - gates[i]) + norm(phi_new - gates[lp_old]));\n",
    "    end\n",
    "\n",
    "    # rogress reward rpt at time t is as a difference in reached\n",
    "    # distance between the current and previous time step\n",
    "    rpt = spt_new - spt_old\n",
    "    spt = spt_new\n",
    "\n",
    "    # The sum that is later goig to be the divisor\n",
    "    # for the reached distance reward\n",
    "    divisor_g = 0.0;\n",
    "    for i in 1:(n-1)\n",
    "        divisor_g += norm(gates[i+1] - gates[i]);\n",
    "    end\n",
    "\n",
    "    # reached distance reward ks\n",
    "    ks = 2 * env.v_max * env.delta_t / divisor_g;\n",
    "\n",
    "    # waypoint index wpi must be same as the index of the current line segment\n",
    "    wpi = lp_old + 1; #test\n",
    "    # distance to new waypoint dw\n",
    "    dwp = norm(env.x_W - gates[wpi]);\n",
    "    # tolerance for proximity to a waypoint\n",
    "    r_tol = env.proximity_tolerance;\n",
    "\n",
    "    # waypoint reward rwp\n",
    "    rwp = exp(-dwp/r_tol);\n",
    "\n",
    "    # no obstacles\n",
    "    collision = false;\n",
    "    # terminal reward rt\n",
    "    rt = collision ? -10 : 0;\n",
    "\n",
    "    # absolute velocity\n",
    "    v_vector = [env.state[7], env.state[8], 0.0]\n",
    "    v = norm(v_vector);\n",
    "    # rotation speed\n",
    "    w = abs(env.state[9]);\n",
    "    # distance from closes point on the guiding path\n",
    "    gd = norm(x_new - phi_new);\n",
    "    # max distance\n",
    "    dmax = 0.3;\n",
    "\n",
    "    # punishment for flying too damn fast\n",
    "    rv = max(0, v - v_expected); #changed not to punish slow flight\n",
    "\n",
    "    # Scaling factors\n",
    "    svmax = v > env.v_max ? 10^(env.v_max - v) : 1.0;\n",
    "    svmin = v < env.v_min ?  10^(v - env.v_min) : 1.0;\n",
    "    sgd = gd > dmax  ? exp(dmax - gd) : 1.0;\n",
    "\n",
    "    # added punishment for intentionally stopping the simulation\n",
    "    bad = max(0,\n",
    "        w + 1 - w_max,\n",
    "        0.2* (1 + floor_level - env.x_W[3]))  * (timeout - env.t)\n",
    "\n",
    "    # Ultimate scaling factor\n",
    "    s = svmax * svmin * sgd;\n",
    "\n",
    "    # Scaling the rewards\n",
    "    kp = s * kp;\n",
    "    ks = s * ks;\n",
    "\n",
    "    reward = kp * rpt + ks * spt + kwp * rwp + rt - kw * w - kv * rv - kb * bad;\n",
    "\n",
    "    ################################################################################################\n",
    "\n",
    "    return reward\n",
    "end\n",
    "\n",
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = computeReward(env)\n",
    "\n",
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    # Visualize initial state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, [0.0; 0.0; 0.0; 0.0]);\n",
    "    end\n",
    "\n",
    "    env.x_W = [0.0; 0.0; 0.0];\n",
    "    env.v_B = [0.0; 0.0; 0.0];\n",
    "    env.R_W = Matrix(UnitQuaternion(RotZ(-pi/2.0) * RotY(-pi/2.0) * RotX(pi)));\n",
    "\n",
    "    env.w_B = [0.0; 0.0; 0.0];\n",
    "    env.wind_W = [0.0; 0.0; 0.0];\n",
    "\n",
    "    env.t = 0.0;\n",
    "    env.action = [0.0, 0.0];\n",
    "    env.done = false;\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Reset environment.\n",
    "    # Is called if the training terminates\n",
    "    # (e.g. if drone crashes or successfully reaches point)\n",
    "    # HINT: Everything you added to your environment needs to be reseted.\n",
    "    #       Compare it with the initialization.\n",
    "\n",
    "    env.x_previous = [0.0; 0.0; 0.0]; # starting position\n",
    "    env.delta_t = T(0.02); # Δ time\n",
    "\n",
    "    env.waypoints = SAMPLE_WAYPOINTS;\n",
    "    env.proximity_tolerance = 1e-5;\n",
    "\n",
    "\n",
    "    # Visualize the waypoints\n",
    "    radius = 0.1;\n",
    "    visualize_waypoints(env.waypoints, radius);\n",
    "    ######################################################################\n",
    "\n",
    "    nothing\n",
    "end;\n",
    "\n",
    "# defines a methods for a callable object.\n",
    "# So when a VtolEnv object is created, it has this method that can be called\n",
    "function (env::VtolEnv)(a)\n",
    "    # set the propeller trust and the two flaps 2D case\n",
    "    # flaps set to 0.0\n",
    "    next_action = [a[1], a[2], 0.0, 0.0]\n",
    "\n",
    "    _step!(env, next_action)\n",
    "end\n",
    "\n",
    "env = VtolEnv();\n",
    "methods(env) # Just to explain which methods the object has\n",
    "\n",
    "\n",
    "function _step!(env::VtolEnv, next_action)\n",
    "# Update previous\n",
    "    env.x_previous = env.x_W;\n",
    "\n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(env.v_B, env.R_W, env.wind_W);\n",
    "\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = vtol_model(v_in_wind_B, next_action, eth_vtol_param);\n",
    "\n",
    "    # Limit to 2D\n",
    "    force_B[3] = 0.0; # Body Z\n",
    "    env.v_B[3] = 0.0;\n",
    "    torque_B[1] = 0.0;\n",
    "    torque_B[2] = 0.0;  # Body X and Y\n",
    "    env.w_B[1] = 0.0;\n",
    "    env.w_B[2] = 0.0;\n",
    "\n",
    "    # integrate rigid body dynamics for delta_t\n",
    "    env.x_W, env.v_B, env.R_W, env.w_B, time = rigid_body_simple(torque_B, force_B, env.x_W, env.v_B, env.R_W, env.w_B, env.t, env.delta_t, eth_vtol_param);\n",
    "\n",
    "    if env.realtime\n",
    "        sleep(env.delta_t); # just a dirty hack. this is of course slower than real time.\n",
    "    end\n",
    "\n",
    "    # Visualize the new state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, next_action);\n",
    "    end\n",
    "\n",
    "    env.t += env.delta_t\n",
    "\n",
    "    env.state[3] = env.x_W[1]; # position along x\n",
    "    env.state[4] = env.x_W[3]; # position along z\n",
    "\n",
    "    env.state[5] = env.R_W[1,1]; # orientation along x\n",
    "    env.state[6] = env.R_W[3,1]; # orientation along z\n",
    "\n",
    "    env.state[7] = env.v_B[1]; # velocity along x BODY coordinates\n",
    "    env.state[8] = env.v_B[2]; # velocity along y BODY coordinates\n",
    "\n",
    "    env.state[9] = env.w_B[3];  # rotational velocity along z BODY coordinates\n",
    "\n",
    "    ################################ TODO ################################\n",
    "\n",
    "    env.state[1] = env.x_previous[1]; # update previous x-coordinate\n",
    "    env.state[2] = env.x_previous[3]; # update previous z-coordinate\n",
    "\n",
    "    env.state[10] = env.waypoints[2][1] # position of target along x WORLD coordinates\n",
    "    env.state[11] = env.waypoints[2][3] # position of target along z WORLD coordinates\n",
    "\n",
    "    env.state[12] = env.waypoints[1][1] # position of target along x WORLD coordinates\n",
    "    env.state[13] = env.waypoints[1][3] # position of target along z WORLD coordinates\n",
    "\n",
    "    # maximum rotation speed\n",
    "\n",
    "    env.done =\n",
    "        norm(env.w_B) > w_max || # stop if body rate is too high\n",
    "        norm(env.v_B) > env.v_max || # stop if body is too fast\n",
    "        env.state[4] < floor_level ||\n",
    "        env.t > timeout ||\n",
    "        norm(env.waypoints[2] - env.x_W) < env.proximity_tolerance  # target reached\n",
    "    ######################################################################\n",
    "\n",
    "    nothing\n",
    "end;\n",
    "\n",
    "RLBase.test_runnable!(env)\n",
    "\n",
    "# changed to 10s (5s before) per point and 5.0m too far off path (2.0 before)\n",
    "# Show an overview of the environment.\n",
    "\n",
    "## Setup of a reinforcement learning experiment.\n",
    "\n",
    "seed = 123\n",
    "rng = StableRNG(seed)\n",
    "    N_ENV = 8\n",
    "    UPDATE_FREQ = 1024\n",
    "\n",
    "    vtol_envs = [\n",
    "        # use different names for the visualization\n",
    "        VtolEnv(; rng = StableRNG(hash(seed+i)), name = \"vtol$i\") for i in 1:N_ENV\n",
    "    ];\n",
    "    # define multiple environments for parallel training\n",
    "    env = MultiThreadEnv(vtol_envs)\n",
    "\n",
    "    # Define the function approximator\n",
    "    # (optional) TODO: change architecture\n",
    "    # TODO: research briefly what Actor Critic is\n",
    "    # (optional) TODO: change optimizer\n",
    "    # TODO: research what ADAM is\n",
    "    ns, na = length(state(env[1])), length(action_space(env[1]))\n",
    "    println(ns)\n",
    "    println(na)\n",
    "    approximator = ActorCritic(\n",
    "                #ns - number states as input\n",
    "                #3 layer; last layer splitted in mean and variance; then action is sampled\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                    Dense(ns, 16, relu; initW = glorot_uniform(rng)),#\n",
    "                    Dense(16, 16, relu; initW = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(Dense(16, na; initW = glorot_uniform(rng))),\n",
    "                    logσ = Chain(Dense(16, na; initW = glorot_uniform(rng))),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 16, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(16, 16, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(16, 1; initW = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(1e-3),\n",
    "            );\n",
    "\n",
    "        agent = Agent( # A wrapper of an AbstractPolicy\n",
    "        # AbstractPolicy: the policy to use\n",
    "        # (optional) TODO: change eventually\n",
    "        # TODO: research briefly what PPO is\n",
    "        policy = PPOPolicy(;\n",
    "                    approximator = approximator |> gpu,\n",
    "                    update_freq=UPDATE_FREQ,\n",
    "                    dist = Normal,\n",
    "                    # For parameters visit the docu: https://juliareinforcementlearning.org/docs/rlzoo/#ReinforcementLearningZoo.PPOPolicy\n",
    "                    ),\n",
    "\n",
    "        # AbstractTrajectory: used to store transitions between an agent and an environment source\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float64} => (ns, N_ENV),\n",
    "            action = Matrix{Float64} => (na, N_ENV),\n",
    "            action_log_prob = Vector{Float64} => (N_ENV,),\n",
    "            reward = Vector{Float64} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    );\n",
    "\n",
    "\n",
    "function saveModel(t, agent, env)\n",
    "    model = cpu(agent.policy.approximator)\n",
    "    f = joinpath(\"./RL_models_leo/\", \"vtol_2D_ppo_$t.bson\") # TODO: save model here\n",
    "    @save f model\n",
    "    println(\"parameters at step $t saved to $f\")\n",
    "end;\n",
    "\n",
    "function loadModel()\n",
    "    f = joinpath(\"./RL_models_leo/\", \"vtol_2D_ppo_1500000.bson\") # TODO: load model here\n",
    "    @load f model\n",
    "    return model\n",
    "end;\n",
    "\n",
    "function validate_policy(t, agent, env)\n",
    "    run(agent.policy, test_env, StopAfterEpisode(1), episode_test_reward_hook)\n",
    "    # the result of the hook\n",
    "    println(\"test reward at step $t: $(episode_test_reward_hook.rewards[end])\")\n",
    "\n",
    "end;\n",
    "\n",
    "episode_test_reward_hook = TotalRewardPerEpisode(;is_display_on_exit=false)\n",
    "# create a env only for reward test\n",
    "test_env = VtolEnv(;name = \"testVTOL\", visualization = true, realtime = true);\n",
    "\n",
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(1_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000),\n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.policy.approximator = loadModel();\n",
    "\n",
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(1_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000),\n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip200\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip200)\" d=\"\nM0 1600 L2400 1600 L2400 0 L0 0  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip201\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip200)\" d=\"\nM239.19 1486.45 L2352.76 1486.45 L2352.76 47.2441 L239.19 47.2441  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip202\">\n    <rect x=\"239\" y=\"47\" width=\"2115\" height=\"1440\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  285.626,1486.45 285.626,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  954.73,1486.45 954.73,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1623.83,1486.45 1623.83,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  2292.94,1486.45 2292.94,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  239.19,1486.45 2352.76,1486.45 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  285.626,1486.45 285.626,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  954.73,1486.45 954.73,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1623.83,1486.45 1623.83,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2292.94,1486.45 2292.94,1467.55 \n  \"/>\n<path clip-path=\"url(#clip200)\" d=\"M285.626 1517.37 Q282.015 1517.37 280.186 1520.93 Q278.381 1524.47 278.381 1531.6 Q278.381 1538.71 280.186 1542.27 Q282.015 1545.82 285.626 1545.82 Q289.26 1545.82 291.066 1542.27 Q292.895 1538.71 292.895 1531.6 Q292.895 1524.47 291.066 1520.93 Q289.26 1517.37 285.626 1517.37 M285.626 1513.66 Q291.436 1513.66 294.492 1518.27 Q297.571 1522.85 297.571 1531.6 Q297.571 1540.33 294.492 1544.94 Q291.436 1549.52 285.626 1549.52 Q279.816 1549.52 276.737 1544.94 Q273.682 1540.33 273.682 1531.6 Q273.682 1522.85 276.737 1518.27 Q279.816 1513.66 285.626 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M929.429 1514.29 L947.786 1514.29 L947.786 1518.22 L933.712 1518.22 L933.712 1526.7 Q934.73 1526.35 935.749 1526.19 Q936.767 1526 937.786 1526 Q943.573 1526 946.952 1529.17 Q950.332 1532.34 950.332 1537.76 Q950.332 1543.34 946.86 1546.44 Q943.388 1549.52 937.068 1549.52 Q934.892 1549.52 932.624 1549.15 Q930.378 1548.78 927.971 1548.04 L927.971 1543.34 Q930.054 1544.47 932.277 1545.03 Q934.499 1545.58 936.976 1545.58 Q940.98 1545.58 943.318 1543.48 Q945.656 1541.37 945.656 1537.76 Q945.656 1534.15 943.318 1532.04 Q940.98 1529.94 936.976 1529.94 Q935.101 1529.94 933.226 1530.35 Q931.374 1530.77 929.429 1531.65 L929.429 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M969.545 1517.37 Q965.934 1517.37 964.105 1520.93 Q962.3 1524.47 962.3 1531.6 Q962.3 1538.71 964.105 1542.27 Q965.934 1545.82 969.545 1545.82 Q973.179 1545.82 974.985 1542.27 Q976.813 1538.71 976.813 1531.6 Q976.813 1524.47 974.985 1520.93 Q973.179 1517.37 969.545 1517.37 M969.545 1513.66 Q975.355 1513.66 978.411 1518.27 Q981.489 1522.85 981.489 1531.6 Q981.489 1540.33 978.411 1544.94 Q975.355 1549.52 969.545 1549.52 Q963.735 1549.52 960.656 1544.94 Q957.6 1540.33 957.6 1531.6 Q957.6 1522.85 960.656 1518.27 Q963.735 1513.66 969.545 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1583.44 1544.91 L1591.08 1544.91 L1591.08 1518.55 L1582.77 1520.21 L1582.77 1515.95 L1591.03 1514.29 L1595.71 1514.29 L1595.71 1544.91 L1603.35 1544.91 L1603.35 1548.85 L1583.44 1548.85 L1583.44 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1622.79 1517.37 Q1619.18 1517.37 1617.35 1520.93 Q1615.55 1524.47 1615.55 1531.6 Q1615.55 1538.71 1617.35 1542.27 Q1619.18 1545.82 1622.79 1545.82 Q1626.43 1545.82 1628.23 1542.27 Q1630.06 1538.71 1630.06 1531.6 Q1630.06 1524.47 1628.23 1520.93 Q1626.43 1517.37 1622.79 1517.37 M1622.79 1513.66 Q1628.6 1513.66 1631.66 1518.27 Q1634.74 1522.85 1634.74 1531.6 Q1634.74 1540.33 1631.66 1544.94 Q1628.6 1549.52 1622.79 1549.52 Q1616.98 1549.52 1613.9 1544.94 Q1610.85 1540.33 1610.85 1531.6 Q1610.85 1522.85 1613.9 1518.27 Q1616.98 1513.66 1622.79 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1652.95 1517.37 Q1649.34 1517.37 1647.51 1520.93 Q1645.71 1524.47 1645.71 1531.6 Q1645.71 1538.71 1647.51 1542.27 Q1649.34 1545.82 1652.95 1545.82 Q1656.59 1545.82 1658.39 1542.27 Q1660.22 1538.71 1660.22 1531.6 Q1660.22 1524.47 1658.39 1520.93 Q1656.59 1517.37 1652.95 1517.37 M1652.95 1513.66 Q1658.76 1513.66 1661.82 1518.27 Q1664.9 1522.85 1664.9 1531.6 Q1664.9 1540.33 1661.82 1544.94 Q1658.76 1549.52 1652.95 1549.52 Q1647.14 1549.52 1644.07 1544.94 Q1641.01 1540.33 1641.01 1531.6 Q1641.01 1522.85 1644.07 1518.27 Q1647.14 1513.66 1652.95 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M2252.54 1544.91 L2260.18 1544.91 L2260.18 1518.55 L2251.87 1520.21 L2251.87 1515.95 L2260.14 1514.29 L2264.81 1514.29 L2264.81 1544.91 L2272.45 1544.91 L2272.45 1548.85 L2252.54 1548.85 L2252.54 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M2281.94 1514.29 L2300.3 1514.29 L2300.3 1518.22 L2286.23 1518.22 L2286.23 1526.7 Q2287.24 1526.35 2288.26 1526.19 Q2289.28 1526 2290.3 1526 Q2296.09 1526 2299.47 1529.17 Q2302.85 1532.34 2302.85 1537.76 Q2302.85 1543.34 2299.37 1546.44 Q2295.9 1549.52 2289.58 1549.52 Q2287.41 1549.52 2285.14 1549.15 Q2282.89 1548.78 2280.48 1548.04 L2280.48 1543.34 Q2282.57 1544.47 2284.79 1545.03 Q2287.01 1545.58 2289.49 1545.58 Q2293.49 1545.58 2295.83 1543.48 Q2298.17 1541.37 2298.17 1537.76 Q2298.17 1534.15 2295.83 1532.04 Q2293.49 1529.94 2289.49 1529.94 Q2287.61 1529.94 2285.74 1530.35 Q2283.89 1530.77 2281.94 1531.65 L2281.94 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M2322.06 1517.37 Q2318.45 1517.37 2316.62 1520.93 Q2314.81 1524.47 2314.81 1531.6 Q2314.81 1538.71 2316.62 1542.27 Q2318.45 1545.82 2322.06 1545.82 Q2325.69 1545.82 2327.5 1542.27 Q2329.33 1538.71 2329.33 1531.6 Q2329.33 1524.47 2327.5 1520.93 Q2325.69 1517.37 2322.06 1517.37 M2322.06 1513.66 Q2327.87 1513.66 2330.92 1518.27 Q2334 1522.85 2334 1531.6 Q2334 1540.33 2330.92 1544.94 Q2327.87 1549.52 2322.06 1549.52 Q2316.25 1549.52 2313.17 1544.94 Q2310.11 1540.33 2310.11 1531.6 Q2310.11 1522.85 2313.17 1518.27 Q2316.25 1513.66 2322.06 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  239.19,1426.11 2352.76,1426.11 \n  \"/>\n<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  239.19,1220.09 2352.76,1220.09 \n  \"/>\n<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  239.19,1014.07 2352.76,1014.07 \n  \"/>\n<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  239.19,808.049 2352.76,808.049 \n  \"/>\n<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  239.19,602.027 2352.76,602.027 \n  \"/>\n<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  239.19,396.005 2352.76,396.005 \n  \"/>\n<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  239.19,189.984 2352.76,189.984 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  239.19,1486.45 239.19,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  239.19,1426.11 258.088,1426.11 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  239.19,1220.09 258.088,1220.09 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  239.19,1014.07 258.088,1014.07 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  239.19,808.049 258.088,808.049 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  239.19,602.027 258.088,602.027 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  239.19,396.005 258.088,396.005 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  239.19,189.984 258.088,189.984 \n  \"/>\n<path clip-path=\"url(#clip200)\" d=\"M50.9921 1426.57 L80.6679 1426.57 L80.6679 1430.5 L50.9921 1430.5 L50.9921 1426.57 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M91.5706 1439.46 L99.2095 1439.46 L99.2095 1413.09 L90.8993 1414.76 L90.8993 1410.5 L99.1632 1408.83 L103.839 1408.83 L103.839 1439.46 L111.478 1439.46 L111.478 1443.39 L91.5706 1443.39 L91.5706 1439.46 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M119.742 1408.83 L141.964 1408.83 L141.964 1410.83 L129.418 1443.39 L124.533 1443.39 L136.339 1412.77 L119.742 1412.77 L119.742 1408.83 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M151.13 1408.83 L169.487 1408.83 L169.487 1412.77 L155.413 1412.77 L155.413 1421.24 Q156.431 1420.89 157.45 1420.73 Q158.468 1420.55 159.487 1420.55 Q165.274 1420.55 168.654 1423.72 Q172.033 1426.89 172.033 1432.31 Q172.033 1437.89 168.561 1440.99 Q165.089 1444.07 158.769 1444.07 Q156.593 1444.07 154.325 1443.7 Q152.08 1443.33 149.672 1442.58 L149.672 1437.89 Q151.755 1439.02 153.978 1439.58 Q156.2 1440.13 158.677 1440.13 Q162.681 1440.13 165.019 1438.02 Q167.357 1435.92 167.357 1432.31 Q167.357 1428.7 165.019 1426.59 Q162.681 1424.48 158.677 1424.48 Q156.802 1424.48 154.927 1424.9 Q153.075 1425.32 151.13 1426.2 L151.13 1408.83 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M191.246 1411.91 Q187.635 1411.91 185.806 1415.48 Q184.001 1419.02 184.001 1426.15 Q184.001 1433.26 185.806 1436.82 Q187.635 1440.36 191.246 1440.36 Q194.88 1440.36 196.686 1436.82 Q198.514 1433.26 198.514 1426.15 Q198.514 1419.02 196.686 1415.48 Q194.88 1411.91 191.246 1411.91 M191.246 1408.21 Q197.056 1408.21 200.112 1412.82 Q203.19 1417.4 203.19 1426.15 Q203.19 1434.88 200.112 1439.48 Q197.056 1444.07 191.246 1444.07 Q185.436 1444.07 182.357 1439.48 Q179.302 1434.88 179.302 1426.15 Q179.302 1417.4 182.357 1412.82 Q185.436 1408.21 191.246 1408.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M50.9921 1220.54 L80.6679 1220.54 L80.6679 1224.48 L50.9921 1224.48 L50.9921 1220.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M91.5706 1233.44 L99.2095 1233.44 L99.2095 1207.07 L90.8993 1208.74 L90.8993 1204.48 L99.1632 1202.81 L103.839 1202.81 L103.839 1233.44 L111.478 1233.44 L111.478 1237.37 L91.5706 1237.37 L91.5706 1233.44 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M120.969 1202.81 L139.325 1202.81 L139.325 1206.75 L125.251 1206.75 L125.251 1215.22 Q126.27 1214.87 127.288 1214.71 Q128.307 1214.53 129.325 1214.53 Q135.112 1214.53 138.492 1217.7 Q141.871 1220.87 141.871 1226.28 Q141.871 1231.86 138.399 1234.97 Q134.927 1238.04 128.607 1238.04 Q126.432 1238.04 124.163 1237.67 Q121.918 1237.3 119.51 1236.56 L119.51 1231.86 Q121.594 1233 123.816 1233.55 Q126.038 1234.11 128.515 1234.11 Q132.519 1234.11 134.857 1232 Q137.195 1229.9 137.195 1226.28 Q137.195 1222.67 134.857 1220.57 Q132.519 1218.46 128.515 1218.46 Q126.64 1218.46 124.765 1218.88 Q122.913 1219.29 120.969 1220.17 L120.969 1202.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M161.084 1205.89 Q157.473 1205.89 155.644 1209.46 Q153.839 1213 153.839 1220.13 Q153.839 1227.23 155.644 1230.8 Q157.473 1234.34 161.084 1234.34 Q164.718 1234.34 166.524 1230.8 Q168.353 1227.23 168.353 1220.13 Q168.353 1213 166.524 1209.46 Q164.718 1205.89 161.084 1205.89 M161.084 1202.19 Q166.894 1202.19 169.95 1206.79 Q173.029 1211.38 173.029 1220.13 Q173.029 1228.85 169.95 1233.46 Q166.894 1238.04 161.084 1238.04 Q155.274 1238.04 152.195 1233.46 Q149.14 1228.85 149.14 1220.13 Q149.14 1211.38 152.195 1206.79 Q155.274 1202.19 161.084 1202.19 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M191.246 1205.89 Q187.635 1205.89 185.806 1209.46 Q184.001 1213 184.001 1220.13 Q184.001 1227.23 185.806 1230.8 Q187.635 1234.34 191.246 1234.34 Q194.88 1234.34 196.686 1230.8 Q198.514 1227.23 198.514 1220.13 Q198.514 1213 196.686 1209.46 Q194.88 1205.89 191.246 1205.89 M191.246 1202.19 Q197.056 1202.19 200.112 1206.79 Q203.19 1211.38 203.19 1220.13 Q203.19 1228.85 200.112 1233.46 Q197.056 1238.04 191.246 1238.04 Q185.436 1238.04 182.357 1233.46 Q179.302 1228.85 179.302 1220.13 Q179.302 1211.38 182.357 1206.79 Q185.436 1202.19 191.246 1202.19 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M50.9921 1014.52 L80.6679 1014.52 L80.6679 1018.46 L50.9921 1018.46 L50.9921 1014.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M91.5706 1027.42 L99.2095 1027.42 L99.2095 1001.05 L90.8993 1002.72 L90.8993 998.458 L99.1632 996.791 L103.839 996.791 L103.839 1027.42 L111.478 1027.42 L111.478 1031.35 L91.5706 1031.35 L91.5706 1027.42 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M124.95 1027.42 L141.269 1027.42 L141.269 1031.35 L119.325 1031.35 L119.325 1027.42 Q121.987 1024.66 126.57 1020.03 Q131.177 1015.38 132.357 1014.04 Q134.603 1011.51 135.482 1009.78 Q136.385 1008.02 136.385 1006.33 Q136.385 1003.57 134.441 1001.84 Q132.519 1000.1 129.418 1000.1 Q127.219 1000.1 124.765 1000.87 Q122.334 1001.63 119.557 1003.18 L119.557 998.458 Q122.381 997.323 124.834 996.745 Q127.288 996.166 129.325 996.166 Q134.695 996.166 137.89 998.851 Q141.084 1001.54 141.084 1006.03 Q141.084 1008.16 140.274 1010.08 Q139.487 1011.98 137.381 1014.57 Q136.802 1015.24 133.7 1018.46 Q130.598 1021.65 124.95 1027.42 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M151.13 996.791 L169.487 996.791 L169.487 1000.73 L155.413 1000.73 L155.413 1009.2 Q156.431 1008.85 157.45 1008.69 Q158.468 1008.5 159.487 1008.5 Q165.274 1008.5 168.654 1011.68 Q172.033 1014.85 172.033 1020.26 Q172.033 1025.84 168.561 1028.94 Q165.089 1032.02 158.769 1032.02 Q156.593 1032.02 154.325 1031.65 Q152.08 1031.28 149.672 1030.54 L149.672 1025.84 Q151.755 1026.98 153.978 1027.53 Q156.2 1028.09 158.677 1028.09 Q162.681 1028.09 165.019 1025.98 Q167.357 1023.87 167.357 1020.26 Q167.357 1016.65 165.019 1014.55 Q162.681 1012.44 158.677 1012.44 Q156.802 1012.44 154.927 1012.86 Q153.075 1013.27 151.13 1014.15 L151.13 996.791 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M191.246 999.87 Q187.635 999.87 185.806 1003.43 Q184.001 1006.98 184.001 1014.11 Q184.001 1021.21 185.806 1024.78 Q187.635 1028.32 191.246 1028.32 Q194.88 1028.32 196.686 1024.78 Q198.514 1021.21 198.514 1014.11 Q198.514 1006.98 196.686 1003.43 Q194.88 999.87 191.246 999.87 M191.246 996.166 Q197.056 996.166 200.112 1000.77 Q203.19 1005.36 203.19 1014.11 Q203.19 1022.83 200.112 1027.44 Q197.056 1032.02 191.246 1032.02 Q185.436 1032.02 182.357 1027.44 Q179.302 1022.83 179.302 1014.11 Q179.302 1005.36 182.357 1000.77 Q185.436 996.166 191.246 996.166 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M50.9921 808.501 L80.6679 808.501 L80.6679 812.436 L50.9921 812.436 L50.9921 808.501 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M91.5706 821.394 L99.2095 821.394 L99.2095 795.028 L90.8993 796.695 L90.8993 792.436 L99.1632 790.769 L103.839 790.769 L103.839 821.394 L111.478 821.394 L111.478 825.329 L91.5706 825.329 L91.5706 821.394 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M130.922 793.848 Q127.311 793.848 125.482 797.413 Q123.677 800.954 123.677 808.084 Q123.677 815.19 125.482 818.755 Q127.311 822.297 130.922 822.297 Q134.556 822.297 136.362 818.755 Q138.191 815.19 138.191 808.084 Q138.191 800.954 136.362 797.413 Q134.556 793.848 130.922 793.848 M130.922 790.144 Q136.732 790.144 139.788 794.751 Q142.867 799.334 142.867 808.084 Q142.867 816.811 139.788 821.417 Q136.732 826 130.922 826 Q125.112 826 122.033 821.417 Q118.978 816.811 118.978 808.084 Q118.978 799.334 122.033 794.751 Q125.112 790.144 130.922 790.144 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M161.084 793.848 Q157.473 793.848 155.644 797.413 Q153.839 800.954 153.839 808.084 Q153.839 815.19 155.644 818.755 Q157.473 822.297 161.084 822.297 Q164.718 822.297 166.524 818.755 Q168.353 815.19 168.353 808.084 Q168.353 800.954 166.524 797.413 Q164.718 793.848 161.084 793.848 M161.084 790.144 Q166.894 790.144 169.95 794.751 Q173.029 799.334 173.029 808.084 Q173.029 816.811 169.95 821.417 Q166.894 826 161.084 826 Q155.274 826 152.195 821.417 Q149.14 816.811 149.14 808.084 Q149.14 799.334 152.195 794.751 Q155.274 790.144 161.084 790.144 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M191.246 793.848 Q187.635 793.848 185.806 797.413 Q184.001 800.954 184.001 808.084 Q184.001 815.19 185.806 818.755 Q187.635 822.297 191.246 822.297 Q194.88 822.297 196.686 818.755 Q198.514 815.19 198.514 808.084 Q198.514 800.954 196.686 797.413 Q194.88 793.848 191.246 793.848 M191.246 790.144 Q197.056 790.144 200.112 794.751 Q203.19 799.334 203.19 808.084 Q203.19 816.811 200.112 821.417 Q197.056 826 191.246 826 Q185.436 826 182.357 821.417 Q179.302 816.811 179.302 808.084 Q179.302 799.334 182.357 794.751 Q185.436 790.144 191.246 790.144 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M81.154 602.479 L110.83 602.479 L110.83 606.414 L81.154 606.414 L81.154 602.479 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M119.742 584.747 L141.964 584.747 L141.964 586.738 L129.418 619.307 L124.533 619.307 L136.339 588.682 L119.742 588.682 L119.742 584.747 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M151.13 584.747 L169.487 584.747 L169.487 588.682 L155.413 588.682 L155.413 597.155 Q156.431 596.807 157.45 596.645 Q158.468 596.46 159.487 596.46 Q165.274 596.46 168.654 599.631 Q172.033 602.803 172.033 608.219 Q172.033 613.798 168.561 616.9 Q165.089 619.979 158.769 619.979 Q156.593 619.979 154.325 619.608 Q152.08 619.238 149.672 618.497 L149.672 613.798 Q151.755 614.932 153.978 615.488 Q156.2 616.043 158.677 616.043 Q162.681 616.043 165.019 613.937 Q167.357 611.83 167.357 608.219 Q167.357 604.608 165.019 602.502 Q162.681 600.395 158.677 600.395 Q156.802 600.395 154.927 600.812 Q153.075 601.229 151.13 602.108 L151.13 584.747 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M191.246 587.826 Q187.635 587.826 185.806 591.391 Q184.001 594.932 184.001 602.062 Q184.001 609.168 185.806 612.733 Q187.635 616.275 191.246 616.275 Q194.88 616.275 196.686 612.733 Q198.514 609.168 198.514 602.062 Q198.514 594.932 196.686 591.391 Q194.88 587.826 191.246 587.826 M191.246 584.122 Q197.056 584.122 200.112 588.729 Q203.19 593.312 203.19 602.062 Q203.19 610.789 200.112 615.395 Q197.056 619.979 191.246 619.979 Q185.436 619.979 182.357 615.395 Q179.302 610.789 179.302 602.062 Q179.302 593.312 182.357 588.729 Q185.436 584.122 191.246 584.122 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M81.154 396.457 L110.83 396.457 L110.83 400.392 L81.154 400.392 L81.154 396.457 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M120.969 378.725 L139.325 378.725 L139.325 382.661 L125.251 382.661 L125.251 391.133 Q126.27 390.786 127.288 390.624 Q128.307 390.438 129.325 390.438 Q135.112 390.438 138.492 393.61 Q141.871 396.781 141.871 402.198 Q141.871 407.776 138.399 410.878 Q134.927 413.957 128.607 413.957 Q126.432 413.957 124.163 413.586 Q121.918 413.216 119.51 412.475 L119.51 407.776 Q121.594 408.91 123.816 409.466 Q126.038 410.022 128.515 410.022 Q132.519 410.022 134.857 407.915 Q137.195 405.809 137.195 402.198 Q137.195 398.586 134.857 396.48 Q132.519 394.374 128.515 394.374 Q126.64 394.374 124.765 394.79 Q122.913 395.207 120.969 396.086 L120.969 378.725 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M161.084 381.804 Q157.473 381.804 155.644 385.369 Q153.839 388.911 153.839 396.04 Q153.839 403.147 155.644 406.711 Q157.473 410.253 161.084 410.253 Q164.718 410.253 166.524 406.711 Q168.353 403.147 168.353 396.04 Q168.353 388.911 166.524 385.369 Q164.718 381.804 161.084 381.804 M161.084 378.1 Q166.894 378.1 169.95 382.707 Q173.029 387.29 173.029 396.04 Q173.029 404.767 169.95 409.373 Q166.894 413.957 161.084 413.957 Q155.274 413.957 152.195 409.373 Q149.14 404.767 149.14 396.04 Q149.14 387.29 152.195 382.707 Q155.274 378.1 161.084 378.1 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M191.246 381.804 Q187.635 381.804 185.806 385.369 Q184.001 388.911 184.001 396.04 Q184.001 403.147 185.806 406.711 Q187.635 410.253 191.246 410.253 Q194.88 410.253 196.686 406.711 Q198.514 403.147 198.514 396.04 Q198.514 388.911 196.686 385.369 Q194.88 381.804 191.246 381.804 M191.246 378.1 Q197.056 378.1 200.112 382.707 Q203.19 387.29 203.19 396.04 Q203.19 404.767 200.112 409.373 Q197.056 413.957 191.246 413.957 Q185.436 413.957 182.357 409.373 Q179.302 404.767 179.302 396.04 Q179.302 387.29 182.357 382.707 Q185.436 378.1 191.246 378.1 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M81.154 190.435 L110.83 190.435 L110.83 194.37 L81.154 194.37 L81.154 190.435 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M124.95 203.328 L141.269 203.328 L141.269 207.264 L119.325 207.264 L119.325 203.328 Q121.987 200.574 126.57 195.944 Q131.177 191.291 132.357 189.949 Q134.603 187.426 135.482 185.69 Q136.385 183.93 136.385 182.241 Q136.385 179.486 134.441 177.75 Q132.519 176.014 129.418 176.014 Q127.219 176.014 124.765 176.778 Q122.334 177.542 119.557 179.092 L119.557 174.37 Q122.381 173.236 124.834 172.657 Q127.288 172.079 129.325 172.079 Q134.695 172.079 137.89 174.764 Q141.084 177.449 141.084 181.94 Q141.084 184.069 140.274 185.991 Q139.487 187.889 137.381 190.481 Q136.802 191.153 133.7 194.37 Q130.598 197.565 124.95 203.328 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M151.13 172.704 L169.487 172.704 L169.487 176.639 L155.413 176.639 L155.413 185.111 Q156.431 184.764 157.45 184.602 Q158.468 184.417 159.487 184.417 Q165.274 184.417 168.654 187.588 Q172.033 190.759 172.033 196.176 Q172.033 201.754 168.561 204.856 Q165.089 207.935 158.769 207.935 Q156.593 207.935 154.325 207.565 Q152.08 207.194 149.672 206.453 L149.672 201.754 Q151.755 202.889 153.978 203.444 Q156.2 204 158.677 204 Q162.681 204 165.019 201.893 Q167.357 199.787 167.357 196.176 Q167.357 192.565 165.019 190.458 Q162.681 188.352 158.677 188.352 Q156.802 188.352 154.927 188.768 Q153.075 189.185 151.13 190.065 L151.13 172.704 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M191.246 175.782 Q187.635 175.782 185.806 179.347 Q184.001 182.889 184.001 190.018 Q184.001 197.125 185.806 200.69 Q187.635 204.231 191.246 204.231 Q194.88 204.231 196.686 200.69 Q198.514 197.125 198.514 190.018 Q198.514 182.889 196.686 179.347 Q194.88 175.782 191.246 175.782 M191.246 172.079 Q197.056 172.079 200.112 176.685 Q203.19 181.268 203.19 190.018 Q203.19 198.745 200.112 203.352 Q197.056 207.935 191.246 207.935 Q185.436 207.935 182.357 203.352 Q179.302 198.745 179.302 190.018 Q179.302 181.268 182.357 176.685 Q185.436 172.079 191.246 172.079 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip202)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  299.008,970.668 312.39,839.985 325.772,1011.01 339.155,406.591 352.537,652.225 365.919,385.044 379.301,1085.79 392.683,400.75 406.065,640.452 419.447,1301.81 \n  432.829,861.895 446.211,802.566 459.593,699.884 472.975,631.552 486.357,494.712 499.739,561.651 513.122,768.641 526.504,442.437 539.886,883.341 553.268,686.997 \n  566.65,235.945 580.032,986.156 593.414,463.832 606.796,235.99 620.178,499.023 633.56,232.417 646.942,345.775 660.324,223.935 673.706,239.253 687.089,228.971 \n  700.471,222.373 713.853,322.273 727.235,535.68 740.617,226.037 753.999,218.62 767.381,225.939 780.763,211.218 794.145,238.622 807.527,224.809 820.909,215.962 \n  834.291,230.363 847.674,241.034 861.056,228.616 874.438,333.456 887.82,236.039 901.202,236.447 914.584,285.296 927.966,220.741 941.348,219.497 954.73,220.684 \n  968.112,230.819 981.494,221.929 994.876,238.947 1008.26,270.882 1021.64,219.106 1035.02,221.815 1048.4,232.906 1061.79,221.445 1075.17,225.803 1088.55,236.376 \n  1101.93,242.398 1115.32,235.883 1128.7,225.653 1142.08,224.474 1155.46,428.957 1168.84,256.092 1182.23,227.976 1195.61,255.763 1208.99,228.92 1222.37,287.749 \n  1235.75,497.861 1249.14,347.027 1262.52,317.273 1275.9,252.31 1289.28,300.167 1302.66,238.222 1316.05,269.992 1329.43,236.93 1342.81,254.117 1356.19,281.271 \n  1369.57,301.372 1382.96,218.295 1396.34,223.134 1409.72,788.001 1423.1,231.66 1436.48,214.449 1449.87,225.665 1463.25,291.88 1476.63,275.316 1490.01,220.495 \n  1503.4,215.909 1516.78,256.708 1530.16,224.219 1543.54,225.773 1556.92,224.693 1570.31,230.643 1583.69,225.992 1597.07,224.212 1610.45,226.36 1623.83,1142.16 \n  1637.22,229.326 1650.6,221.716 1663.98,230.224 1677.36,282.643 1690.74,231.263 1704.13,231.083 1717.51,1445.72 1730.89,1227.37 1744.27,221.162 1757.65,223.403 \n  1771.04,804.128 1784.42,227.304 1797.8,217.798 1811.18,808.836 1824.57,224.016 1837.95,223.938 1851.33,231.613 1864.71,222.845 1878.09,234.883 1891.48,224.769 \n  1904.86,589.106 1918.24,215.056 1931.62,218.694 1945,212.772 1958.39,221.781 1971.77,219.501 1985.15,865.603 1998.53,211.211 2011.91,215.575 2025.3,217.535 \n  2038.68,213.189 2052.06,218.742 2065.44,220.539 2078.82,212.028 2092.21,205.965 2105.59,213.542 2118.97,199.226 2132.35,202.181 2145.74,186.915 2159.12,151.589 \n  2172.5,132.063 2185.88,123.674 2199.26,121.883 2212.65,119.151 2226.03,107.954 2239.41,101.338 2252.79,96.523 2266.17,89.746 2279.56,87.9763 2292.94,95.1588 \n  \n  \"/>\n<path clip-path=\"url(#clip200)\" d=\"\nM2018.52 1438.47 L2282.3 1438.47 L2282.3 1334.79 L2018.52 1334.79  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2018.52,1438.47 2282.3,1438.47 2282.3,1334.79 2018.52,1334.79 2018.52,1438.47 \n  \"/>\n<polyline clip-path=\"url(#clip200)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2042,1386.63 2182.91,1386.63 \n  \"/>\n<path clip-path=\"url(#clip200)\" d=\"M2220.23 1406.32 Q2218.43 1410.95 2216.71 1412.36 Q2215 1413.78 2212.13 1413.78 L2208.73 1413.78 L2208.73 1410.21 L2211.23 1410.21 Q2212.99 1410.21 2213.96 1409.38 Q2214.93 1408.54 2216.11 1405.44 L2216.88 1403.5 L2206.39 1377.99 L2210.9 1377.99 L2219.01 1398.27 L2227.11 1377.99 L2231.62 1377.99 L2220.23 1406.32 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M2238.91 1399.98 L2246.55 1399.98 L2246.55 1373.61 L2238.24 1375.28 L2238.24 1371.02 L2246.5 1369.35 L2251.18 1369.35 L2251.18 1399.98 L2258.82 1399.98 L2258.82 1403.91 L2238.91 1403.91 L2238.91 1399.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plot the stuff\n",
    "plot(episode_test_reward_hook.rewards)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "close_visualization(); # closes the MeshCat visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
