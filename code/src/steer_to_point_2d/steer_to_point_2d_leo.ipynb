{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1m┌ \u001B[22m\u001B[39m\u001B[36m\u001B[1mInfo: \u001B[22m\u001B[39mMeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "\u001B[36m\u001B[1m└ \u001B[22m\u001B[39mhttp://127.0.0.1:8700\n"
     ]
    }
   ],
   "source": [
    "## Init Bionic VTOL\n",
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position\n",
    "\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;\n",
    "using Distributions;\n",
    "\n",
    "using Plots;\n",
    "using Statistics;\n",
    "\n",
    "using BSON: @save, @load # save mode\n",
    "create_visualization();\n",
    "\n",
    "# indicates how many threads Julia was started with. This is important for the multi-threaded environment\n",
    "Threads.nthreads()\n",
    "### Create Reinforcement Learning Environment\n",
    "\n",
    "\n",
    "################################ TODO ################################\n",
    "# You can initialization global constants here.\n",
    "# E.g. a fixed point in the beginning of training (for testing/overfitting)\n",
    "# Define global constants for initial position and rotation\n",
    "\n",
    "#####\n",
    "##### first coordinate - red axis - x\n",
    "##### second coordinate - green axis - y\n",
    "##### third coordinate - blue axis - z\n",
    "#####\n",
    "\n",
    "const NUM_WAYPOINTS = 2;\n",
    "const INITIAL_POSITION = [0.0, 0.0, 0.0];\n",
    "const INITIAL_ROTATION = [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0];\n",
    "const SAMPLE_WAYPOINTS = [[0.0, 0.0, 0.0], [-10.0, 0.0, 5.0]];\n",
    "\n",
    "w_max = 25.0; # maximum rotational speed before getting punished\n",
    "timeout = 15.0; # simulation end time\n",
    "floor_level = -10.0; # as in aviation\n",
    "v_expected = 3.0; # maximum speed before getting punished\n",
    "\n",
    "######################################################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[1mTest Summary:              | \u001B[22m\u001B[32m\u001B[1mPass  \u001B[22m\u001B[39m\u001B[36m\u001B[1mTotal  \u001B[22m\u001B[39m\u001B[0m\u001B[1mTime\u001B[22m\n",
      "random policy with VtolEnv | \u001B[32m2000  \u001B[39m\u001B[36m 2000  \u001B[39m\u001B[0m1.1s\n",
      "13\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1m┌ \u001B[22m\u001B[39m\u001B[36m\u001B[1mInfo: \u001B[22m\u001B[39mThe GPU function is being called but the GPU is not accessible. \n",
      "\u001B[36m\u001B[1m└ \u001B[22m\u001B[39mDefaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "\u001B[32mProgress:   1%|▎                                        |  ETA: 1:27:30\u001B[39mm9m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 10000: -1197.3325044227252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   1%|▌                                        |  ETA: 0:50:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 20000: -1038.7529508396442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   2%|▊                                        |  ETA: 0:37:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 30000: -1246.2829955078248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   2%|█                                        |  ETA: 0:30:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 40000: -512.8447001673078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   3%|█▎                                       |  ETA: 0:26:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 50000: -810.9132105775715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   4%|█▌                                       |  ETA: 0:23:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 60000: -486.6981606521489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   5%|█▉                                       |  ETA: 0:21:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 70000: -1337.0246386182575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   5%|██▎                                      |  ETA: 0:20:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 80000: -505.7576277216737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   6%|██▍                                      |  ETA: 0:18:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 90000: -796.6275399345215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   6%|██▋                                      |  ETA: 0:18:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 100000 saved to ./RL_models_leo/vtol_2D_ppo_100000.bson\n",
      "test reward at step 100000: -1599.157016475404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   7%|██▉                                      |  ETA: 0:18:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 110000: -1065.3396966569037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   8%|███▎                                     |  ETA: 0:17:22\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 120000: -993.3467525948479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   9%|███▌                                     |  ETA: 0:16:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 130000: -868.7459682443944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   9%|███▋                                     |  ETA: 0:17:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 140000: -785.8268964929946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  10%|████                                     |  ETA: 0:16:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 150000: -619.7765239427064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  11%|████▍                                    |  ETA: 0:16:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 160000: -701.0046956373168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  11%|████▋                                    |  ETA: 0:16:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 170000: -952.1791522386694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  12%|████▉                                    |  ETA: 0:18:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 180000: -556.3426254486329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  12%|█████▏                                   |  ETA: 0:17:40\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 190000: -1091.3635393211264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  13%|█████▍                                   |  ETA: 0:18:35\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 200000 saved to ./RL_models_leo/vtol_2D_ppo_200000.bson\n",
      "test reward at step 200000: -853.1074952868696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  14%|█████▋                                   |  ETA: 0:19:13\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 210000: -305.7729248726722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  15%|██████                                   |  ETA: 0:19:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 220000: -1216.1264451583263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  15%|██████▏                                  |  ETA: 0:20:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 230000: -582.3048781811934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  16%|██████▌                                  |  ETA: 0:20:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 240000: -305.82752433729496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  17%|██████▊                                  |  ETA: 0:21:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 250000: -625.007725755052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  17%|███████▏                                 |  ETA: 0:21:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 260000: -301.4917257224193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  18%|███████▎                                 |  ETA: 0:22:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 270000: -439.0474593939486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  18%|███████▋                                 |  ETA: 0:22:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 280000: -291.1990764105893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  19%|███████▉                                 |  ETA: 0:22:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 290000: -309.78684856498944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  20%|████████                                 |  ETA: 0:23:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 300000 saved to ./RL_models_leo/vtol_2D_ppo_300000.bson\n",
      "test reward at step 300000: -297.3097718332196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  20%|████████▍                                |  ETA: 0:23:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 310000: -289.3037521006822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  21%|████████▋                                |  ETA: 0:23:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 320000: -410.52883492483954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  22%|█████████                                |  ETA: 0:23:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 330000: -669.4900395189534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  22%|█████████▏                               |  ETA: 0:23:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 340000: -293.74922902351034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  23%|█████████▌                               |  ETA: 0:23:40\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 350000: -284.74862530369666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  24%|█████████▊                               |  ETA: 0:23:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 360000: -293.6299949683434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  25%|██████████▏                              |  ETA: 0:23:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 370000: -275.76767050738925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  25%|██████████▍                              |  ETA: 0:24:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 380000: -309.020318694461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  26%|██████████▌                              |  ETA: 0:24:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 390000: -292.2594225864156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  26%|██████████▉                              |  ETA: 0:24:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 400000 saved to ./RL_models_leo/vtol_2D_ppo_400000.bson\n",
      "test reward at step 400000: -281.52386239200706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  27%|███████████▏                             |  ETA: 0:24:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 410000: -298.9992897056305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  28%|███████████▌                             |  ETA: 0:23:55\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 420000: -311.9471675992724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  29%|███████████▊                             |  ETA: 0:24:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 430000: -296.87891608674477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  29%|███████████▉                             |  ETA: 0:24:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 440000: -424.0984039241801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  30%|████████████▎                            |  ETA: 0:24:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 450000: -305.8866932546402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  31%|████████████▌                            |  ETA: 0:23:54\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 460000: -306.3811357550596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  31%|████████████▉                            |  ETA: 0:23:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 470000: -365.6583728829827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  32%|█████████████                            |  ETA: 0:23:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 480000: -287.3227330115013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  32%|█████████████▎                           |  ETA: 0:23:47\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 490000: -285.81378302744116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  33%|█████████████▋                           |  ETA: 0:23:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 500000 saved to ./RL_models_leo/vtol_2D_ppo_500000.bson\n",
      "test reward at step 500000: -287.2533245313659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  34%|█████████████▉                           |  ETA: 0:23:25\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 510000: -299.55208530978325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  35%|██████████████▎                          |  ETA: 0:23:47\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 520000: -288.76409930319505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  35%|██████████████▍                          |  ETA: 0:23:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 530000: -309.4157944055943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  36%|██████████████▋                          |  ETA: 0:23:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 540000: -348.1673438892387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  37%|███████████████                          |  ETA: 0:23:03\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 550000: -285.3389654396265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  37%|███████████████▎                         |  ETA: 0:22:50\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 560000: -288.626444347949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  38%|███████████████▌                         |  ETA: 0:22:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 570000: -302.0847876460862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  38%|███████████████▊                         |  ETA: 0:22:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 580000: -288.17687977988743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  39%|████████████████▏                        |  ETA: 0:22:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 590000: -293.46570326840134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  40%|████████████████▍                        |  ETA: 0:22:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 600000 saved to ./RL_models_leo/vtol_2D_ppo_600000.bson\n",
      "test reward at step 600000: -306.2957473303757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  40%|████████████████▌                        |  ETA: 0:22:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 610000: -313.60309991618107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  41%|████████████████▉                        |  ETA: 0:22:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 620000: -305.6976008393142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  42%|█████████████████▏                       |  ETA: 0:21:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 630000: -293.28354921464773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  43%|█████████████████▌                       |  ETA: 0:21:35\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 640000: -291.85322086933473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  43%|█████████████████▋                       |  ETA: 0:21:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 650000: -539.9859798490806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  44%|██████████████████                       |  ETA: 0:21:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 660000: -330.2203147996896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  45%|██████████████████▎                      |  ETA: 0:21:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 670000: -296.10276849605594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  45%|██████████████████▌                      |  ETA: 0:20:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 680000: -329.8205345653035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  46%|██████████████████▊                      |  ETA: 0:20:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 690000: -297.24732247682607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  46%|███████████████████                      |  ETA: 0:20:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 700000 saved to ./RL_models_leo/vtol_2D_ppo_700000.bson\n",
      "test reward at step 700000: -368.634642900835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  47%|███████████████████▍                     |  ETA: 0:20:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 710000: -623.5983668476264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  48%|███████████████████▋                     |  ETA: 0:20:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 720000: -440.5660626795307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  48%|███████████████████▉                     |  ETA: 0:19:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 730000: -404.4614084421256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  49%|████████████████████▏                    |  ETA: 0:19:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 740000: -325.6309808656399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  50%|████████████████████▌                    |  ETA: 0:19:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 750000: -383.70380413781123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  51%|████████████████████▊                    |  ETA: 0:19:10\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 760000: -308.5358217008225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  51%|████████████████████▉                    |  ETA: 0:19:10\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 770000: -347.0874097526751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  52%|█████████████████████▎                   |  ETA: 0:18:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 780000: -306.96794708073867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  53%|█████████████████████▋                   |  ETA: 0:18:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 790000: -327.82318044659223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  53%|█████████████████████▊                   |  ETA: 0:18:32\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 800000 saved to ./RL_models_leo/vtol_2D_ppo_800000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  53%|█████████████████████▉                   |  ETA: 0:18:30\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 800000: -360.77410992826043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  54%|██████████████████████                   |  ETA: 0:18:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 810000: -385.16540807058493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  55%|██████████████████████▍                  |  ETA: 0:17:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 820000: -284.3547148959763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  55%|██████████████████████▋                  |  ETA: 0:17:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 830000: -290.2267982916173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  56%|██████████████████████▉                  |  ETA: 0:17:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 840000: -975.6726507421355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  56%|███████████████████████▏                 |  ETA: 0:17:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 850000: -300.5723149290503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  57%|███████████████████████▌                 |  ETA: 0:17:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 860000: -279.6882836761858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  58%|███████████████████████▊                 |  ETA: 0:16:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 870000: -293.2979867821219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  58%|███████████████████████▉                 |  ETA: 0:16:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 880000: -373.646996810062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  59%|████████████████████████▎                |  ETA: 0:16:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 890000: -353.547255334514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  60%|████████████████████████▋                |  ETA: 0:16:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 900000 saved to ./RL_models_leo/vtol_2D_ppo_900000.bson\n",
      "test reward at step 900000: -287.0245633586159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  60%|████████████████████████▊                |  ETA: 0:15:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 910000: -281.4599163526231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  61%|█████████████████████████                |  ETA: 0:15:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 920000: -330.9677013464277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  62%|█████████████████████████▍               |  ETA: 0:15:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 930000: -291.54325849907025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  63%|█████████████████████████▋               |  ETA: 0:15:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 940000: -293.4289638695467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  63%|█████████████████████████▉               |  ETA: 0:14:58\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 950000: -292.1183606837019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  64%|██████████████████████████▏              |  ETA: 0:14:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 960000: -299.33925055744015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  64%|██████████████████████████▍              |  ETA: 0:14:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 970000: -293.69507915721033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  65%|██████████████████████████▊              |  ETA: 0:14:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 980000: -291.5350641727026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  66%|███████████████████████████              |  ETA: 0:13:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 990000: -294.14107430740586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  66%|███████████████████████████▏             |  ETA: 0:13:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1000000 saved to ./RL_models_leo/vtol_2D_ppo_1000000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  67%|███████████████████████████▍             |  ETA: 0:13:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1000000: -1405.4282010464915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  67%|███████████████████████████▌             |  ETA: 0:13:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1010000: -297.7400400847716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  68%|███████████████████████████▊             |  ETA: 0:13:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1020000: -288.5057541149078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  69%|████████████████████████████▏            |  ETA: 0:12:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1030000: -298.82980443771936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  69%|████████████████████████████▍            |  ETA: 0:12:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1040000: -362.4382054740018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  70%|████████████████████████████▋            |  ETA: 0:12:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1050000: -300.0905263195922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  70%|████████████████████████████▉            |  ETA: 0:12:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1060000: -299.8725757319008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  71%|█████████████████████████████▎           |  ETA: 0:11:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1070000: -1773.7851517962408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  72%|█████████████████████████████▌           |  ETA: 0:11:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1080000: -1508.8248101645356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  73%|█████████████████████████████▊           |  ETA: 0:11:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1090000: -287.8332229026755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  73%|██████████████████████████████           |  ETA: 0:11:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1100000 saved to ./RL_models_leo/vtol_2D_ppo_1100000.bson\n",
      "test reward at step 1100000: -290.5534518604674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  74%|██████████████████████████████▎          |  ETA: 0:10:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1110000: -995.2420076668521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  75%|██████████████████████████████▋          |  ETA: 0:10:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1120000: -295.28705669837296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  75%|██████████████████████████████▉          |  ETA: 0:10:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1130000: -283.7519338522494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  76%|███████████████████████████████          |  ETA: 0:10:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1140000: -1000.9546384411178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  76%|███████████████████████████████▍         |  ETA: 0:09:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1150000: -291.29726189029253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  77%|███████████████████████████████▋         |  ETA: 0:09:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1160000: -291.20210798221524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  78%|████████████████████████████████         |  ETA: 0:09:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1170000: -300.5153421182234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  79%|████████████████████████████████▎        |  ETA: 0:08:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1180000: -289.8766243415815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  79%|████████████████████████████████▍        |  ETA: 0:08:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1190000: -304.48347319475704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  80%|████████████████████████████████▊        |  ETA: 0:08:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1200000 saved to ./RL_models_leo/vtol_2D_ppo_1200000.bson\n",
      "test reward at step 1200000: -292.2104413438931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  81%|█████████████████████████████████        |  ETA: 0:07:58\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1210000: -734.3202119929924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  81%|█████████████████████████████████▎       |  ETA: 0:07:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1220000: -280.4239428878118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  82%|█████████████████████████████████▌       |  ETA: 0:07:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1230000: -284.83878709680295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  82%|█████████████████████████████████▊       |  ETA: 0:07:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1240000: -277.65275864969976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  83%|██████████████████████████████████▏      |  ETA: 0:06:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1250000: -288.58467598142494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  84%|██████████████████████████████████▍      |  ETA: 0:06:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1260000: -285.8182711894928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  85%|██████████████████████████████████▊      |  ETA: 0:06:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1270000: -1069.8390460129192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  85%|██████████████████████████████████▉      |  ETA: 0:06:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1280000: -275.75853331197715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  86%|███████████████████████████████████▏     |  ETA: 0:05:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1290000: -281.05412512008724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  87%|███████████████████████████████████▌     |  ETA: 0:05:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1300000 saved to ./RL_models_leo/vtol_2D_ppo_1300000.bson\n",
      "test reward at step 1300000: -283.43256272472036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  87%|███████████████████████████████████▊     |  ETA: 0:05:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1310000: -278.15828388291544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  88%|████████████████████████████████████     |  ETA: 0:05:07\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1320000: -284.8967622160238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  88%|████████████████████████████████████▎    |  ETA: 0:04:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1330000: -287.07775334906836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  89%|████████████████████████████████████▌    |  ETA: 0:04:30\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1340000: -276.75053134282547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  90%|████████████████████████████████████▉    |  ETA: 0:04:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1350000: -269.3930960721547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  91%|█████████████████████████████████████▏   |  ETA: 0:03:54\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1360000: -278.5873559647574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  91%|█████████████████████████████████████▍   |  ETA: 0:03:43\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1370000: -261.214736433941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  92%|█████████████████████████████████████▋   |  ETA: 0:03:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1380000: -264.8013814956391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  93%|██████████████████████████████████████   |  ETA: 0:03:05\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1390000: -246.27574247664242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  93%|██████████████████████████████████████▏  |  ETA: 0:02:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1400000 saved to ./RL_models_leo/vtol_2D_ppo_1400000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  93%|██████████████████████████████████████▎  |  ETA: 0:02:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1400000: -203.40915289291127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  94%|██████████████████████████████████████▍  |  ETA: 0:02:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1410000: -179.71581034679247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  95%|██████████████████████████████████████▊  |  ETA: 0:02:18\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1420000: -169.53532624863948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  95%|███████████████████████████████████████  |  ETA: 0:01:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1430000: -167.36192490721754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  96%|███████████████████████████████████████▍ |  ETA: 0:01:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1440000: -164.04741925011209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  96%|███████████████████████████████████████▌ |  ETA: 0:01:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1450000: -150.4595605411987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  97%|███████████████████████████████████████▉ |  ETA: 0:01:12\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1460000: -142.43224749535142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  98%|████████████████████████████████████████▏|  ETA: 0:00:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1470000: -136.58891248924556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  99%|████████████████████████████████████████▌|  ETA: 0:00:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1480000: -128.3653464157472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  99%|████████████████████████████████████████▋|  ETA: 0:00:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1490000: -126.21779551486578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress: 100%|█████████████████████████████████████████| Time: 0:41:58\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1500000 saved to ./RL_models_leo/vtol_2D_ppo_1500000.bson\n",
      "test reward at step 1500000: -134.93352085268606\n"
     ]
    }
   ],
   "source": [
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv # Parametric Constructor for a subtype of AbstractEnv\n",
    "    action_space::A # action space\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}} # observation space\n",
    "    state::Vector{T} # current state space\n",
    "    action::ACT # action space\n",
    "    done::Bool # done\n",
    "    t::T # time\n",
    "    rng::R # random number generator\n",
    "\n",
    "    name::String # for multible environments\n",
    "    visualization::Bool # visualization\n",
    "    realtime::Bool # realtime\n",
    "\n",
    "    x_previous::Vector{T} # previous position\n",
    "    x_W::Vector{T} # current position\n",
    "    v_B::Vector{T} # velocity\n",
    "    R_W::Matrix{T} # current rotation\n",
    "    w_B::Vector{T} # rotation velocitiy\n",
    "    wind_W::Vector{T} # wind\n",
    "    delta_t::T # simulation time step\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Extend the environment here.\n",
    "    # Everything you need additionaly in your environment also go in here.\n",
    "    # E.g. a trajectory\n",
    "\n",
    "    waypoints::Vector{Vector{T}} # waypoints\n",
    "    proximity_tolerance::T # proximity tolerance\n",
    "    v_min::T # minimum required velocity\n",
    "    v_max::T # maximum allowed velocity\n",
    "\n",
    "    ######################################################################\n",
    "end\n",
    "\n",
    "\n",
    "# define a keyword-based constructor for the type declared in the mutable struct typedef.\n",
    "# It could also be done with the macro Base.@kwdef.\n",
    "function VtolEnv(;\n",
    "    rng = Random.GLOBAL_RNG, # random number generation\n",
    "    name = \"vtol\",\n",
    "            visualization = false,\n",
    "    realtime = false,\n",
    "    kwargs...) # let the function take an arbitrary number of keyword arguments\n",
    "\n",
    "    T = Float64; # explicit type which is used e.g. in state. Cannot be altered due to the poor matrix defininon.\n",
    "    A = Space{Vector{ClosedInterval{T}}};\n",
    "\n",
    "    action_space = Space(\n",
    "        ClosedInterval{T}[\n",
    "            0.0..2.0, # propeller 1\n",
    "            0.0..2.0, # propeller 2\n",
    "            ],\n",
    "    ) # propeller 1 and 2\n",
    "\n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            ################################ TODO ################################\n",
    "            # Implement an observation space.\n",
    "            # Here is an example space. You can change it if desired.\n",
    "            # You have to extend it.\n",
    "            # Orientate yourself on the observation space from the paper.\n",
    "\n",
    "            typemin(T)..typemax(T), #1 previous position along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #2 previous position along z WORLD coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #3 current position along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #4 current position along z WORLD coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #5 orientation along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #6 orientation along z WORLD coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #7 velocity along x BODY coordinates\n",
    "            typemin(T)..typemax(T), #8 velocity along y BODY coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #9 rotational velocity along z BODY coordinates\n",
    "\n",
    "            #changed back to world for calculating guiding path easier\n",
    "            typemin(T)..typemax(T), #10 position of target along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #11 position of target along z WORLD coordinates\n",
    "\n",
    "            #changed so the drone knows the guiding path\n",
    "            typemin(T)..typemax(T), #12 position of previous WP along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #13 position of previous WP along z WORLD coordinates\n",
    "\n",
    "            ######################################################################\n",
    "            ],\n",
    "    )\n",
    "\n",
    "    if visualization #visualizes VTOL\n",
    "        create_VTOL(name, actuators = true, color_vec=[1.0; 1.0; 0.6; 1.0]);\n",
    "    end\n",
    "\n",
    "    environment = VtolEnv(\n",
    "        action_space, # action space\n",
    "        state_space, # observation space\n",
    "        zeros(T, length(state_space)), # current state space\n",
    "        rand(action_space), # initialization action\n",
    "        false, # episode done\n",
    "        0.0, # time\n",
    "        rng, # random number generator\n",
    "\n",
    "        name,\n",
    "        visualization,\n",
    "        realtime,\n",
    "\n",
    "        zeros(T, 3), # x_previous, previous position\n",
    "        zeros(T, 3), # x_W, current position\n",
    "        zeros(T, 3), # v_B, velocity\n",
    "        [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0], # R_W, current rotation\n",
    "        zeros(T, 3), # w_B\n",
    "        zeros(T, 3), # wind_W\n",
    "        T(0.02), # simulation time step\n",
    "\n",
    "        ################################## TODO ##################################\n",
    "        # Initialization everything you need additionaly in your environment here\n",
    "        SAMPLE_WAYPOINTS,\n",
    "        1e-5, # proximity tolerance\n",
    "        1.0, # minimum required velocity\n",
    "        20.0, # maximum allowed velocity\n",
    "        ##########################################################################\n",
    "    )\n",
    "\n",
    "    reset!(environment)\n",
    "    return environment\n",
    "end;\n",
    "\n",
    "methods(VtolEnv)\n",
    "\n",
    "\n",
    "# Just for explanation:\n",
    "# 1. A mutable Struct is created. A struct is a constructor and a constructor is a function that creates new objects.\n",
    "# 2. A outer keyword-based constructor method is added for the type declared in the mutable struct typedef before.'\n",
    "# So now we have a function with two methods. Julia will decide which method to call by multiple dispatch.\n",
    "\n",
    "## Define the RL interface\n",
    "\n",
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state\n",
    "\n",
    "\n",
    "function computeReward(env::VtolEnv{A,T}) where {A,T}\n",
    "    reward = 0.0\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Implement the reward function.\n",
    "    # Orientate on the paper.\n",
    "\n",
    "    # Hyperparameters\n",
    "    kp = 5.0;\n",
    "    kw = 0.5;\n",
    "    kwp = 25.0;\n",
    "    kv = 1.0;\n",
    "    # Stop perverse incentives\n",
    "    kb = 25.0;\n",
    "\n",
    "    # Gates and their length\n",
    "    gates = [[0.0, 0.0, 0.0], [env.state[10], 0.0, env.state[11]]];\n",
    "    n = length(gates);\n",
    "\n",
    "    # closest point on the guiding path phi\n",
    "    # its line-segment index lp\n",
    "    x_old = [env.state[1], 0.0, env.state[2]];\n",
    "    x_new = [env.state[3], 0.0, env.state[4]];\n",
    "    lp_old, phi_old = calculate_progress(gates, x_old);\n",
    "    lp_new, phi_new = calculate_progress(gates, x_new);\n",
    "\n",
    "    # previous time step spt_old\n",
    "    # current time step spt_new\n",
    "    spt_old = 0.0;\n",
    "    spt_new = 0.0;\n",
    "    for i in 1:(lp_old-1)\n",
    "        spt_old += (norm(gates[i+1] - gates[i]) + norm(phi_old - gates[lp_old]));\n",
    "    end\n",
    "    for i in 1:(lp_new-1)\n",
    "        spt_new += (norm(gates[i+1] - gates[i]) + norm(phi_new - gates[lp_old]));\n",
    "    end\n",
    "\n",
    "    # rogress reward rpt at time t is as a difference in reached\n",
    "    # distance between the current and previous time step\n",
    "    rpt = spt_new - spt_old\n",
    "    spt = spt_new\n",
    "\n",
    "    # The sum that is later goig to be the divisor\n",
    "    # for the reached distance reward\n",
    "    divisor_g = 0.0;\n",
    "    for i in 1:(n-1)\n",
    "        divisor_g += norm(gates[i+1] - gates[i]);\n",
    "    end\n",
    "\n",
    "    # reached distance reward ks\n",
    "    ks = 2 * env.v_max * env.delta_t / divisor_g;\n",
    "\n",
    "    # waypoint index wpi must be same as the index of the current line segment\n",
    "    wpi = lp_old + 1; #test\n",
    "    # distance to new waypoint dw\n",
    "    dwp = norm(env.x_W - gates[wpi]);\n",
    "    # tolerance for proximity to a waypoint\n",
    "    r_tol = env.proximity_tolerance;\n",
    "\n",
    "    # waypoint reward rwp\n",
    "    rwp = exp(-dwp/r_tol);\n",
    "\n",
    "    # no obstacles\n",
    "    collision = false;\n",
    "    # terminal reward rt\n",
    "    rt = collision ? -10 : 0;\n",
    "\n",
    "    # absolute velocity\n",
    "    v_vector = [env.state[7], env.state[8], 0.0]\n",
    "    v = norm(v_vector);\n",
    "    # rotation speed\n",
    "    w = abs(env.state[9]);\n",
    "    # distance from closes point on the guiding path\n",
    "    gd = norm(x_new - phi_new);\n",
    "    # max distance\n",
    "    dmax = 0.3;\n",
    "\n",
    "    # punishment for flying too damn fast\n",
    "    rv = max(0, v - v_expected); #changed not to punish slow flight\n",
    "\n",
    "    # Scaling factors\n",
    "    svmax = v > env.v_max ? 10^(env.v_max - v) : 1.0;\n",
    "    svmin = v < env.v_min ?  10^(v - env.v_min) : 1.0;\n",
    "    sgd = gd > dmax  ? exp(dmax - gd) : 1.0;\n",
    "\n",
    "    # added punishment for intentionally stopping the simulation\n",
    "    bad = max(0,\n",
    "        w + 1 - w_max,\n",
    "        0.2* (1 + floor_level - env.x_W[3]))  * (timeout - env.t)\n",
    "\n",
    "    # Ultimate scaling factor\n",
    "    s = svmax * svmin * sgd;\n",
    "\n",
    "    # Scaling the rewards\n",
    "    kp = s * kp;\n",
    "    ks = s * ks;\n",
    "\n",
    "    reward = kp * rpt + ks * spt + kwp * rwp + rt - kw * w - kv * rv - kb * bad;\n",
    "\n",
    "    ################################################################################################\n",
    "\n",
    "    return reward\n",
    "end\n",
    "\n",
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = computeReward(env)\n",
    "\n",
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    # Visualize initial state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, [0.0; 0.0; 0.0; 0.0]);\n",
    "    end\n",
    "\n",
    "    env.x_W = [0.0; 0.0; 0.0];\n",
    "    env.v_B = [0.0; 0.0; 0.0];\n",
    "    env.R_W = Matrix(UnitQuaternion(RotZ(-pi/2.0) * RotY(-pi/2.0) * RotX(pi)));\n",
    "\n",
    "    env.w_B = [0.0; 0.0; 0.0];\n",
    "    env.wind_W = [0.0; 0.0; 0.0];\n",
    "\n",
    "    env.t = 0.0;\n",
    "    env.action = [0.0, 0.0];\n",
    "    env.done = false;\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Reset environment.\n",
    "    # Is called if the training terminates\n",
    "    # (e.g. if drone crashes or successfully reaches point)\n",
    "    # HINT: Everything you added to your environment needs to be reseted.\n",
    "    #       Compare it with the initialization.\n",
    "\n",
    "    env.x_previous = [0.0; 0.0; 0.0]; # starting position\n",
    "    env.delta_t = T(0.02); # Δ time\n",
    "\n",
    "    env.waypoints = SAMPLE_WAYPOINTS;\n",
    "    env.proximity_tolerance = 1e-5;\n",
    "\n",
    "\n",
    "    # Visualize the waypoints\n",
    "    radius = 0.1;\n",
    "    visualize_waypoints(env.waypoints, radius);\n",
    "    ######################################################################\n",
    "\n",
    "    nothing\n",
    "end;\n",
    "\n",
    "# defines a methods for a callable object.\n",
    "# So when a VtolEnv object is created, it has this method that can be called\n",
    "function (env::VtolEnv)(a)\n",
    "    # set the propeller trust and the two flaps 2D case\n",
    "    # flaps set to 0.0\n",
    "    next_action = [a[1], a[2], 0.0, 0.0]\n",
    "\n",
    "    _step!(env, next_action)\n",
    "end\n",
    "\n",
    "env = VtolEnv();\n",
    "methods(env) # Just to explain which methods the object has\n",
    "\n",
    "\n",
    "function _step!(env::VtolEnv, next_action)\n",
    "# Update previous\n",
    "    env.x_previous = env.x_W;\n",
    "\n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(env.v_B, env.R_W, env.wind_W);\n",
    "\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = vtol_model(v_in_wind_B, next_action, eth_vtol_param);\n",
    "\n",
    "    # Limit to 2D\n",
    "    force_B[3] = 0.0; # Body Z\n",
    "    env.v_B[3] = 0.0;\n",
    "    torque_B[1] = 0.0;\n",
    "    torque_B[2] = 0.0;  # Body X and Y\n",
    "    env.w_B[1] = 0.0;\n",
    "    env.w_B[2] = 0.0;\n",
    "\n",
    "    # integrate rigid body dynamics for delta_t\n",
    "    env.x_W, env.v_B, env.R_W, env.w_B, time = rigid_body_simple(torque_B, force_B, env.x_W, env.v_B, env.R_W, env.w_B, env.t, env.delta_t, eth_vtol_param);\n",
    "\n",
    "    if env.realtime\n",
    "        sleep(env.delta_t); # just a dirty hack. this is of course slower than real time.\n",
    "    end\n",
    "\n",
    "    # Visualize the new state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, next_action);\n",
    "    end\n",
    "\n",
    "    env.t += env.delta_t\n",
    "\n",
    "    env.state[3] = env.x_W[1]; # position along x\n",
    "    env.state[4] = env.x_W[3]; # position along z\n",
    "\n",
    "    env.state[5] = env.R_W[1,1]; # orientation along x\n",
    "    env.state[6] = env.R_W[3,1]; # orientation along z\n",
    "\n",
    "    env.state[7] = env.v_B[1]; # velocity along x BODY coordinates\n",
    "    env.state[8] = env.v_B[2]; # velocity along y BODY coordinates\n",
    "\n",
    "    env.state[9] = env.w_B[3];  # rotational velocity along z BODY coordinates\n",
    "\n",
    "    ################################ TODO ################################\n",
    "\n",
    "    env.state[1] = env.x_previous[1]; # update previous x-coordinate\n",
    "    env.state[2] = env.x_previous[3]; # update previous z-coordinate\n",
    "\n",
    "    env.state[10] = env.waypoints[2][1] # position of target along x WORLD coordinates\n",
    "    env.state[11] = env.waypoints[2][3] # position of target along z WORLD coordinates\n",
    "\n",
    "    env.state[12] = env.waypoints[1][1] # position of target along x WORLD coordinates\n",
    "    env.state[13] = env.waypoints[1][3] # position of target along z WORLD coordinates\n",
    "\n",
    "    # maximum rotation speed\n",
    "\n",
    "    env.done =\n",
    "        norm(env.w_B) > w_max || # stop if body rate is too high\n",
    "        norm(env.v_B) > env.v_max || # stop if body is too fast\n",
    "        env.state[4] < floor_level ||\n",
    "        env.t > timeout ||\n",
    "        norm(env.waypoints[2] - env.x_W) < env.proximity_tolerance  # target reached\n",
    "    ######################################################################\n",
    "\n",
    "    nothing\n",
    "end;\n",
    "\n",
    "RLBase.test_runnable!(env)\n",
    "\n",
    "# changed to 10s (5s before) per point and 5.0m too far off path (2.0 before)\n",
    "# Show an overview of the environment.\n",
    "\n",
    "## Setup of a reinforcement learning experiment.\n",
    "\n",
    "seed = 123\n",
    "rng = StableRNG(seed)\n",
    "    N_ENV = 8\n",
    "    UPDATE_FREQ = 1024\n",
    "\n",
    "    vtol_envs = [\n",
    "        # use different names for the visualization\n",
    "        VtolEnv(; rng = StableRNG(hash(seed+i)), name = \"vtol$i\") for i in 1:N_ENV\n",
    "    ];\n",
    "    # define multiple environments for parallel training\n",
    "    env = MultiThreadEnv(vtol_envs)\n",
    "\n",
    "    # Define the function approximator\n",
    "    # (optional) TODO: change architecture\n",
    "    # TODO: research briefly what Actor Critic is\n",
    "    # (optional) TODO: change optimizer\n",
    "    # TODO: research what ADAM is\n",
    "    ns, na = length(state(env[1])), length(action_space(env[1]))\n",
    "    println(ns)\n",
    "    println(na)\n",
    "    approximator = ActorCritic(\n",
    "                #ns - number states as input\n",
    "                #3 layer; last layer splitted in mean and variance; then action is sampled\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                    Dense(ns, 16, relu; initW = glorot_uniform(rng)),#\n",
    "                    Dense(16, 16, relu; initW = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(Dense(16, na; initW = glorot_uniform(rng))),\n",
    "                    logσ = Chain(Dense(16, na; initW = glorot_uniform(rng))),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 16, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(16, 16, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(16, 1; initW = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(1e-3),\n",
    "            );\n",
    "\n",
    "        agent = Agent( # A wrapper of an AbstractPolicy\n",
    "        # AbstractPolicy: the policy to use\n",
    "        # (optional) TODO: change eventually\n",
    "        # TODO: research briefly what PPO is\n",
    "        policy = PPOPolicy(;\n",
    "                    approximator = approximator |> gpu,\n",
    "                    update_freq=UPDATE_FREQ,\n",
    "                    dist = Normal,\n",
    "                    # For parameters visit the docu: https://juliareinforcementlearning.org/docs/rlzoo/#ReinforcementLearningZoo.PPOPolicy\n",
    "                    ),\n",
    "\n",
    "        # AbstractTrajectory: used to store transitions between an agent and an environment source\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float64} => (ns, N_ENV),\n",
    "            action = Matrix{Float64} => (na, N_ENV),\n",
    "            action_log_prob = Vector{Float64} => (N_ENV,),\n",
    "            reward = Vector{Float64} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    );\n",
    "\n",
    "\n",
    "function saveModel(t, agent, env)\n",
    "    model = cpu(agent.policy.approximator)\n",
    "    f = joinpath(\"./RL_models_leo/\", \"vtol_2D_ppo_$t.bson\") # TODO: save model here\n",
    "    @save f model\n",
    "    println(\"parameters at step $t saved to $f\")\n",
    "end;\n",
    "\n",
    "function loadModel()\n",
    "    f = joinpath(\"./RL_models_leo/\", \"vtol_2D_ppo_1500000.bson\") # TODO: load model here\n",
    "    @load f model\n",
    "    return model\n",
    "end;\n",
    "\n",
    "function validate_policy(t, agent, env)\n",
    "    run(agent.policy, test_env, StopAfterEpisode(1), episode_test_reward_hook)\n",
    "    # the result of the hook\n",
    "    println(\"test reward at step $t: $(episode_test_reward_hook.rewards[end])\")\n",
    "\n",
    "end;\n",
    "\n",
    "episode_test_reward_hook = TotalRewardPerEpisode(;is_display_on_exit=false)\n",
    "# create a env only for reward test\n",
    "test_env = VtolEnv(;name = \"testVTOL\", visualization = true, realtime = true);\n",
    "\n",
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(1_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000),\n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.policy.approximator = loadModel();\n",
    "\n",
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(1_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000),\n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Plot the stuff\n",
    "plot(episode_test_reward_hook.rewards)\n",
    "\n",
    "close_visualization(); # closes the MeshCat visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
