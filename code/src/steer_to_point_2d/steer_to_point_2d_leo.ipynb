{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1m┌ \u001B[22m\u001B[39m\u001B[36m\u001B[1mInfo: \u001B[22m\u001B[39mMeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "\u001B[36m\u001B[1m└ \u001B[22m\u001B[39mhttp://127.0.0.1:8700\n"
     ]
    }
   ],
   "source": [
    "## Init Bionic VTOL\n",
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position\n",
    "\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;\n",
    "using Distributions;\n",
    "\n",
    "using Plots;\n",
    "using Statistics;\n",
    "\n",
    "using BSON: @save, @load # save mode\n",
    "create_visualization();\n",
    "\n",
    "# indicates how many threads Julia was started with. This is important for the multi-threaded environment\n",
    "Threads.nthreads()\n",
    "### Create Reinforcement Learning Environment\n",
    "\n",
    "\n",
    "################################ TODO ################################\n",
    "# You can initialization global constants here.\n",
    "# E.g. a fixed point in the beginning of training (for testing/overfitting)\n",
    "# Define global constants for initial position and rotation\n",
    "\n",
    "#####\n",
    "##### first coordinate - red axis - x\n",
    "##### second coordinate - green axis - y\n",
    "##### third coordinate - blue axis - z\n",
    "#####\n",
    "x_init = [0.0, 0.0, 0.0];\n",
    "rot_init = Matrix(UnitQuaternion(RotZ(-pi/2.0) * RotY(-pi/2.0) * RotX(pi)));\n",
    "\n",
    "# Defaault values for VtolEnv variables\n",
    "waypoints_default = generate_trajectory(2);\n",
    "proximity_tolerance_default = 0.25;\n",
    "timeout_default = 30.0;\n",
    "\n",
    "v_min_default = 1.0;\n",
    "v_max_default = 2.0;\n",
    "w_max_default = 15.0;;\n",
    "\n",
    "######################################################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[1mTest Summary:              | \u001B[22m\u001B[32m\u001B[1mPass  \u001B[22m\u001B[39m\u001B[36m\u001B[1mTotal  \u001B[22m\u001B[39m\u001B[0m\u001B[1mTime\u001B[22m\n",
      "random policy with VtolEnv | \u001B[32m2000  \u001B[39m\u001B[36m 2000  \u001B[39m\u001B[0m0.0s\n"
     ]
    }
   ],
   "source": [
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv # Parametric Constructor for a subtype of AbstractEnv\n",
    "    action_space::A # action space\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}} # observation space\n",
    "    state::Vector{T} # current state space\n",
    "    action::ACT # action space\n",
    "    done::Bool # done\n",
    "    t::T # time\n",
    "    rng::R # random number generator\n",
    "\n",
    "    name::String # for multible environments\n",
    "    visualization::Bool # visualization\n",
    "    realtime::Bool # realtime\n",
    "\n",
    "    x_previous::Vector{T} # previous position\n",
    "    x_W::Vector{T} # current position\n",
    "    v_B::Vector{T} # velocity\n",
    "    R_W::Matrix{T} # current rotation\n",
    "    w_B::Vector{T} # rotation velocitiy\n",
    "    wind_W::Vector{T} # wind\n",
    "    delta_t::T # simulation time step\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Extend the environment here.\n",
    "    # Everything you need additionaly in your environment also go in here.\n",
    "    # E.g. a trajectory\n",
    "\n",
    "    # Pathway variables\n",
    "    waypoints::Vector{Vector{T}}\n",
    "    proximity_tolerance::T\n",
    "    timeout::T\n",
    "\n",
    "    # Kinetic variables\n",
    "    v_min::T\n",
    "    v_max::T # maximum allowed velocity\n",
    "    w_max::T # maximum allowed velocity\n",
    "\n",
    "    ######################################################################\n",
    "end\n",
    "\n",
    "\n",
    "# define a keyword-based constructor for the type declared in the mutable struct typedef.\n",
    "# It could also be done with the macro Base.@kwdef.\n",
    "function VtolEnv(;\n",
    "    rng = Random.GLOBAL_RNG, # random number generation\n",
    "    name = \"vtol\",\n",
    "            visualization = false,\n",
    "    realtime = false,\n",
    "    kwargs...) # let the function take an arbitrary number of keyword arguments\n",
    "\n",
    "    T = Float64; # explicit type which is used e.g. in state. Cannot be altered due to the poor matrix defininon.\n",
    "    A = Space{Vector{ClosedInterval{T}}};\n",
    "\n",
    "    action_space = Space(\n",
    "        ClosedInterval{T}[\n",
    "            0.0..2.0, # propeller 1\n",
    "            0.0..2.0, # propeller 2\n",
    "            ],\n",
    "    ) # propeller 1 and 2\n",
    "\n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            ################################ TODO ################################\n",
    "            # Implement an observation space.\n",
    "            # Here is an example space. You can change it if desired.\n",
    "            # You have to extend it.\n",
    "            # Orientate yourself on the observation space from the paper.\n",
    "\n",
    "            typemin(T)..typemax(T), #1 previous position along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #2 previous position along z WORLD coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #3 current position along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #4 current position along z WORLD coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #7 velocity along x BODY coordinates\n",
    "            typemin(T)..typemax(T), #8 velocity along y BODY coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #9 rotational velocity along z BODY coordinates\n",
    "            ######################################################################\n",
    "            ],\n",
    "    )\n",
    "\n",
    "    if visualization # visualizes VTOL\n",
    "        create_VTOL(name, actuators = true, color_vec=[1.0; 1.0; 0.6; 1.0]);\n",
    "    end\n",
    "\n",
    "    environment = VtolEnv(\n",
    "        action_space, # action space\n",
    "        state_space, # observation space\n",
    "        zeros(T, length(state_space)), # current state space\n",
    "        rand(action_space), # initialization action\n",
    "        false, # episode done\n",
    "        0.0, # time\n",
    "        rng, # random number generator\n",
    "\n",
    "        name,\n",
    "        visualization,\n",
    "        realtime,\n",
    "\n",
    "        zeros(T, 3), # x_previous, previous position\n",
    "        zeros(T, 3), # x_W, current position\n",
    "        zeros(T, 3), # v_B, velocity\n",
    "        rot_init, # R_W, current rotation\n",
    "        zeros(T, 3), # w_B\n",
    "        zeros(T, 3), # wind_W\n",
    "        T(0.02), # simulation time step\n",
    "\n",
    "        ################################## TODO ##################################\n",
    "        # Initialization everything you need additionaly in your environment here\n",
    "\n",
    "        waypoints_default,\n",
    "        proximity_tolerance_default,\n",
    "        timeout_default,\n",
    "        v_min_default,\n",
    "        v_max_default,\n",
    "        w_max_default,\n",
    "        ##########################################################################\n",
    "    )\n",
    "\n",
    "    reset!(environment)\n",
    "    return environment\n",
    "end;\n",
    "\n",
    "methods(VtolEnv)\n",
    "\n",
    "# Just for explanation:\n",
    "# 1. A mutable Struct is created. A struct is a constructor and a constructor is a function that creates new objects.\n",
    "# 2. A outer keyword-based constructor method is added for the type declared in the mutable struct typedef before.'\n",
    "# So now we have a function with two methods. Julia will decide which method to call by multiple dispatch.\n",
    "\n",
    "## Define the RL interface\n",
    "\n",
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state\n",
    "\n",
    "function computeReward(env::VtolEnv{A,T}) where {A,T}\n",
    "    reward = 0.0\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Implement the reward function.\n",
    "    # Orientate on the paper.\n",
    "\n",
    "    # Hyperparameters\n",
    "    kp = 5.0;\n",
    "    kw = 0.01;\n",
    "    kwp = 5.0;\n",
    "    # max distance\n",
    "    dmax = 0.3;\n",
    "\n",
    "    # Gates and their length\n",
    "    gates = env.waypoints;\n",
    "    n = length(gates);\n",
    "\n",
    "    # closest point on the guiding path phi\n",
    "    # its line-segment index lp\n",
    "    x_old = [env.state[1], 0.0, env.state[2]];\n",
    "    x_new = [env.state[3], 0.0, env.state[4]];\n",
    "    lp_old, phi_old = calculate_progress(gates, x_old);\n",
    "    lp_new, phi_new = calculate_progress(gates, x_new);\n",
    "\n",
    "    # previous time step spt_old\n",
    "    # current time step spt_new\n",
    "    spt_old = norm(phi_old - gates[lp_old]);\n",
    "    spt_new = norm(phi_new - gates[lp_new]);\n",
    "\n",
    "    # rogress reward rpt at time t is as a difference in reached\n",
    "    # distance between the current and previous time step\n",
    "    rpt = spt_new - spt_old\n",
    "    spt = spt_new\n",
    "\n",
    "    # The sum that is later going to be the divisor\n",
    "    # for the reached distance reward\n",
    "    divisor_g = norm(gates[2] - gates[1]);\n",
    "\n",
    "    # reached distance reward ks\n",
    "    ks = 2 * env.v_max * env.delta_t / divisor_g;\n",
    "\n",
    "    # steered at waypoint must be 1 bigger than the current line segment\n",
    "    # distance to new waypoint dw\n",
    "    dwp = norm(x_new - gates[2]);\n",
    "    # tolerance for proximity to a waypoint\n",
    "    r_tol = env.proximity_tolerance;\n",
    "\n",
    "    # waypoint reward rwp\n",
    "    rwp = dwp <= r_tol ? exp(-dwp/r_tol) : 0.0;\n",
    "\n",
    "    # no obstacles\n",
    "    collision = false;\n",
    "    # terminal reward rt\n",
    "    rt = collision ? 10 : 0;\n",
    "\n",
    "    # absolute velocity\n",
    "    v_vector = [env.state[5], env.state[6], 0.0]\n",
    "    v = norm(v_vector);\n",
    "    # rotation speed\n",
    "    w = abs(env.state[7]);\n",
    "    # distance from closes point on the guiding path\n",
    "    gd = norm(x_new - phi_new);\n",
    "\n",
    "    # Scaling factors\n",
    "    svmax = v > env.v_max ? 10^(env.v_max - v) : 1.0;\n",
    "    svmin = v < env.v_min ?  10^(v - env.v_min) : 1.0;\n",
    "    sgd = gd > dmax  ? exp(dmax - gd) : 1.0;\n",
    "\n",
    "    # Ultimate scaling factor\n",
    "    s = svmax * svmin * sgd;\n",
    "\n",
    "    # Scaling the rewards\n",
    "    kp = s * kp;\n",
    "    ks = s * ks;\n",
    "\n",
    "    #### Punishment for stupidity and autism\n",
    "    # Punish for falling down\n",
    "    kz = 1.5 / (1.0 + env.t);\n",
    "    rz = (min(0, env.state[4]))^2;\n",
    "    # Punish for attempting to quickly end the simulation at the beginning due to high rotation acceleration\n",
    "    rz += (w * max(0, 0.5 - env.t))^2;\n",
    "    kw *= max(1.0, 4.0 - env.t);\n",
    "\n",
    "    # Sum up positive reinforcement and negative reinforcement\n",
    "    positive_r = kp * rpt + ks * spt + kwp * rwp;\n",
    "    negative_r = kw * w + rt + kz * rz;\n",
    "\n",
    "    # Sum it all\n",
    "    reward = positive_r - negative_r;\n",
    "\n",
    "    # Increase reward for better timing after performance threshold\n",
    "    perf_th = 1.0;\n",
    "    if(reward > perf_th)\n",
    "        reward *= (1.0 / (dwp^2 * env.t))\n",
    "        if(dwp < env.proximity_tolerance)\n",
    "            reward *= reward;\n",
    "        end\n",
    "    end\n",
    "\n",
    "\n",
    "    ################################################################################################\n",
    "\n",
    "    return reward\n",
    "end\n",
    "\n",
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = computeReward(env)\n",
    "\n",
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    # Visualize initial state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, [0.0; 0.0; 0.0; 0.0]);\n",
    "    end\n",
    "\n",
    "    env.x_W = [0.0; 0.0; 0.0];\n",
    "    env.v_B = [0.0; 0.0; 0.0];\n",
    "    env.R_W = rot_init;\n",
    "\n",
    "    env.w_B = [0.0; 0.0; 0.0];\n",
    "    env.wind_W = [0.0; 0.0; 0.0];\n",
    "\n",
    "    env.t = 0.0;\n",
    "    env.action = [0.0, 0.0];\n",
    "    env.done = false;\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Reset environment.\n",
    "    # Is called if the training terminates\n",
    "    # (e.g. if drone crashes or successfully reaches point)\n",
    "    # HINT: Everything you added to your environment needs to be reseted.\n",
    "    #       Compare it with the initialization.\n",
    "\n",
    "    env.state[1] = env.x_previous[1]; # update previous x-coordinate\n",
    "    env.state[2] = env.x_previous[3]; # update previous z-coordinate\n",
    "\n",
    "    env.state[3] = env.x_W[1]; # position along x\n",
    "    env.state[4] = env.x_W[3]; # position along z\n",
    "\n",
    "    env.state[5] = env.v_B[1]; # velocity along x BODY coordinates\n",
    "    env.state[6] = env.v_B[2]; # velocity along y BODY coordinates\n",
    "\n",
    "    env.state[7] = env.w_B[3];  # rotational velocity along z BODY coordinates\n",
    "\n",
    "    env.x_previous = x_init; # starting position\n",
    "    env.delta_t = T(0.02); # Δ time\n",
    "\n",
    "    env.waypoints = waypoints_default;\n",
    "    env.proximity_tolerance = proximity_tolerance_default;\n",
    "    env.timeout = timeout_default;\n",
    "    env.v_min = v_min_default;\n",
    "    env.v_max = v_max_default;\n",
    "    env.w_max = w_max_default;\n",
    "\n",
    "    # Visualize the waypoints\n",
    "    radius = 0.1;\n",
    "    visualize_waypoints(env.waypoints, radius);\n",
    "    ######################################################################\n",
    "\n",
    "    nothing\n",
    "end;\n",
    "\n",
    "# defines a methods for a callable object.\n",
    "# So when a VtolEnv object is created, it has this method that can be called\n",
    "function (env::VtolEnv)(a)\n",
    "    # set the propeller trust and the two flaps 2D case\n",
    "    # flaps set to 0.0\n",
    "    next_action = [a[1], a[2], 0.0, 0.0]\n",
    "\n",
    "    _step!(env, next_action)\n",
    "end\n",
    "\n",
    "env = VtolEnv();\n",
    "methods(env) # Just to explain which methods the object has\n",
    "\n",
    "\n",
    "function _step!(env::VtolEnv, next_action)\n",
    "    # Update previous\n",
    "    env.x_previous = [env.state[3], 0.0, env.state[4]];\n",
    "\n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(env.v_B, env.R_W, env.wind_W);\n",
    "\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = vtol_model(v_in_wind_B, next_action, eth_vtol_param);\n",
    "\n",
    "    # Limit to 2D\n",
    "    force_B[3] = 0.0; # Body Z\n",
    "    env.v_B[3] = 0.0;\n",
    "    torque_B[1] = 0.0;\n",
    "    torque_B[2] = 0.0;  # Body X and Y\n",
    "    env.w_B[1] = 0.0;\n",
    "    env.w_B[2] = 0.0;\n",
    "\n",
    "    # integrate rigid body dynamics for delta_t\n",
    "    env.x_W, env.v_B, env.R_W, env.w_B, time = rigid_body_simple(torque_B, force_B, env.x_W, env.v_B, env.R_W, env.w_B, env.t, env.delta_t, eth_vtol_param);\n",
    "\n",
    "    if env.realtime\n",
    "        sleep(env.delta_t); # just a dirty hack. this is of course slower than real time.\n",
    "    end\n",
    "\n",
    "    # Visualize the new state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, next_action);\n",
    "    end\n",
    "\n",
    "    env.t += env.delta_t\n",
    "\n",
    "\n",
    "    ################################ TODO ################################\n",
    "\n",
    "    env.state[1] = env.x_previous[1]; # update previous x-coordinate\n",
    "    env.state[2] = env.x_previous[3]; # update previous z-coordinate\n",
    "\n",
    "    env.state[3] = env.x_W[1]; # position along x\n",
    "    env.state[4] = env.x_W[3]; # position along z\n",
    "\n",
    "    env.state[5] = env.v_B[1]; # velocity along x BODY coordinates\n",
    "    env.state[6] = env.v_B[2]; # velocity along y BODY coordinates\n",
    "\n",
    "    env.state[7] = env.w_B[3];  # rotational velocity along z BODY coordinates\n",
    "\n",
    "    # Instead of the floor level which assumes the simulation will only run upstairs,\n",
    "    # Here a variables for being too far from the next wp after reaching a previous waypoint can be used instead\n",
    "\n",
    "    segment_length = norm(env.waypoints[2] - env.waypoints[1])\n",
    "    k_failure = 1.5;\n",
    "    wp_dist = norm(env.waypoints[2] - env.x_W)\n",
    "\n",
    "    env.done =\n",
    "        norm(env.w_B) > env.w_max || # stop if body rate is too high\n",
    "        wp_dist > k_failure * segment_length ||\n",
    "        env.t > env.timeout ||\n",
    "        wp_dist < env.proximity_tolerance;\n",
    "    ######################################################################\n",
    "\n",
    "    nothing\n",
    "end;\n",
    "\n",
    "RLBase.test_runnable!(env)\n",
    "\n",
    "# changed to 10s (5s before) per point and 5.0m too far off path (2.0 before)\n",
    "# Show an overview of the environment.\n",
    "\n",
    "## Setup of a reinforcement learning experiment.\n",
    "\n",
    "seed = 123\n",
    "rng = StableRNG(seed)\n",
    "    N_ENV = 8\n",
    "    UPDATE_FREQ = 1024\n",
    "\n",
    "    vtol_envs = [\n",
    "        # use different names for the visualization\n",
    "        VtolEnv(; rng = StableRNG(hash(seed+i)), name = \"vtol$i\") for i in 1:N_ENV\n",
    "    ];\n",
    "    # define multiple environments for parallel training\n",
    "    env = MultiThreadEnv(vtol_envs)\n",
    "\n",
    "    # Define the function approximator\n",
    "    # TODO: research briefly what Actor Critic is\n",
    "    # TODO: research what ADAM is\n",
    "    # Define the function approximator\n",
    "    ns, na = length(state(env[1])), length(action_space(env[1]))\n",
    "    #ActorCritic Policy\n",
    "    approximator = ActorCritic(\n",
    "                #ns - number states as input\n",
    "                #3 layer; last layer splitted in mean and variance; then action is sampled\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                        Dense(ns, 32, relu; initW = glorot_uniform(rng)),\n",
    "                        Dense(32, 16, relu; initW = glorot_uniform(rng)),\n",
    "                        Dense(16, 16, relu; initW = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(\n",
    "                        Dense(16, na; initW = glorot_uniform(rng))\n",
    "                    ),\n",
    "                    logσ = Chain(\n",
    "                        Dense(16, na; initW = glorot_uniform(rng))\n",
    "                    ),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 32, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(32, 16, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(16, 1; initW = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(1e-3),\n",
    "            );\n",
    "\n",
    "        agent = Agent( # A wrapper of an AbstractPolicy\n",
    "        # AbstractPolicy: the policy to use\n",
    "        # (optional) TODO: change eventually\n",
    "        # TODO: research briefly what PPO is\n",
    "        policy = PPOPolicy(;\n",
    "                    approximator = approximator |> gpu,\n",
    "                    update_freq=UPDATE_FREQ,\n",
    "                    dist = Normal,\n",
    "                    # For parameters visit the docu: https://juliareinforcementlearning.org/docs/rlzoo/#ReinforcementLearningZoo.PPOPolicy\n",
    "                    ),\n",
    "\n",
    "        # AbstractTrajectory: used to store transitions between an agent and an environment source\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float64} => (ns, N_ENV),\n",
    "            action = Matrix{Float64} => (na, N_ENV),\n",
    "            action_log_prob = Vector{Float64} => (N_ENV,),\n",
    "            reward = Vector{Float64} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    );\n",
    "\n",
    "\n",
    "function saveModel(t, agent, env)\n",
    "    model = cpu(agent.policy.approximator)\n",
    "    f = joinpath(\"./RL_models_2dpoint_leo/\", \"vtol_2D_ppo_$t.bson\") # TODO: save model here\n",
    "    @save f model\n",
    "    println(\"parameters at step $t saved to $f\")\n",
    "end;\n",
    "\n",
    "function loadModel()\n",
    "    f = joinpath(\"./RL_models_2dpoint_leo/\", \"vtol_2D_ppo_1500000.bson\") # TODO: load model here\n",
    "    @load f model\n",
    "    return model\n",
    "end;\n",
    "\n",
    "function validate_policy(t, agent, env)\n",
    "    run(agent.policy, test_env, StopAfterEpisode(1), episode_test_reward_hook)\n",
    "    # the result of the hook\n",
    "    println(\"test reward at step $t: $(episode_test_reward_hook.rewards[end])\")\n",
    "\n",
    "end;\n",
    "\n",
    "episode_test_reward_hook = TotalRewardPerEpisode(;is_display_on_exit=false)\n",
    "# create a env only for reward test\n",
    "test_env = VtolEnv(;name = \"testVTOL\", visualization = true, realtime = true);\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run without loading the model\n",
    "\n",
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(1_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000),\n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   1%|▎                                        |  ETA: 0:05:10\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 10000: 368.08989429878403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   1%|▌                                        |  ETA: 0:10:22\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 20000: -1.3451597546200769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   2%|▉                                        |  ETA: 0:08:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 30000: 1487.7193110670382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   3%|█▏                                       |  ETA: 0:08:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 40000: 327.9178475562236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   3%|█▎                                       |  ETA: 0:09:10\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 50000: 467.5061060895106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   4%|█▌                                       |  ETA: 0:08:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 60000: 546.8797897699261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   5%|█▉                                       |  ETA: 0:08:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 70000: 20167.981248890355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   5%|██▏                                      |  ETA: 0:08:32\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 80000: 474.5308564389741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   6%|██▍                                      |  ETA: 0:08:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 90000: 4868.588556376358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   7%|██▋                                      |  ETA: 0:08:32\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 100000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_100000.bson\n",
      "test reward at step 100000: -0.16988773558436332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   7%|███                                      |  ETA: 0:08:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 110000: -0.46452835338332366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   8%|███▎                                     |  ETA: 0:08:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 120000: 1228.6125175147783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   9%|███▌                                     |  ETA: 0:08:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 130000: 6647.592332334452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   9%|███▉                                     |  ETA: 0:08:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 140000: 1184.8909293122824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  10%|████                                     |  ETA: 0:08:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 150000: 336.3621303532896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  10%|████▎                                    |  ETA: 0:08:32\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 160000: 724.9188732080951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  11%|████▋                                    |  ETA: 0:08:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 170000: 321.1040286528959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  12%|████▉                                    |  ETA: 0:08:18\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 180000: 6807.107579463913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  12%|█████▏                                   |  ETA: 0:08:21\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 190000: 924.0945193917667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  13%|█████▍                                   |  ETA: 0:08:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 200000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_200000.bson\n",
      "test reward at step 200000: 647.8509802295999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  14%|█████▊                                   |  ETA: 0:08:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 210000: 403.8138296961058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  14%|█████▉                                   |  ETA: 0:08:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 220000: 7274.155107011533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  15%|██████▎                                  |  ETA: 0:08:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 230000: 93723.93090878148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  16%|██████▌                                  |  ETA: 0:07:55\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 240000: 308.5297887346467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  17%|██████▉                                  |  ETA: 0:07:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 250000: 1378.4927750122997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  17%|███████                                  |  ETA: 0:07:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 260000: 3567.91151241294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  18%|███████▍                                 |  ETA: 0:07:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 270000: 310.48946740027134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  19%|███████▋                                 |  ETA: 0:07:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 280000: -0.3399720630312263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  19%|███████▊                                 |  ETA: 0:07:45\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 290000: 5054.330104550911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  20%|████████▏                                |  ETA: 0:07:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 300000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_300000.bson\n",
      "test reward at step 300000: 405.78832066044606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  21%|████████▌                                |  ETA: 0:07:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 310000: 25420.06140208683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  21%|████████▋                                |  ETA: 0:07:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 320000: 6443.989093747529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  22%|█████████                                |  ETA: 0:07:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 330000: 509.2575234745261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  23%|█████████▎                               |  ETA: 0:07:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 340000: -0.04479705939664283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  23%|█████████▍                               |  ETA: 0:07:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 350000: 1.954711308929321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  24%|█████████▊                               |  ETA: 0:07:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 360000: 3587.2758460422365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  25%|██████████                               |  ETA: 0:07:18\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 370000: 611.7641201536302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  25%|██████████▍                              |  ETA: 0:07:13\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 380000: 1182.5426601849176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  26%|██████████▌                              |  ETA: 0:07:13\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 390000: 4993.527874492867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  26%|██████████▉                              |  ETA: 0:07:07\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 400000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_400000.bson\n",
      "test reward at step 400000: 331.8676987861673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  27%|███████████▎                             |  ETA: 0:07:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 410000: 744.4761488123785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  28%|███████████▌                             |  ETA: 0:07:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 420000: 435.49379344925944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  28%|███████████▋                             |  ETA: 0:06:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 430000: 1866.237753252818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  29%|████████████                             |  ETA: 0:06:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 440000: 7318.910974171681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  30%|████████████▎                            |  ETA: 0:06:47\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 450000: 285.7497992302657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  31%|████████████▋                            |  ETA: 0:06:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 460000: 304.3415887788244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  31%|████████████▊                            |  ETA: 0:06:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 470000: -2.3560990342336896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  32%|█████████████                            |  ETA: 0:06:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 480000: 2363.0116880600585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  33%|█████████████▍                           |  ETA: 0:06:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 490000: 966.4173540900804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  33%|█████████████▋                           |  ETA: 0:06:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 500000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_500000.bson\n",
      "test reward at step 500000: 5003.195924881813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  34%|█████████████▊                           |  ETA: 0:06:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 510000: 1311.1499112646866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  34%|██████████████▏                          |  ETA: 0:06:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 520000: 2.1849983257871584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  35%|██████████████▍                          |  ETA: 0:06:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 530000: 2.8520034880187466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  36%|██████████████▊                          |  ETA: 0:06:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 540000: -0.5680599815609618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  36%|██████████████▉                          |  ETA: 0:06:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 550000: -0.2343714276793361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  37%|███████████████▎                         |  ETA: 0:06:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 560000: -1.221138329986628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  38%|███████████████▋                         |  ETA: 0:06:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 570000: -5.857725874308936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  39%|███████████████▉                         |  ETA: 0:06:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 580000: 0.6897162047373572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  39%|████████████████                         |  ETA: 0:06:03\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 590000: 1968.2328277269391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  40%|████████████████▍                        |  ETA: 0:05:58\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 600000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_600000.bson\n",
      "test reward at step 600000: 482.014021534573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  41%|████████████████▋                        |  ETA: 0:05:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 610000: 521.8915970284338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  41%|█████████████████                        |  ETA: 0:05:50\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 620000: 20352.885803831574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  42%|█████████████████▏                       |  ETA: 0:05:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 630000: 348.46517072789953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  42%|█████████████████▍                       |  ETA: 0:05:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 640000: -3.0196140564793876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  43%|█████████████████▊                       |  ETA: 0:05:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 650000: -2.5021377554115367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  44%|█████████████████▉                       |  ETA: 0:05:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 660000: -1.9839104548097555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  44%|██████████████████▎                      |  ETA: 0:05:32\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 670000: -1.2029481616304707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  45%|██████████████████▌                      |  ETA: 0:05:27\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 680000: 0.44881270483782904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  46%|██████████████████▊                      |  ETA: 0:05:27\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 690000: -1.1492953197999607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  46%|███████████████████                      |  ETA: 0:05:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 700000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_700000.bson\n",
      "test reward at step 700000: 653.0524206172973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  47%|███████████████████▍                     |  ETA: 0:05:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 710000: -0.06976761945142379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  48%|███████████████████▋                     |  ETA: 0:05:13\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 720000: 4258.362115314725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  48%|███████████████████▊                     |  ETA: 0:05:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 730000: 2012.9387072674745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  49%|████████████████████▏                    |  ETA: 0:05:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 740000: 1.0813423099620492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  50%|████████████████████▌                    |  ETA: 0:05:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 750000: 25267.40869809719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  51%|████████████████████▊                    |  ETA: 0:04:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 760000: 884.661726716915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  51%|████████████████████▉                    |  ETA: 0:04:54\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 770000: -0.40066108654354143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  52%|█████████████████████▎                   |  ETA: 0:04:50\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 780000: 1.7871439027677454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  53%|█████████████████████▌                   |  ETA: 0:04:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 790000: 6012.609710456446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  53%|█████████████████████▉                   |  ETA: 0:04:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 800000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_800000.bson\n",
      "test reward at step 800000: 834.9581983219056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  54%|██████████████████████▏                  |  ETA: 0:04:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 810000: 1503.5976961048502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  54%|██████████████████████▎                  |  ETA: 0:04:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 820000: 512.6907059588003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  55%|██████████████████████▋                  |  ETA: 0:04:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 830000: 9655.033633539626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  56%|███████████████████████                  |  ETA: 0:04:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 840000: 0.5620880735607253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  56%|███████████████████████▏                 |  ETA: 0:04:22\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 850000: 489.14818215026037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  57%|███████████████████████▍                 |  ETA: 0:04:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 860000: -0.5301690841982508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  58%|███████████████████████▊                 |  ETA: 0:04:12\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 870000: 2365.1871506766784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  59%|████████████████████████                 |  ETA: 0:04:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 880000: 354.22309850133996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  59%|████████████████████████▎                |  ETA: 0:04:05\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 890000: 411.1621877386425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  60%|████████████████████████▌                |  ETA: 0:04:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 900000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_900000.bson\n",
      "test reward at step 900000: 1775.6054641498013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  60%|████████████████████████▊                |  ETA: 0:03:58\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 910000: 2357.8441816939667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  61%|█████████████████████████                |  ETA: 0:03:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 920000: -0.06796270612981276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  62%|█████████████████████████▍               |  ETA: 0:03:47\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 930000: 0.34452085473049987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  62%|█████████████████████████▌               |  ETA: 0:03:45\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 940000: -0.3063131765087215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  63%|█████████████████████████▉               |  ETA: 0:03:40\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 950000: 0.31713562591484695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  64%|██████████████████████████▎              |  ETA: 0:03:35\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 960000: 0.032857629126361754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  64%|██████████████████████████▍              |  ETA: 0:03:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 970000: -2.9022045800176364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  65%|██████████████████████████▊              |  ETA: 0:03:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 980000: 0.4220098986896461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  66%|███████████████████████████              |  ETA: 0:03:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 990000: -1.2065792525088854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  66%|███████████████████████████▎             |  ETA: 0:03:21\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1000000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1000000.bson\n",
      "test reward at step 1000000: -0.937532472558156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  67%|███████████████████████████▌             |  ETA: 0:03:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1010000: -1.2501379372675956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  68%|███████████████████████████▊             |  ETA: 0:03:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1020000: 337.1310254508072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  68%|████████████████████████████             |  ETA: 0:03:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1030000: 1220.0239438831136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  69%|████████████████████████████▍            |  ETA: 0:03:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1040000: 2437.337116201865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  70%|████████████████████████████▋            |  ETA: 0:02:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1050000: 3805.0025213715185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  70%|████████████████████████████▉            |  ETA: 0:02:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1060000: 8754.763327117684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  71%|█████████████████████████████▏           |  ETA: 0:02:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1070000: 2894.462487491428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  72%|█████████████████████████████▌           |  ETA: 0:02:47\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1080000: 769.3006847061337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  73%|█████████████████████████████▊           |  ETA: 0:02:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1090000: 0.6547439529314106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  73%|█████████████████████████████▉           |  ETA: 0:02:40\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1100000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1100000.bson\n",
      "test reward at step 1100000: 804.2313113371779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  74%|██████████████████████████████▎          |  ETA: 0:02:35\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1110000: -2.2174731922121955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  75%|██████████████████████████████▋          |  ETA: 0:02:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1120000: -143.04405318022236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  75%|██████████████████████████████▊          |  ETA: 0:02:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1130000: -3.643924037248025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  76%|███████████████████████████████▏         |  ETA: 0:02:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1140000: 5319.691539861118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  77%|███████████████████████████████▍         |  ETA: 0:02:18\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1150000: -2.405149641287195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  77%|███████████████████████████████▋         |  ETA: 0:02:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1160000: -1.106289529701517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  78%|███████████████████████████████▉         |  ETA: 0:02:12\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1170000: -1.0487631616230746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  79%|████████████████████████████████▎        |  ETA: 0:02:07\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1180000: -4.556410329406753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  79%|████████████████████████████████▍        |  ETA: 0:02:05\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1190000: -4.688121638336507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  80%|████████████████████████████████▊        |  ETA: 0:02:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1200000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1200000.bson\n",
      "test reward at step 1200000: 22590.245823502777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  81%|█████████████████████████████████▏       |  ETA: 0:01:55\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1210000: 4464.210260745582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  81%|█████████████████████████████████▎       |  ETA: 0:01:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1220000: 1194.2646063548589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  82%|█████████████████████████████████▌       |  ETA: 0:01:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1230000: 400.56875183650266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  83%|█████████████████████████████████▉       |  ETA: 0:01:43\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1240000: 893.6419410708008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  83%|██████████████████████████████████▏      |  ETA: 0:01:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1250000: -135.82091287868522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  84%|██████████████████████████████████▍      |  ETA: 0:01:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1260000: -4.990695454753553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  84%|██████████████████████████████████▋      |  ETA: 0:01:32\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1270000: 13832.705155001706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  85%|███████████████████████████████████      |  ETA: 0:01:27\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1280000: 24982.59994314529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  86%|███████████████████████████████████▎     |  ETA: 0:01:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1290000: -3.7984936555638327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  86%|███████████████████████████████████▍     |  ETA: 0:01:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1300000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1300000.bson\n",
      "test reward at step 1300000: -14.328284709267948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  87%|███████████████████████████████████▊     |  ETA: 0:01:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1310000: -4.5048059944071905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  88%|████████████████████████████████████▏    |  ETA: 0:01:11\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1320000: -9.413497062710102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  88%|████████████████████████████████████▎    |  ETA: 0:01:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1330000: 711.7633571911251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  89%|████████████████████████████████████▋    |  ETA: 0:01:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1340000: 417.5612576421706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  90%|████████████████████████████████████▉    |  ETA: 0:00:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1350000: 0.14274166365851987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  90%|█████████████████████████████████████▏   |  ETA: 0:00:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1360000: -6.634868230567075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  91%|█████████████████████████████████████▍   |  ETA: 0:00:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1370000: 584.7060490744572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  92%|█████████████████████████████████████▊   |  ETA: 0:00:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1380000: -151.77498518316358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  92%|█████████████████████████████████████▉   |  ETA: 0:00:45\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1390000: -0.4714998600645346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  93%|██████████████████████████████████████▎  |  ETA: 0:00:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1400000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1400000.bson\n",
      "test reward at step 1400000: 902.2207925203368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  94%|██████████████████████████████████████▌  |  ETA: 0:00:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1410000: -31.95395363820125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  94%|██████████████████████████████████████▊  |  ETA: 0:00:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1420000: -33.006459279652844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  95%|███████████████████████████████████████  |  ETA: 0:00:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1430000: -6.0092351767986685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  96%|███████████████████████████████████████▍ |  ETA: 0:00:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1440000: -4.797596995308767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  96%|███████████████████████████████████████▌ |  ETA: 0:00:22\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1450000: -3.4897047488667203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  97%|███████████████████████████████████████▉ |  ETA: 0:00:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1460000: -25.686790025493757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  98%|████████████████████████████████████████ |  ETA: 0:00:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1470000: 825.4797848260724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  98%|████████████████████████████████████████▍|  ETA: 0:00:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1480000: 763.6710777477088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  99%|████████████████████████████████████████▋|  ETA: 0:00:05\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1490000: 8783.003435107314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress: 100%|█████████████████████████████████████████| Time: 0:09:56\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1500000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1500000.bson\n",
      "test reward at step 1500000: -182.14538898211015\n"
     ]
    }
   ],
   "source": [
    "# Run with loading the model\n",
    "\n",
    "agent.policy.approximator = loadModel();\n",
    "\n",
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(1_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000),\n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip260\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip260)\" d=\"\nM0 1600 L2400 1600 L2400 0 L0 0  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip261\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip260)\" d=\"\nM277.431 1486.45 L2352.76 1486.45 L2352.76 47.2441 L277.431 47.2441  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip262\">\n    <rect x=\"277\" y=\"47\" width=\"2076\" height=\"1440\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  323.027,1486.45 323.027,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  980.024,1486.45 980.024,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1637.02,1486.45 1637.02,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  2294.02,1486.45 2294.02,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  277.431,1486.45 2352.76,1486.45 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  323.027,1486.45 323.027,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  980.024,1486.45 980.024,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1637.02,1486.45 1637.02,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2294.02,1486.45 2294.02,1467.55 \n  \"/>\n<path clip-path=\"url(#clip260)\" d=\"M323.027 1517.37 Q319.415 1517.37 317.587 1520.93 Q315.781 1524.47 315.781 1531.6 Q315.781 1538.71 317.587 1542.27 Q319.415 1545.82 323.027 1545.82 Q326.661 1545.82 328.466 1542.27 Q330.295 1538.71 330.295 1531.6 Q330.295 1524.47 328.466 1520.93 Q326.661 1517.37 323.027 1517.37 M323.027 1513.66 Q328.837 1513.66 331.892 1518.27 Q334.971 1522.85 334.971 1531.6 Q334.971 1540.33 331.892 1544.94 Q328.837 1549.52 323.027 1549.52 Q317.216 1549.52 314.138 1544.94 Q311.082 1540.33 311.082 1531.6 Q311.082 1522.85 314.138 1518.27 Q317.216 1513.66 323.027 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M954.724 1514.29 L973.08 1514.29 L973.08 1518.22 L959.006 1518.22 L959.006 1526.7 Q960.025 1526.35 961.043 1526.19 Q962.062 1526 963.08 1526 Q968.867 1526 972.247 1529.17 Q975.626 1532.34 975.626 1537.76 Q975.626 1543.34 972.154 1546.44 Q968.682 1549.52 962.363 1549.52 Q960.187 1549.52 957.918 1549.15 Q955.673 1548.78 953.265 1548.04 L953.265 1543.34 Q955.349 1544.47 957.571 1545.03 Q959.793 1545.58 962.27 1545.58 Q966.275 1545.58 968.613 1543.48 Q970.95 1541.37 970.95 1537.76 Q970.95 1534.15 968.613 1532.04 Q966.275 1529.94 962.27 1529.94 Q960.395 1529.94 958.52 1530.35 Q956.668 1530.77 954.724 1531.65 L954.724 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M994.839 1517.37 Q991.228 1517.37 989.399 1520.93 Q987.594 1524.47 987.594 1531.6 Q987.594 1538.71 989.399 1542.27 Q991.228 1545.82 994.839 1545.82 Q998.473 1545.82 1000.28 1542.27 Q1002.11 1538.71 1002.11 1531.6 Q1002.11 1524.47 1000.28 1520.93 Q998.473 1517.37 994.839 1517.37 M994.839 1513.66 Q1000.65 1513.66 1003.7 1518.27 Q1006.78 1522.85 1006.78 1531.6 Q1006.78 1540.33 1003.7 1544.94 Q1000.65 1549.52 994.839 1549.52 Q989.029 1549.52 985.95 1544.94 Q982.895 1540.33 982.895 1531.6 Q982.895 1522.85 985.95 1518.27 Q989.029 1513.66 994.839 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1596.63 1544.91 L1604.27 1544.91 L1604.27 1518.55 L1595.96 1520.21 L1595.96 1515.95 L1604.22 1514.29 L1608.9 1514.29 L1608.9 1544.91 L1616.54 1544.91 L1616.54 1548.85 L1596.63 1548.85 L1596.63 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1635.98 1517.37 Q1632.37 1517.37 1630.54 1520.93 Q1628.74 1524.47 1628.74 1531.6 Q1628.74 1538.71 1630.54 1542.27 Q1632.37 1545.82 1635.98 1545.82 Q1639.61 1545.82 1641.42 1542.27 Q1643.25 1538.71 1643.25 1531.6 Q1643.25 1524.47 1641.42 1520.93 Q1639.61 1517.37 1635.98 1517.37 M1635.98 1513.66 Q1641.79 1513.66 1644.85 1518.27 Q1647.93 1522.85 1647.93 1531.6 Q1647.93 1540.33 1644.85 1544.94 Q1641.79 1549.52 1635.98 1549.52 Q1630.17 1549.52 1627.09 1544.94 Q1624.04 1540.33 1624.04 1531.6 Q1624.04 1522.85 1627.09 1518.27 Q1630.17 1513.66 1635.98 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1666.14 1517.37 Q1662.53 1517.37 1660.7 1520.93 Q1658.9 1524.47 1658.9 1531.6 Q1658.9 1538.71 1660.7 1542.27 Q1662.53 1545.82 1666.14 1545.82 Q1669.78 1545.82 1671.58 1542.27 Q1673.41 1538.71 1673.41 1531.6 Q1673.41 1524.47 1671.58 1520.93 Q1669.78 1517.37 1666.14 1517.37 M1666.14 1513.66 Q1671.95 1513.66 1675.01 1518.27 Q1678.09 1522.85 1678.09 1531.6 Q1678.09 1540.33 1675.01 1544.94 Q1671.95 1549.52 1666.14 1549.52 Q1660.33 1549.52 1657.25 1544.94 Q1654.2 1540.33 1654.2 1531.6 Q1654.2 1522.85 1657.25 1518.27 Q1660.33 1513.66 1666.14 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M2253.63 1544.91 L2261.27 1544.91 L2261.27 1518.55 L2252.96 1520.21 L2252.96 1515.95 L2261.22 1514.29 L2265.9 1514.29 L2265.9 1544.91 L2273.53 1544.91 L2273.53 1548.85 L2253.63 1548.85 L2253.63 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M2283.02 1514.29 L2301.38 1514.29 L2301.38 1518.22 L2287.31 1518.22 L2287.31 1526.7 Q2288.33 1526.35 2289.34 1526.19 Q2290.36 1526 2291.38 1526 Q2297.17 1526 2300.55 1529.17 Q2303.93 1532.34 2303.93 1537.76 Q2303.93 1543.34 2300.46 1546.44 Q2296.98 1549.52 2290.66 1549.52 Q2288.49 1549.52 2286.22 1549.15 Q2283.97 1548.78 2281.57 1548.04 L2281.57 1543.34 Q2283.65 1544.47 2285.87 1545.03 Q2288.09 1545.58 2290.57 1545.58 Q2294.58 1545.58 2296.91 1543.48 Q2299.25 1541.37 2299.25 1537.76 Q2299.25 1534.15 2296.91 1532.04 Q2294.58 1529.94 2290.57 1529.94 Q2288.7 1529.94 2286.82 1530.35 Q2284.97 1530.77 2283.02 1531.65 L2283.02 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M2323.14 1517.37 Q2319.53 1517.37 2317.7 1520.93 Q2315.9 1524.47 2315.9 1531.6 Q2315.9 1538.71 2317.7 1542.27 Q2319.53 1545.82 2323.14 1545.82 Q2326.77 1545.82 2328.58 1542.27 Q2330.41 1538.71 2330.41 1531.6 Q2330.41 1524.47 2328.58 1520.93 Q2326.77 1517.37 2323.14 1517.37 M2323.14 1513.66 Q2328.95 1513.66 2332.01 1518.27 Q2335.08 1522.85 2335.08 1531.6 Q2335.08 1540.33 2332.01 1544.94 Q2328.95 1549.52 2323.14 1549.52 Q2317.33 1549.52 2314.25 1544.94 Q2311.2 1540.33 2311.2 1531.6 Q2311.2 1522.85 2314.25 1518.27 Q2317.33 1513.66 2323.14 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  277.431,1444.76 2352.76,1444.76 \n  \"/>\n<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  277.431,1132.82 2352.76,1132.82 \n  \"/>\n<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  277.431,820.873 2352.76,820.873 \n  \"/>\n<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  277.431,508.93 2352.76,508.93 \n  \"/>\n<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  277.431,196.986 2352.76,196.986 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  277.431,1486.45 277.431,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  277.431,1444.76 296.329,1444.76 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  277.431,1132.82 296.329,1132.82 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  277.431,820.873 296.329,820.873 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  277.431,508.93 296.329,508.93 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  277.431,196.986 296.329,196.986 \n  \"/>\n<path clip-path=\"url(#clip260)\" d=\"M229.487 1430.56 Q225.875 1430.56 224.047 1434.12 Q222.241 1437.67 222.241 1444.79 Q222.241 1451.9 224.047 1455.47 Q225.875 1459.01 229.487 1459.01 Q233.121 1459.01 234.926 1455.47 Q236.755 1451.9 236.755 1444.79 Q236.755 1437.67 234.926 1434.12 Q233.121 1430.56 229.487 1430.56 M229.487 1426.86 Q235.297 1426.86 238.352 1431.46 Q241.431 1436.05 241.431 1444.79 Q241.431 1453.52 238.352 1458.13 Q235.297 1462.71 229.487 1462.71 Q223.676 1462.71 220.598 1458.13 Q217.542 1453.52 217.542 1444.79 Q217.542 1436.05 220.598 1431.46 Q223.676 1426.86 229.487 1426.86 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M57.7745 1152.61 L74.0939 1152.61 L74.0939 1156.54 L52.1495 1156.54 L52.1495 1152.61 Q54.8115 1149.85 59.3949 1145.22 Q64.0013 1140.57 65.1819 1139.23 Q67.4272 1136.71 68.3068 1134.97 Q69.2096 1133.21 69.2096 1131.52 Q69.2096 1128.77 67.2652 1127.03 Q65.3439 1125.29 62.2421 1125.29 Q60.043 1125.29 57.5893 1126.06 Q55.1588 1126.82 52.381 1128.37 L52.381 1123.65 Q55.2051 1122.52 57.6588 1121.94 Q60.1124 1121.36 62.1495 1121.36 Q67.5198 1121.36 70.7142 1124.04 Q73.9087 1126.73 73.9087 1131.22 Q73.9087 1133.35 73.0985 1135.27 Q72.3115 1137.17 70.205 1139.76 Q69.6263 1140.43 66.5245 1143.65 Q63.4226 1146.85 57.7745 1152.61 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M83.9086 1150.66 L88.7928 1150.66 L88.7928 1156.54 L83.9086 1156.54 L83.9086 1150.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M108.978 1125.06 Q105.367 1125.06 103.538 1128.63 Q101.733 1132.17 101.733 1139.3 Q101.733 1146.41 103.538 1149.97 Q105.367 1153.51 108.978 1153.51 Q112.612 1153.51 114.418 1149.97 Q116.246 1146.41 116.246 1139.3 Q116.246 1132.17 114.418 1128.63 Q112.612 1125.06 108.978 1125.06 M108.978 1121.36 Q114.788 1121.36 117.844 1125.97 Q120.922 1130.55 120.922 1139.3 Q120.922 1148.03 117.844 1152.63 Q114.788 1157.22 108.978 1157.22 Q103.168 1157.22 100.089 1152.63 Q97.0335 1148.03 97.0335 1139.3 Q97.0335 1130.55 100.089 1125.97 Q103.168 1121.36 108.978 1121.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M157.311 1131.08 L146.732 1141.71 L157.311 1152.29 L154.556 1155.09 L143.931 1144.46 L133.306 1155.09 L130.575 1152.29 L141.131 1141.71 L130.575 1131.08 L133.306 1128.28 L143.931 1138.91 L154.556 1128.28 L157.311 1131.08 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M169.672 1152.61 L177.311 1152.61 L177.311 1126.24 L169.001 1127.91 L169.001 1123.65 L177.265 1121.98 L181.94 1121.98 L181.94 1152.61 L189.579 1152.61 L189.579 1156.54 L169.672 1156.54 L169.672 1152.61 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M209.024 1125.06 Q205.413 1125.06 203.584 1128.63 Q201.778 1132.17 201.778 1139.3 Q201.778 1146.41 203.584 1149.97 Q205.413 1153.51 209.024 1153.51 Q212.658 1153.51 214.463 1149.97 Q216.292 1146.41 216.292 1139.3 Q216.292 1132.17 214.463 1128.63 Q212.658 1125.06 209.024 1125.06 M209.024 1121.36 Q214.834 1121.36 217.889 1125.97 Q220.968 1130.55 220.968 1139.3 Q220.968 1148.03 217.889 1152.63 Q214.834 1157.22 209.024 1157.22 Q203.214 1157.22 200.135 1152.63 Q197.079 1148.03 197.079 1139.3 Q197.079 1130.55 200.135 1125.97 Q203.214 1121.36 209.024 1121.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M233.645 1104.36 L224.053 1119.35 L233.645 1119.35 L233.645 1104.36 M232.648 1101.05 L237.425 1101.05 L237.425 1119.35 L241.431 1119.35 L241.431 1122.51 L237.425 1122.51 L237.425 1129.13 L233.645 1129.13 L233.645 1122.51 L220.968 1122.51 L220.968 1118.85 L232.648 1101.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M66.5939 814.115 L54.7884 832.564 L66.5939 832.564 L66.5939 814.115 M65.367 810.041 L71.2466 810.041 L71.2466 832.564 L76.1772 832.564 L76.1772 836.453 L71.2466 836.453 L71.2466 844.601 L66.5939 844.601 L66.5939 836.453 L50.9921 836.453 L50.9921 831.939 L65.367 810.041 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M83.9086 838.721 L88.7928 838.721 L88.7928 844.601 L83.9086 844.601 L83.9086 838.721 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M108.978 813.12 Q105.367 813.12 103.538 816.684 Q101.733 820.226 101.733 827.356 Q101.733 834.462 103.538 838.027 Q105.367 841.568 108.978 841.568 Q112.612 841.568 114.418 838.027 Q116.246 834.462 116.246 827.356 Q116.246 820.226 114.418 816.684 Q112.612 813.12 108.978 813.12 M108.978 809.416 Q114.788 809.416 117.844 814.022 Q120.922 818.606 120.922 827.356 Q120.922 836.082 117.844 840.689 Q114.788 845.272 108.978 845.272 Q103.168 845.272 100.089 840.689 Q97.0335 836.082 97.0335 827.356 Q97.0335 818.606 100.089 814.022 Q103.168 809.416 108.978 809.416 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M157.311 819.138 L146.732 829.763 L157.311 840.342 L154.556 843.143 L143.931 832.518 L133.306 843.143 L130.575 840.342 L141.131 829.763 L130.575 819.138 L133.306 816.337 L143.931 826.962 L154.556 816.337 L157.311 819.138 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M169.672 840.666 L177.311 840.666 L177.311 814.3 L169.001 815.967 L169.001 811.708 L177.265 810.041 L181.94 810.041 L181.94 840.666 L189.579 840.666 L189.579 844.601 L169.672 844.601 L169.672 840.666 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M209.024 813.12 Q205.413 813.12 203.584 816.684 Q201.778 820.226 201.778 827.356 Q201.778 834.462 203.584 838.027 Q205.413 841.568 209.024 841.568 Q212.658 841.568 214.463 838.027 Q216.292 834.462 216.292 827.356 Q216.292 820.226 214.463 816.684 Q212.658 813.12 209.024 813.12 M209.024 809.416 Q214.834 809.416 217.889 814.022 Q220.968 818.606 220.968 827.356 Q220.968 836.082 217.889 840.689 Q214.834 845.272 209.024 845.272 Q203.214 845.272 200.135 840.689 Q197.079 836.082 197.079 827.356 Q197.079 818.606 200.135 814.022 Q203.214 809.416 209.024 809.416 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M233.645 792.421 L224.053 807.41 L233.645 807.41 L233.645 792.421 M232.648 789.11 L237.425 789.11 L237.425 807.41 L241.431 807.41 L241.431 810.57 L237.425 810.57 L237.425 817.19 L233.645 817.19 L233.645 810.57 L220.968 810.57 L220.968 806.903 L232.648 789.11 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M64.3254 513.514 Q61.1773 513.514 59.3254 515.667 Q57.4967 517.82 57.4967 521.569 Q57.4967 525.296 59.3254 527.472 Q61.1773 529.625 64.3254 529.625 Q67.4735 529.625 69.3022 527.472 Q71.1541 525.296 71.1541 521.569 Q71.1541 517.82 69.3022 515.667 Q67.4735 513.514 64.3254 513.514 M73.6077 498.861 L73.6077 503.121 Q71.8485 502.287 70.0429 501.847 Q68.2606 501.408 66.5013 501.408 Q61.8717 501.408 59.418 504.533 Q56.9875 507.658 56.6402 513.977 Q58.006 511.963 60.0662 510.898 Q62.1263 509.81 64.6032 509.81 Q69.8115 509.81 72.8207 512.982 Q75.8531 516.13 75.8531 521.569 Q75.8531 526.894 72.705 530.111 Q69.5568 533.329 64.3254 533.329 Q58.33 533.329 55.1588 528.745 Q51.9875 524.139 51.9875 515.412 Q51.9875 507.218 55.8764 502.357 Q59.7652 497.472 66.3161 497.472 Q68.0754 497.472 69.8578 497.82 Q71.6633 498.167 73.6077 498.861 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M83.9086 526.778 L88.7928 526.778 L88.7928 532.657 L83.9086 532.657 L83.9086 526.778 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M108.978 501.176 Q105.367 501.176 103.538 504.741 Q101.733 508.283 101.733 515.412 Q101.733 522.519 103.538 526.083 Q105.367 529.625 108.978 529.625 Q112.612 529.625 114.418 526.083 Q116.246 522.519 116.246 515.412 Q116.246 508.283 114.418 504.741 Q112.612 501.176 108.978 501.176 M108.978 497.472 Q114.788 497.472 117.844 502.079 Q120.922 506.662 120.922 515.412 Q120.922 524.139 117.844 528.745 Q114.788 533.329 108.978 533.329 Q103.168 533.329 100.089 528.745 Q97.0335 524.139 97.0335 515.412 Q97.0335 506.662 100.089 502.079 Q103.168 497.472 108.978 497.472 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M157.311 507.195 L146.732 517.82 L157.311 528.398 L154.556 531.199 L143.931 520.574 L133.306 531.199 L130.575 528.398 L141.131 517.82 L130.575 507.195 L133.306 504.394 L143.931 515.019 L154.556 504.394 L157.311 507.195 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M169.672 528.722 L177.311 528.722 L177.311 502.357 L169.001 504.023 L169.001 499.764 L177.265 498.097 L181.94 498.097 L181.94 528.722 L189.579 528.722 L189.579 532.657 L169.672 532.657 L169.672 528.722 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M209.024 501.176 Q205.413 501.176 203.584 504.741 Q201.778 508.283 201.778 515.412 Q201.778 522.519 203.584 526.083 Q205.413 529.625 209.024 529.625 Q212.658 529.625 214.463 526.083 Q216.292 522.519 216.292 515.412 Q216.292 508.283 214.463 504.741 Q212.658 501.176 209.024 501.176 M209.024 497.472 Q214.834 497.472 217.889 502.079 Q220.968 506.662 220.968 515.412 Q220.968 524.139 217.889 528.745 Q214.834 533.329 209.024 533.329 Q203.214 533.329 200.135 528.745 Q197.079 524.139 197.079 515.412 Q197.079 506.662 200.135 502.079 Q203.214 497.472 209.024 497.472 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M233.645 480.477 L224.053 495.467 L233.645 495.467 L233.645 480.477 M232.648 477.167 L237.425 477.167 L237.425 495.467 L241.431 495.467 L241.431 498.627 L237.425 498.627 L237.425 505.247 L233.645 505.247 L233.645 498.627 L220.968 498.627 L220.968 494.959 L232.648 477.167 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M63.7467 204.302 Q60.4134 204.302 58.4921 206.084 Q56.5939 207.867 56.5939 210.992 Q56.5939 214.117 58.4921 215.899 Q60.4134 217.682 63.7467 217.682 Q67.08 217.682 69.0013 215.899 Q70.9226 214.094 70.9226 210.992 Q70.9226 207.867 69.0013 206.084 Q67.1032 204.302 63.7467 204.302 M59.0708 202.311 Q56.0615 201.571 54.3717 199.51 Q52.7051 197.45 52.7051 194.487 Q52.7051 190.344 55.6449 187.936 Q58.6078 185.529 63.7467 185.529 Q68.9087 185.529 71.8485 187.936 Q74.7883 190.344 74.7883 194.487 Q74.7883 197.45 73.0985 199.51 Q71.4318 201.571 68.4457 202.311 Q71.8253 203.098 73.7003 205.39 Q75.5985 207.682 75.5985 210.992 Q75.5985 216.015 72.5198 218.7 Q69.4642 221.385 63.7467 221.385 Q58.0291 221.385 54.9504 218.7 Q51.8949 216.015 51.8949 210.992 Q51.8949 207.682 53.793 205.39 Q55.6912 203.098 59.0708 202.311 M57.3578 194.927 Q57.3578 197.612 59.0245 199.117 Q60.7143 200.621 63.7467 200.621 Q66.7559 200.621 68.4457 199.117 Q70.1587 197.612 70.1587 194.927 Q70.1587 192.242 68.4457 190.737 Q66.7559 189.233 63.7467 189.233 Q60.7143 189.233 59.0245 190.737 Q57.3578 192.242 57.3578 194.927 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M83.9086 214.834 L88.7928 214.834 L88.7928 220.714 L83.9086 220.714 L83.9086 214.834 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M108.978 189.233 Q105.367 189.233 103.538 192.797 Q101.733 196.339 101.733 203.469 Q101.733 210.575 103.538 214.14 Q105.367 217.682 108.978 217.682 Q112.612 217.682 114.418 214.14 Q116.246 210.575 116.246 203.469 Q116.246 196.339 114.418 192.797 Q112.612 189.233 108.978 189.233 M108.978 185.529 Q114.788 185.529 117.844 190.135 Q120.922 194.719 120.922 203.469 Q120.922 212.195 117.844 216.802 Q114.788 221.385 108.978 221.385 Q103.168 221.385 100.089 216.802 Q97.0335 212.195 97.0335 203.469 Q97.0335 194.719 100.089 190.135 Q103.168 185.529 108.978 185.529 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M157.311 195.251 L146.732 205.876 L157.311 216.455 L154.556 219.256 L143.931 208.631 L133.306 219.256 L130.575 216.455 L141.131 205.876 L130.575 195.251 L133.306 192.45 L143.931 203.075 L154.556 192.45 L157.311 195.251 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M169.672 216.779 L177.311 216.779 L177.311 190.413 L169.001 192.08 L169.001 187.821 L177.265 186.154 L181.94 186.154 L181.94 216.779 L189.579 216.779 L189.579 220.714 L169.672 220.714 L169.672 216.779 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M209.024 189.233 Q205.413 189.233 203.584 192.797 Q201.778 196.339 201.778 203.469 Q201.778 210.575 203.584 214.14 Q205.413 217.682 209.024 217.682 Q212.658 217.682 214.463 214.14 Q216.292 210.575 216.292 203.469 Q216.292 196.339 214.463 192.797 Q212.658 189.233 209.024 189.233 M209.024 185.529 Q214.834 185.529 217.889 190.135 Q220.968 194.719 220.968 203.469 Q220.968 212.195 217.889 216.802 Q214.834 221.385 209.024 221.385 Q203.214 221.385 200.135 216.802 Q197.079 212.195 197.079 203.469 Q197.079 194.719 200.135 190.135 Q203.214 185.529 209.024 185.529 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M233.645 168.534 L224.053 183.523 L233.645 183.523 L233.645 168.534 M232.648 165.224 L237.425 165.224 L237.425 183.523 L241.431 183.523 L241.431 186.683 L237.425 186.683 L237.425 193.304 L233.645 193.304 L233.645 186.683 L220.968 186.683 L220.968 183.016 L232.648 165.224 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip262)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  336.167,1443.76 349.306,1437.43 362.446,1418.7 375.586,1436.25 388.726,1432.18 401.866,1403.81 415.006,1404.25 428.146,1433.02 441.286,1441.17 454.426,1438.58 \n  467.566,1429.17 480.706,1439.55 493.846,1433.12 506.986,1438.26 520.126,1426.14 533.266,1435.23 546.406,1431.9 559.546,1362.6 572.686,1366.68 585.826,1423.06 \n  598.966,1383.68 612.106,1433.1 625.246,1441.09 638.386,1432.28 651.526,1428.99 664.665,1429.44 677.805,1438.42 690.945,1441.16 704.085,1440.14 717.225,1435.88 \n  730.365,1437.79 743.505,1444 756.645,1280.66 769.785,1437.97 782.925,1444.65 796.065,1439.83 809.205,1444.74 822.345,1314.32 835.485,1444.73 848.625,1425.8 \n  861.765,1444.77 874.905,1437.78 888.045,1444.48 901.185,1436.88 914.325,1444.77 927.465,1354.42 940.605,1444.79 953.745,1409.99 966.885,1445.17 980.024,1440.2 \n  993.164,1445.38 1006.3,1426.88 1019.44,1444.86 1032.58,1444.82 1045.72,1444.93 1058.86,1327.52 1072,1444.89 1085.14,1444.8 1098.28,1114.03 1111.42,1444.81 \n  1124.56,1444.92 1137.7,1444.85 1150.84,1444.78 1163.98,1444.76 1177.12,1444.81 1190.26,1444.83 1203.4,1444.75 1216.54,1444.82 1229.68,1445.72 1242.82,1444.43 \n  1255.96,1436.25 1269.1,647.049 1282.24,1399.57 1295.38,1444.27 1308.52,1444.75 1321.66,1444.79 1334.8,1444.84 1347.94,1426.82 1361.08,1431.32 1374.22,1382.51 \n  1387.36,1444.77 1400.5,1444.77 1413.64,1444.77 1426.78,1444.78 1439.92,1444.79 1453.06,1444.79 1466.2,1444.72 1479.34,1444.52 1492.48,1224.82 1505.62,1437.31 \n  1518.76,1444.81 1531.9,1438.65 1545.04,1437.7 1558.18,1238.9 1571.32,1444.21 1584.46,87.9763 1597.6,1444.23 1610.74,1431.74 1623.88,1425.29 1637.02,446.255 \n  1650.16,1444.82 1663.3,1444.76 1676.44,1444.79 1689.58,1444.73 1702.72,1378.61 1715.86,1352.15 1729,1385.98 1742.14,1367.41 1755.28,1246.34 1768.42,330.839 \n  1781.56,1382.58 1794.7,1412.79 1807.84,1369.62 1820.98,1424.04 1834.12,1430.88 1847.26,1429.73 1860.4,1433.83 1873.54,1211.97 1886.68,1439.94 1899.82,1437.74 \n  1912.96,1435.28 1926.1,1427.08 1939.24,1391.39 1952.38,1430.74 1965.52,1231.64 1978.66,1398.98 1991.8,1417.85 2004.94,1106.23 2018.08,1344.55 2031.22,1420.41 \n  2044.36,1438.94 2057.5,1412.2 2070.64,1254.7 2083.78,1444.53 2096.92,1444.52 2110.06,1358.85 2123.2,1444.16 2136.34,1427.2 2149.48,1427.45 2162.62,1414.74 \n  2175.76,1360.53 2188.9,1436.13 2202.04,449.345 2215.18,1396.11 2228.32,1444.31 2241.46,1355.32 2254.6,1426 2267.74,1434.05 2280.88,1444.17 2294.02,1444.36 \n  \n  \"/>\n<path clip-path=\"url(#clip260)\" d=\"\nM2023.62 198.898 L2283.58 198.898 L2283.58 95.2176 L2023.62 95.2176  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2023.62,198.898 2283.58,198.898 2283.58,95.2176 2023.62,95.2176 2023.62,198.898 \n  \"/>\n<polyline clip-path=\"url(#clip260)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2046.67,147.058 2185.03,147.058 \n  \"/>\n<path clip-path=\"url(#clip260)\" d=\"M2221.93 166.745 Q2220.13 171.375 2218.41 172.787 Q2216.7 174.199 2213.83 174.199 L2210.43 174.199 L2210.43 170.634 L2212.93 170.634 Q2214.69 170.634 2215.66 169.8 Q2216.63 168.967 2217.81 165.865 L2218.58 163.921 L2208.09 138.412 L2212.6 138.412 L2220.7 158.689 L2228.81 138.412 L2233.32 138.412 L2221.93 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M2240.61 160.402 L2248.25 160.402 L2248.25 134.037 L2239.94 135.703 L2239.94 131.444 L2248.2 129.778 L2252.88 129.778 L2252.88 160.402 L2260.52 160.402 L2260.52 164.338 L2240.61 164.338 L2240.61 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plot the stuff\n",
    "plot(episode_test_reward_hook.rewards)\n",
    "\n",
    "# plot(episode_test_reward_hook.rewards, ylim=(-25, 100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "close_visualization(); # closes the MeshCat visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
