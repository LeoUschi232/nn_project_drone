{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1m┌ \u001B[22m\u001B[39m\u001B[36m\u001B[1mInfo: \u001B[22m\u001B[39mMeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "\u001B[36m\u001B[1m└ \u001B[22m\u001B[39mhttp://127.0.0.1:8700\n"
     ]
    }
   ],
   "source": [
    "## Init Bionic VTOL\n",
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position\n",
    "\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;\n",
    "using Distributions;\n",
    "\n",
    "using Plots;\n",
    "using Statistics;\n",
    "\n",
    "using BSON: @save, @load # save mode\n",
    "create_visualization();\n",
    "\n",
    "# indicates how many threads Julia was started with. This is important for the multi-threaded environment\n",
    "Threads.nthreads()\n",
    "### Create Reinforcement Learning Environment\n",
    "\n",
    "\n",
    "################################ TODO ################################\n",
    "# You can initialization global constants here.\n",
    "# E.g. a fixed point in the beginning of training (for testing/overfitting)\n",
    "# Define global constants for initial position and rotation\n",
    "\n",
    "#####\n",
    "##### first coordinate - red axis - x\n",
    "##### second coordinate - green axis - y\n",
    "##### third coordinate - blue axis - z\n",
    "#####\n",
    "x_init = [0.0, 0.0, 0.0];\n",
    "rot_init = Matrix(UnitQuaternion(RotZ(-pi/2.0) * RotY(-pi/2.0) * RotX(pi)));\n",
    "\n",
    "# Defaault values for VtolEnv variables\n",
    "waypoints_default = generate_trajectory(2);\n",
    "proximity_tolerance_default = 0.25;\n",
    "timeout_default = 30.0;\n",
    "\n",
    "v_min_default = 1.0;\n",
    "v_max_default = 2.0;\n",
    "w_max_default = 15.0;;\n",
    "\n",
    "######################################################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[1mTest Summary:              | \u001B[22m\u001B[32m\u001B[1mPass  \u001B[22m\u001B[39m\u001B[36m\u001B[1mTotal  \u001B[22m\u001B[39m\u001B[0m\u001B[1mTime\u001B[22m\n",
      "random policy with VtolEnv | \u001B[32m2000  \u001B[39m\u001B[36m 2000  \u001B[39m\u001B[0m1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m\u001B[1m┌ \u001B[22m\u001B[39m\u001B[36m\u001B[1mInfo: \u001B[22m\u001B[39mThe GPU function is being called but the GPU is not accessible. \n",
      "\u001B[36m\u001B[1m└ \u001B[22m\u001B[39mDefaulting back to the CPU. (No action is required if you want to run on the CPU).\n"
     ]
    }
   ],
   "source": [
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv # Parametric Constructor for a subtype of AbstractEnv\n",
    "    action_space::A # action space\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}} # observation space\n",
    "    state::Vector{T} # current state space\n",
    "    action::ACT # action space\n",
    "    done::Bool # done\n",
    "    t::T # time\n",
    "    rng::R # random number generator\n",
    "\n",
    "    name::String # for multible environments\n",
    "    visualization::Bool # visualization\n",
    "    realtime::Bool # realtime\n",
    "\n",
    "    x_previous::Vector{T} # previous position\n",
    "    x_W::Vector{T} # current position\n",
    "    v_B::Vector{T} # velocity\n",
    "    R_W::Matrix{T} # current rotation\n",
    "    w_B::Vector{T} # rotation velocitiy\n",
    "    wind_W::Vector{T} # wind\n",
    "    delta_t::T # simulation time step\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Extend the environment here.\n",
    "    # Everything you need additionaly in your environment also go in here.\n",
    "    # E.g. a trajectory\n",
    "\n",
    "    # Pathway variables\n",
    "    waypoints::Vector{Vector{T}}\n",
    "    proximity_tolerance::T\n",
    "    timeout::T\n",
    "\n",
    "    # Kinetic variables\n",
    "    v_min::T\n",
    "    v_max::T # maximum allowed velocity\n",
    "    w_max::T # maximum allowed velocity\n",
    "\n",
    "    ######################################################################\n",
    "end\n",
    "\n",
    "\n",
    "# define a keyword-based constructor for the type declared in the mutable struct typedef.\n",
    "# It could also be done with the macro Base.@kwdef.\n",
    "function VtolEnv(;\n",
    "    rng = Random.GLOBAL_RNG, # random number generation\n",
    "    name = \"vtol\",\n",
    "            visualization = false,\n",
    "    realtime = false,\n",
    "    kwargs...) # let the function take an arbitrary number of keyword arguments\n",
    "\n",
    "    T = Float64; # explicit type which is used e.g. in state. Cannot be altered due to the poor matrix defininon.\n",
    "    A = Space{Vector{ClosedInterval{T}}};\n",
    "\n",
    "    action_space = Space(\n",
    "        ClosedInterval{T}[\n",
    "            0.0..2.0, # propeller 1\n",
    "            0.0..2.0, # propeller 2\n",
    "            ],\n",
    "    ) # propeller 1 and 2\n",
    "\n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            ################################ TODO ################################\n",
    "            # Implement an observation space.\n",
    "            # Here is an example space. You can change it if desired.\n",
    "            # You have to extend it.\n",
    "            # Orientate yourself on the observation space from the paper.\n",
    "\n",
    "            typemin(T)..typemax(T), #1 previous position along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #2 previous position along z WORLD coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #3 current position along x WORLD coordinates\n",
    "            typemin(T)..typemax(T), #4 current position along z WORLD coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #7 velocity along x BODY coordinates\n",
    "            typemin(T)..typemax(T), #8 velocity along y BODY coordinates\n",
    "\n",
    "            typemin(T)..typemax(T), #9 rotational velocity along z BODY coordinates\n",
    "            ######################################################################\n",
    "            ],\n",
    "    )\n",
    "\n",
    "    if visualization # visualizes VTOL\n",
    "        create_VTOL(name, actuators = true, color_vec=[1.0; 1.0; 0.6; 1.0]);\n",
    "    end\n",
    "\n",
    "    environment = VtolEnv(\n",
    "        action_space, # action space\n",
    "        state_space, # observation space\n",
    "        zeros(T, length(state_space)), # current state space\n",
    "        rand(action_space), # initialization action\n",
    "        false, # episode done\n",
    "        0.0, # time\n",
    "        rng, # random number generator\n",
    "\n",
    "        name,\n",
    "        visualization,\n",
    "        realtime,\n",
    "\n",
    "        zeros(T, 3), # x_previous, previous position\n",
    "        zeros(T, 3), # x_W, current position\n",
    "        zeros(T, 3), # v_B, velocity\n",
    "        rot_init, # R_W, current rotation\n",
    "        zeros(T, 3), # w_B\n",
    "        zeros(T, 3), # wind_W\n",
    "        T(0.02), # simulation time step\n",
    "\n",
    "        ################################## TODO ##################################\n",
    "        # Initialization everything you need additionaly in your environment here\n",
    "\n",
    "        waypoints_default,\n",
    "        proximity_tolerance_default,\n",
    "        timeout_default,\n",
    "        v_min_default,\n",
    "        v_max_default,\n",
    "        w_max_default,\n",
    "        ##########################################################################\n",
    "    )\n",
    "\n",
    "    reset!(environment)\n",
    "    return environment\n",
    "end;\n",
    "\n",
    "methods(VtolEnv)\n",
    "\n",
    "# Just for explanation:\n",
    "# 1. A mutable Struct is created. A struct is a constructor and a constructor is a function that creates new objects.\n",
    "# 2. A outer keyword-based constructor method is added for the type declared in the mutable struct typedef before.'\n",
    "# So now we have a function with two methods. Julia will decide which method to call by multiple dispatch.\n",
    "\n",
    "## Define the RL interface\n",
    "\n",
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state\n",
    "\n",
    "function computeReward(env::VtolEnv{A,T}) where {A,T}\n",
    "    reward = 0.0\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Implement the reward function.\n",
    "    # Orientate on the paper.\n",
    "\n",
    "    # Hyperparameters\n",
    "    kp = 5.0;\n",
    "    kw = 0.01;\n",
    "    kwp = 5.0;\n",
    "    # max distance\n",
    "    dmax = 0.3;\n",
    "\n",
    "    # Gates and their length\n",
    "    gates = env.waypoints;\n",
    "    n = length(gates);\n",
    "\n",
    "    # closest point on the guiding path phi\n",
    "    # its line-segment index lp\n",
    "    x_old = [env.state[1], 0.0, env.state[2]];\n",
    "    x_new = [env.state[3], 0.0, env.state[4]];\n",
    "    lp_old, phi_old = calculate_progress(gates, x_old);\n",
    "    lp_new, phi_new = calculate_progress(gates, x_new);\n",
    "\n",
    "    # previous time step spt_old\n",
    "    # current time step spt_new\n",
    "    spt_old = norm(phi_old - gates[lp_old]);\n",
    "    spt_new = norm(phi_new - gates[lp_new]);\n",
    "\n",
    "    # rogress reward rpt at time t is as a difference in reached\n",
    "    # distance between the current and previous time step\n",
    "    rpt = spt_new - spt_old\n",
    "    spt = spt_new\n",
    "\n",
    "    # The sum that is later going to be the divisor\n",
    "    # for the reached distance reward\n",
    "    divisor_g = norm(gates[2] - gates[1]);\n",
    "\n",
    "    # reached distance reward ks\n",
    "    ks = 2 * env.v_max * env.delta_t / divisor_g;\n",
    "\n",
    "    # steered at waypoint must be 1 bigger than the current line segment\n",
    "    # distance to new waypoint dw\n",
    "    dwp = norm(x_new - gates[2]);\n",
    "    # tolerance for proximity to a waypoint\n",
    "    r_tol = env.proximity_tolerance;\n",
    "\n",
    "    # waypoint reward rwp\n",
    "    rwp = exp(-dwp/r_tol);\n",
    "\n",
    "    # no obstacles\n",
    "    collision = false;\n",
    "    # terminal reward rt\n",
    "    rt = collision ? 10 : 0;\n",
    "\n",
    "    # absolute velocity\n",
    "    v_vector = [env.state[5], env.state[6], 0.0]\n",
    "    v = norm(v_vector);\n",
    "    # rotation speed\n",
    "    w = abs(env.state[7]);\n",
    "    # distance from closes point on the guiding path\n",
    "    gd = norm(x_new - phi_new);\n",
    "\n",
    "    # Scaling factors\n",
    "    svmax = v > env.v_max ? 10^(env.v_max - v) : 1.0;\n",
    "    svmin = v < env.v_min ?  10^(v - env.v_min) : 1.0;\n",
    "    sgd = gd > dmax  ? exp(dmax - gd) : 1.0;\n",
    "\n",
    "    # Ultimate scaling factor\n",
    "    s = svmax * svmin * sgd;\n",
    "\n",
    "    # Scaling the rewards\n",
    "    kp = s * kp;\n",
    "    ks = s * ks;\n",
    "\n",
    "    #### Punishment for stupidity and autism\n",
    "    # Punish for falling down\n",
    "    kz = 1.5 / (1.0 + env.t);\n",
    "    rz = (min(0, env.state[4]))^2;\n",
    "    # Punish for attempting to quickly end the simulation at the beginning due to high rotation acceleration\n",
    "    rz += (w * max(0, 0.5 - env.t))^2;\n",
    "    kw *= max(1.0, 4.0 - env.t);\n",
    "\n",
    "    # Sum up positive reinforcement and negative reinforcement\n",
    "    positive_r = kp * rpt + ks * spt + kwp * rwp;\n",
    "    negative_r = kw * w + rt + kz * rz;\n",
    "\n",
    "    # Sum it all\n",
    "    reward = positive_r - negative_r;\n",
    "\n",
    "    # Increase reward for better timing after performance threshold\n",
    "    perf_th = 200.0;\n",
    "    if(reward > perf_th)\n",
    "        reward *= (1.0 / (dwp^2 * env.t))\n",
    "        if(dwp < env.proximity_tolerance)\n",
    "            reward *= reward;\n",
    "        end\n",
    "    end\n",
    "\n",
    "\n",
    "    ################################################################################################\n",
    "\n",
    "    return reward\n",
    "end\n",
    "\n",
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = computeReward(env)\n",
    "\n",
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    # Visualize initial state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, [0.0; 0.0; 0.0; 0.0]);\n",
    "    end\n",
    "\n",
    "    env.x_W = [0.0; 0.0; 0.0];\n",
    "    env.v_B = [0.0; 0.0; 0.0];\n",
    "    env.R_W = rot_init;\n",
    "\n",
    "    env.w_B = [0.0; 0.0; 0.0];\n",
    "    env.wind_W = [0.0; 0.0; 0.0];\n",
    "\n",
    "    env.t = 0.0;\n",
    "    env.action = [0.0, 0.0];\n",
    "    env.done = false;\n",
    "\n",
    "    ################################ TODO ################################\n",
    "    # Reset environment.\n",
    "    # Is called if the training terminates\n",
    "    # (e.g. if drone crashes or successfully reaches point)\n",
    "    # HINT: Everything you added to your environment needs to be reseted.\n",
    "    #       Compare it with the initialization.\n",
    "\n",
    "    env.state[1] = env.x_previous[1]; # update previous x-coordinate\n",
    "    env.state[2] = env.x_previous[3]; # update previous z-coordinate\n",
    "\n",
    "    env.state[3] = env.x_W[1]; # position along x\n",
    "    env.state[4] = env.x_W[3]; # position along z\n",
    "\n",
    "    env.state[5] = env.v_B[1]; # velocity along x BODY coordinates\n",
    "    env.state[6] = env.v_B[2]; # velocity along y BODY coordinates\n",
    "\n",
    "    env.state[7] = env.w_B[3];  # rotational velocity along z BODY coordinates\n",
    "\n",
    "    env.x_previous = x_init; # starting position\n",
    "    env.delta_t = T(0.02); # Δ time\n",
    "\n",
    "    env.waypoints = waypoints_default;\n",
    "    env.proximity_tolerance = proximity_tolerance_default;\n",
    "    env.timeout = timeout_default;\n",
    "    env.v_min = v_min_default;\n",
    "    env.v_max = v_max_default;\n",
    "    env.w_max = w_max_default;\n",
    "\n",
    "    # Visualize the waypoints\n",
    "    radius = 0.1;\n",
    "    visualize_waypoints(env.waypoints, radius);\n",
    "    ######################################################################\n",
    "\n",
    "    nothing\n",
    "end;\n",
    "\n",
    "# defines a methods for a callable object.\n",
    "# So when a VtolEnv object is created, it has this method that can be called\n",
    "function (env::VtolEnv)(a)\n",
    "    # set the propeller trust and the two flaps 2D case\n",
    "    # flaps set to 0.0\n",
    "    next_action = [a[1], a[2], 0.0, 0.0]\n",
    "\n",
    "    _step!(env, next_action)\n",
    "end\n",
    "\n",
    "env = VtolEnv();\n",
    "methods(env) # Just to explain which methods the object has\n",
    "\n",
    "\n",
    "function _step!(env::VtolEnv, next_action)\n",
    "    # Update previous\n",
    "    env.x_previous = [env.state[3], 0.0, env.state[4]];\n",
    "\n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(env.v_B, env.R_W, env.wind_W);\n",
    "\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = vtol_model(v_in_wind_B, next_action, eth_vtol_param);\n",
    "\n",
    "    # Limit to 2D\n",
    "    force_B[3] = 0.0; # Body Z\n",
    "    env.v_B[3] = 0.0;\n",
    "    torque_B[1] = 0.0;\n",
    "    torque_B[2] = 0.0;  # Body X and Y\n",
    "    env.w_B[1] = 0.0;\n",
    "    env.w_B[2] = 0.0;\n",
    "\n",
    "    # integrate rigid body dynamics for delta_t\n",
    "    env.x_W, env.v_B, env.R_W, env.w_B, time = rigid_body_simple(torque_B, force_B, env.x_W, env.v_B, env.R_W, env.w_B, env.t, env.delta_t, eth_vtol_param);\n",
    "\n",
    "    if env.realtime\n",
    "        sleep(env.delta_t); # just a dirty hack. this is of course slower than real time.\n",
    "    end\n",
    "\n",
    "    # Visualize the new state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, next_action);\n",
    "    end\n",
    "\n",
    "    env.t += env.delta_t\n",
    "\n",
    "\n",
    "    ################################ TODO ################################\n",
    "\n",
    "    env.state[1] = env.x_previous[1]; # update previous x-coordinate\n",
    "    env.state[2] = env.x_previous[3]; # update previous z-coordinate\n",
    "\n",
    "    env.state[3] = env.x_W[1]; # position along x\n",
    "    env.state[4] = env.x_W[3]; # position along z\n",
    "\n",
    "    env.state[5] = env.v_B[1]; # velocity along x BODY coordinates\n",
    "    env.state[6] = env.v_B[2]; # velocity along y BODY coordinates\n",
    "\n",
    "    env.state[7] = env.w_B[3];  # rotational velocity along z BODY coordinates\n",
    "\n",
    "    # Instead of the floor level which assumes the simulation will only run upstairs,\n",
    "    # Here a variables for being too far from the next wp after reaching a previous waypoint can be used instead\n",
    "\n",
    "    segment_length = norm(env.waypoints[2] - env.waypoints[1])\n",
    "    k_failure = 1.5;\n",
    "    wp_dist = norm(env.waypoints[2] - env.x_W)\n",
    "\n",
    "    env.done =\n",
    "        norm(env.w_B) > env.w_max || # stop if body rate is too high\n",
    "        wp_dist > k_failure * segment_length ||\n",
    "        env.t > env.timeout ||\n",
    "        wp_dist < env.proximity_tolerance;\n",
    "    ######################################################################\n",
    "\n",
    "    nothing\n",
    "end;\n",
    "\n",
    "RLBase.test_runnable!(env)\n",
    "\n",
    "# changed to 10s (5s before) per point and 5.0m too far off path (2.0 before)\n",
    "# Show an overview of the environment.\n",
    "\n",
    "## Setup of a reinforcement learning experiment.\n",
    "\n",
    "seed = 123\n",
    "rng = StableRNG(seed)\n",
    "    N_ENV = 8\n",
    "    UPDATE_FREQ = 1024\n",
    "\n",
    "    vtol_envs = [\n",
    "        # use different names for the visualization\n",
    "        VtolEnv(; rng = StableRNG(hash(seed+i)), name = \"vtol$i\") for i in 1:N_ENV\n",
    "    ];\n",
    "    # define multiple environments for parallel training\n",
    "    env = MultiThreadEnv(vtol_envs)\n",
    "\n",
    "    # Define the function approximator\n",
    "    # TODO: research briefly what Actor Critic is\n",
    "    # TODO: research what ADAM is\n",
    "    # Define the function approximator\n",
    "    ns, na = length(state(env[1])), length(action_space(env[1]))\n",
    "    #ActorCritic Policy\n",
    "    approximator = ActorCritic(\n",
    "                #ns - number states as input\n",
    "                #3 layer; last layer splitted in mean and variance; then action is sampled\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                        Dense(ns, 32, relu; initW = glorot_uniform(rng)),\n",
    "                        Dense(32, 16, relu; initW = glorot_uniform(rng)),\n",
    "                        Dense(16, 16, relu; initW = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(\n",
    "                        Dense(16, na; initW = glorot_uniform(rng))\n",
    "                    ),\n",
    "                    logσ = Chain(\n",
    "                        Dense(16, na; initW = glorot_uniform(rng))\n",
    "                    ),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 32, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(32, 16, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(16, 1; initW = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(1e-3),\n",
    "            );\n",
    "\n",
    "        agent = Agent( # A wrapper of an AbstractPolicy\n",
    "        # AbstractPolicy: the policy to use\n",
    "        # (optional) TODO: change eventually\n",
    "        # TODO: research briefly what PPO is\n",
    "        policy = PPOPolicy(;\n",
    "                    approximator = approximator |> gpu,\n",
    "                    update_freq=UPDATE_FREQ,\n",
    "                    dist = Normal,\n",
    "                    # For parameters visit the docu: https://juliareinforcementlearning.org/docs/rlzoo/#ReinforcementLearningZoo.PPOPolicy\n",
    "                    ),\n",
    "\n",
    "        # AbstractTrajectory: used to store transitions between an agent and an environment source\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float64} => (ns, N_ENV),\n",
    "            action = Matrix{Float64} => (na, N_ENV),\n",
    "            action_log_prob = Vector{Float64} => (N_ENV,),\n",
    "            reward = Vector{Float64} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    );\n",
    "\n",
    "\n",
    "function saveModel(t, agent, env)\n",
    "    model = cpu(agent.policy.approximator)\n",
    "    f = joinpath(\"./RL_models_2dpoint_leo/\", \"vtol_2D_ppo_$t.bson\") # TODO: save model here\n",
    "    @save f model\n",
    "    println(\"parameters at step $t saved to $f\")\n",
    "end;\n",
    "\n",
    "function loadModel()\n",
    "    f = joinpath(\"./RL_models_2dpoint_leo/\", \"vtol_2D_ppo_1500000.bson\") # TODO: load model here\n",
    "    @load f model\n",
    "    return model\n",
    "end;\n",
    "\n",
    "function validate_policy(t, agent, env)\n",
    "    run(agent.policy, test_env, StopAfterEpisode(1), episode_test_reward_hook)\n",
    "    # the result of the hook\n",
    "    println(\"test reward at step $t: $(episode_test_reward_hook.rewards[end])\")\n",
    "\n",
    "end;\n",
    "\n",
    "episode_test_reward_hook = TotalRewardPerEpisode(;is_display_on_exit=false)\n",
    "# create a env only for reward test\n",
    "test_env = VtolEnv(;name = \"testVTOL\", visualization = true, realtime = true);\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   0%|▏                                        |  ETA: 2:07:06\u001B[39mm9m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 10000: -22.112987803586453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   1%|▌                                        |  ETA: 0:49:40\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 20000: -15.433201454094696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   2%|▊                                        |  ETA: 0:37:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 30000: -6.871662332595153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   3%|█▏                                       |  ETA: 0:28:18\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 40000: -4.381534053375947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   3%|█▍                                       |  ETA: 0:25:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 50000: 0.0906407599217857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   4%|█▋                                       |  ETA: 0:23:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 60000: 1.2322690947775805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   4%|█▉                                       |  ETA: 0:21:56\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 70000: 5.7287800651043685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   5%|██▏                                      |  ETA: 0:20:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 80000: 8.943092199107117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   6%|██▍                                      |  ETA: 0:19:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 90000: 7.147785482446718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   6%|██▋                                      |  ETA: 0:18:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 100000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_100000.bson\n",
      "test reward at step 100000: 43.74240483424256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   7%|██▉                                      |  ETA: 0:18:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 110000: 20.497484567049426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   8%|███▎                                     |  ETA: 0:18:30\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 120000: 50.41167608739751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   8%|███▌                                     |  ETA: 0:18:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 130000: 10.109160131899698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:   9%|███▊                                     |  ETA: 0:17:54\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 140000: 39.0991769554599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  10%|████▏                                    |  ETA: 0:17:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 150000: 55.23822337249824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  10%|████▎                                    |  ETA: 0:18:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 160000: 34.13865825306356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  11%|████▌                                    |  ETA: 0:19:05\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 170000: 16.10726392337598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  12%|████▉                                    |  ETA: 0:19:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 180000: 14.75275457103605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  13%|█████▏                                   |  ETA: 0:19:30\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 190000: 36.293785627942356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  13%|█████▍                                   |  ETA: 0:20:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 200000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_200000.bson\n",
      "test reward at step 200000: 4.267785717054093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  14%|█████▋                                   |  ETA: 0:20:27\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 210000: 2.921621371809056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  14%|█████▉                                   |  ETA: 0:19:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 220000: 3.46031776945174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  15%|██████▎                                  |  ETA: 0:19:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 230000: 165.65232136989718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  16%|██████▌                                  |  ETA: 0:20:05\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 240000: 4.142343982116885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  17%|██████▉                                  |  ETA: 0:19:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 250000: 42.206282866472165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  17%|███████                                  |  ETA: 0:19:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 260000: 24.43986041126023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  18%|███████▎                                 |  ETA: 0:19:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 270000: 4.881314402243058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  18%|███████▋                                 |  ETA: 0:19:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 280000: 2.493822781765382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  19%|███████▉                                 |  ETA: 0:18:44\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 290000: 5.586207972744116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  20%|████████▏                                |  ETA: 0:18:20\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 300000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_300000.bson\n",
      "test reward at step 300000: 17.676537549101273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  21%|████████▌                                |  ETA: 0:17:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 310000: 15.35747668451619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  21%|████████▊                                |  ETA: 0:17:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 320000: 9.215827601006007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  22%|█████████                                |  ETA: 0:17:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 330000: 37.85158912216359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  22%|█████████▏                               |  ETA: 0:17:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 340000: 30.370661280671328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  23%|█████████▌                               |  ETA: 0:16:35\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 350000: 34.244619889430574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  24%|█████████▊                               |  ETA: 0:16:10\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 360000: 16.202541274156836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  24%|██████████                               |  ETA: 0:15:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 370000: 26.808064546405042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  25%|██████████▍                              |  ETA: 0:15:39\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 380000: 25.996171992242985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  26%|██████████▌                              |  ETA: 0:15:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 390000: 27.169702115710066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  27%|██████████▉                              |  ETA: 0:15:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 400000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_400000.bson\n",
      "test reward at step 400000: 76.83711218260595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  27%|███████████▎                             |  ETA: 0:15:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 410000: 70.8625144338279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  28%|███████████▍                             |  ETA: 0:16:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 420000: 84.0524666423586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  28%|███████████▋                             |  ETA: 0:16:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 430000: 149.0596725092931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  29%|████████████                             |  ETA: 0:16:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 440000: 244.33445229137564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  30%|████████████▎                            |  ETA: 0:16:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 450000: 666.966433739102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  31%|████████████▋                            |  ETA: 0:17:54\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 460000: 509.926925138161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  31%|████████████▊                            |  ETA: 0:17:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 470000: 796.6886409269687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  32%|█████████████                            |  ETA: 0:18:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 480000: 25.798371068865354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  33%|█████████████▍                           |  ETA: 0:17:54\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 490000: 66.37580702196084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  33%|█████████████▋                           |  ETA: 0:17:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 500000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_500000.bson\n",
      "test reward at step 500000: 2.276864938043206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  34%|█████████████▉                           |  ETA: 0:17:31\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 510000: 16.435650389628982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  35%|██████████████▎                          |  ETA: 0:17:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 520000: 27.665097997953794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  35%|██████████████▍                          |  ETA: 0:16:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 530000: 18.82061963810793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  36%|██████████████▊                          |  ETA: 0:16:32\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 540000: 19.997593974023594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  37%|███████████████                          |  ETA: 0:16:13\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 550000: 19.52962774214306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  37%|███████████████▏                         |  ETA: 0:16:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 560000: 19.62875807478935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  38%|███████████████▌                         |  ETA: 0:15:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 570000: 22.73587618648188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  38%|███████████████▊                         |  ETA: 0:15:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 580000: 3.1183011973172166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  39%|████████████████▏                        |  ETA: 0:15:13\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 590000: 2.2435330518897083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  40%|████████████████▎                        |  ETA: 0:15:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 600000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_600000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  40%|████████████████▍                        |  ETA: 0:15:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 600000: 2.5654278627258575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  40%|████████████████▌                        |  ETA: 0:14:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 610000: 7.413772095557339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  41%|████████████████▉                        |  ETA: 0:14:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 620000: 22.58315869685561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  42%|█████████████████▏                       |  ETA: 0:14:07\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 630000: 7.631256150199045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  43%|█████████████████▌                       |  ETA: 0:13:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 640000: 8.957688609918682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  43%|█████████████████▊                       |  ETA: 0:13:32\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 650000: 15.2379658594478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  44%|█████████████████▉                       |  ETA: 0:13:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 660000: 32.268185554631955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  44%|██████████████████▎                      |  ETA: 0:13:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 670000: 24.086592375609833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  45%|██████████████████▌                      |  ETA: 0:12:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 680000: 26.05578690333408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  46%|██████████████████▉                      |  ETA: 0:12:34\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 690000: 21.140844122458898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  47%|███████████████████▏                     |  ETA: 0:12:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 700000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_700000.bson\n",
      "test reward at step 700000: 38.96163486839473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  47%|███████████████████▎                     |  ETA: 0:12:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 710000: 8.687349689947862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  48%|███████████████████▋                     |  ETA: 0:11:58\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 720000: 10.87596311417561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  48%|███████████████████▉                     |  ETA: 0:11:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 730000: 38.22662856477226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  49%|████████████████████▏                    |  ETA: 0:11:28\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 740000: 29.37152612959384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  50%|████████████████████▌                    |  ETA: 0:11:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 750000: 9.670866008410885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  51%|████████████████████▊                    |  ETA: 0:10:58\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 760000: 31.718235502132714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  51%|████████████████████▉                    |  ETA: 0:10:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 770000: 36.30964758355108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  52%|█████████████████████▎                   |  ETA: 0:10:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 780000: 32.51988893973774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  52%|█████████████████████▌                   |  ETA: 0:10:25\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 790000: 33.75495277324367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  53%|█████████████████████▊                   |  ETA: 0:10:12\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 800000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_800000.bson\n",
      "test reward at step 800000: 36.73250175488879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  54%|██████████████████████▏                  |  ETA: 0:10:00\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 810000: 31.83177112898273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  55%|██████████████████████▍                  |  ETA: 0:09:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 820000: 22.10187437597046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  55%|██████████████████████▌                  |  ETA: 0:09:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 830000: 30.847094845494127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  56%|██████████████████████▉                  |  ETA: 0:09:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 840000: 26.46210497019194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  56%|███████████████████████▏                 |  ETA: 0:09:17\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 850000: 44.221089915097174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  57%|███████████████████████▍                 |  ETA: 0:09:05\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 860000: 35.98956413748067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  58%|███████████████████████▊                 |  ETA: 0:08:54\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 870000: 26.228363545380937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  59%|████████████████████████                 |  ETA: 0:08:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 880000: 31.94621165587904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  59%|████████████████████████▍                |  ETA: 0:08:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 890000: 37.22036593765904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  60%|████████████████████████▌                |  ETA: 0:08:24\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 900000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_900000.bson\n",
      "test reward at step 900000: 32.762734475000386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  60%|████████████████████████▊                |  ETA: 0:08:12\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 910000: 24.470265669304563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  61%|█████████████████████████▏               |  ETA: 0:07:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 920000: 30.673800127615067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  62%|█████████████████████████▍               |  ETA: 0:07:47\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 930000: 17.220731544248004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  63%|█████████████████████████▋               |  ETA: 0:07:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 940000: 28.281767055800948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  63%|██████████████████████████               |  ETA: 0:07:27\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 950000: 32.955226544159196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  64%|██████████████████████████▏              |  ETA: 0:07:23\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 960000: 10.680934042483653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  64%|██████████████████████████▍              |  ETA: 0:07:12\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 970000: 34.864783423898174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  65%|██████████████████████████▋              |  ETA: 0:07:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 980000: 16.330143095140222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  66%|███████████████████████████              |  ETA: 0:06:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 990000: 23.597369603634338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  67%|███████████████████████████▎             |  ETA: 0:06:40\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1000000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1000000.bson\n",
      "test reward at step 1000000: 33.925619581088725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  67%|███████████████████████████▋             |  ETA: 0:06:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1010000: 32.03121626099388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  68%|███████████████████████████▉             |  ETA: 0:06:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1020000: 29.74905395950736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  68%|████████████████████████████             |  ETA: 0:06:14\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1030000: 36.00436498195724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  69%|████████████████████████████▍            |  ETA: 0:06:04\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1040000: 28.42562337595107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  70%|████████████████████████████▋            |  ETA: 0:05:53\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1050000: 27.938862508703288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  71%|████████████████████████████▉            |  ETA: 0:05:43\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1060000: 29.747264180934696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  71%|█████████████████████████████▎           |  ETA: 0:05:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1070000: 30.08194635239788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  72%|█████████████████████████████▍           |  ETA: 0:05:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1080000: 30.167223319563345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  72%|█████████████████████████████▊           |  ETA: 0:05:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1090000: 31.835022520560994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  73%|██████████████████████████████           |  ETA: 0:05:09\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1100000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1100000.bson\n",
      "test reward at step 1100000: 34.19694220565827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  74%|██████████████████████████████▍          |  ETA: 0:04:59\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1110000: 37.020756275679425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  75%|██████████████████████████████▋          |  ETA: 0:04:51\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1120000: 41.9012150016061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  75%|██████████████████████████████▉          |  ETA: 0:04:42\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1130000: 37.78776988366754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  76%|███████████████████████████████          |  ETA: 0:04:37\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1140000: 37.894810121745536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  76%|███████████████████████████████▍         |  ETA: 0:04:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1150000: 35.590250914566965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  77%|███████████████████████████████▋         |  ETA: 0:04:19\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1160000: 27.906698193716036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  78%|███████████████████████████████▉         |  ETA: 0:04:10\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1170000: 36.87342051882596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  79%|████████████████████████████████▎        |  ETA: 0:04:01\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1180000: 41.35647282933143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  79%|████████████████████████████████▌        |  ETA: 0:03:52\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1190000: 43.19375666740066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  80%|████████████████████████████████▋        |  ETA: 0:03:48\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1200000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1200000.bson\n",
      "test reward at step 1200000: 40.3072189400758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  81%|█████████████████████████████████        |  ETA: 0:03:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1210000: 33.07980305671393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  81%|█████████████████████████████████▎       |  ETA: 0:03:29\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1220000: 19.705035880433343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  82%|█████████████████████████████████▋       |  ETA: 0:03:21\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1230000: 44.88516947484131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  83%|█████████████████████████████████▉       |  ETA: 0:03:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1240000: 4.934662362610353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  83%|██████████████████████████████████▏      |  ETA: 0:03:07\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1250000: 27.07221676639236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  84%|██████████████████████████████████▎      |  ETA: 0:03:03\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1260000: 28.161695426355063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  84%|██████████████████████████████████▋      |  ETA: 0:02:55\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1270000: 19.336474150741925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  85%|██████████████████████████████████▉      |  ETA: 0:02:46\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1280000: 16.81861583574134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  86%|███████████████████████████████████▎     |  ETA: 0:02:38\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1290000: 30.94168112919318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  86%|███████████████████████████████████▍     |  ETA: 0:02:35\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1300000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1300000.bson\n",
      "test reward at step 1300000: 21.931529141856558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  87%|███████████████████████████████████▋     |  ETA: 0:02:25\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1310000: 30.216180640951144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  88%|████████████████████████████████████     |  ETA: 0:02:16\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1320000: 16.25468140386511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  89%|████████████████████████████████████▎    |  ETA: 0:02:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1330000: 41.92162504569069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  89%|████████████████████████████████████▋    |  ETA: 0:02:02\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1340000: 26.28047940727629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  90%|████████████████████████████████████▉    |  ETA: 0:01:54\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1350000: 27.642047825074197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  91%|█████████████████████████████████████▏   |  ETA: 0:01:45\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1360000: 26.736541625145886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  91%|█████████████████████████████████████▎   |  ETA: 0:01:41\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1370000: 50.593717715946276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  92%|█████████████████████████████████████▋   |  ETA: 0:01:33\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1380000: 43.03115580736801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  93%|█████████████████████████████████████▉   |  ETA: 0:01:26\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1390000: 36.11341490768081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  93%|██████████████████████████████████████▎  |  ETA: 0:01:18\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1400000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1400000.bson\n",
      "test reward at step 1400000: 65.16105132625863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  94%|██████████████████████████████████████▍  |  ETA: 0:01:15\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1410000: 90.10904774168215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  94%|██████████████████████████████████████▊  |  ETA: 0:01:06\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1420000: 33.18777771396452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  95%|███████████████████████████████████████  |  ETA: 0:00:57\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1430000: 32.63080346790017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  96%|███████████████████████████████████████▎ |  ETA: 0:00:49\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1440000: 71.87613416327882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  97%|███████████████████████████████████████▋ |  ETA: 0:00:40\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1450000: 66.00666404149646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  97%|███████████████████████████████████████▊ |  ETA: 0:00:36\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1460000: 47.246446488810555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  98%|████████████████████████████████████████▏|  ETA: 0:00:27\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1470000: 53.15292838719118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  99%|████████████████████████████████████████▍|  ETA: 0:00:18\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1480000: 30.507456913023862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress:  99%|████████████████████████████████████████▊|  ETA: 0:00:08\u001B[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1490000: 34.91452520359754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mProgress: 100%|█████████████████████████████████████████| Time: 0:19:47\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1500000 saved to ./RL_models_2dpoint_leo/vtol_2D_ppo_1500000.bson\n",
      "test reward at step 1500000: 57.27869485374379\n"
     ]
    }
   ],
   "source": [
    "# Run without loading the model\n",
    "\n",
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(1_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000),\n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run with loading the model\n",
    "\n",
    "agent.policy.approximator = loadModel();\n",
    "\n",
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(1_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000),\n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip390\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip390)\" d=\"\nM0 1600 L2400 1600 L2400 0 L0 0  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip391\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip390)\" d=\"\nM177.871 1486.45 L2352.76 1486.45 L2352.76 47.2441 L177.871 47.2441  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip392\">\n    <rect x=\"177\" y=\"47\" width=\"2176\" height=\"1440\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  225.654,1486.45 225.654,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  914.17,1486.45 914.17,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1602.69,1486.45 1602.69,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  2291.2,1486.45 2291.2,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  177.871,1486.45 2352.76,1486.45 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  225.654,1486.45 225.654,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  914.17,1486.45 914.17,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1602.69,1486.45 1602.69,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2291.2,1486.45 2291.2,1467.55 \n  \"/>\n<path clip-path=\"url(#clip390)\" d=\"M225.654 1517.37 Q222.043 1517.37 220.214 1520.93 Q218.409 1524.47 218.409 1531.6 Q218.409 1538.71 220.214 1542.27 Q222.043 1545.82 225.654 1545.82 Q229.289 1545.82 231.094 1542.27 Q232.923 1538.71 232.923 1531.6 Q232.923 1524.47 231.094 1520.93 Q229.289 1517.37 225.654 1517.37 M225.654 1513.66 Q231.464 1513.66 234.52 1518.27 Q237.599 1522.85 237.599 1531.6 Q237.599 1540.33 234.52 1544.94 Q231.464 1549.52 225.654 1549.52 Q219.844 1549.52 216.765 1544.94 Q213.71 1540.33 213.71 1531.6 Q213.71 1522.85 216.765 1518.27 Q219.844 1513.66 225.654 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M888.87 1514.29 L907.226 1514.29 L907.226 1518.22 L893.152 1518.22 L893.152 1526.7 Q894.17 1526.35 895.189 1526.19 Q896.208 1526 897.226 1526 Q903.013 1526 906.393 1529.17 Q909.772 1532.34 909.772 1537.76 Q909.772 1543.34 906.3 1546.44 Q902.828 1549.52 896.508 1549.52 Q894.333 1549.52 892.064 1549.15 Q889.819 1548.78 887.411 1548.04 L887.411 1543.34 Q889.495 1544.47 891.717 1545.03 Q893.939 1545.58 896.416 1545.58 Q900.42 1545.58 902.758 1543.48 Q905.096 1541.37 905.096 1537.76 Q905.096 1534.15 902.758 1532.04 Q900.42 1529.94 896.416 1529.94 Q894.541 1529.94 892.666 1530.35 Q890.814 1530.77 888.87 1531.65 L888.87 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M928.985 1517.37 Q925.374 1517.37 923.545 1520.93 Q921.74 1524.47 921.74 1531.6 Q921.74 1538.71 923.545 1542.27 Q925.374 1545.82 928.985 1545.82 Q932.619 1545.82 934.425 1542.27 Q936.254 1538.71 936.254 1531.6 Q936.254 1524.47 934.425 1520.93 Q932.619 1517.37 928.985 1517.37 M928.985 1513.66 Q934.795 1513.66 937.851 1518.27 Q940.929 1522.85 940.929 1531.6 Q940.929 1540.33 937.851 1544.94 Q934.795 1549.52 928.985 1549.52 Q923.175 1549.52 920.096 1544.94 Q917.041 1540.33 917.041 1531.6 Q917.041 1522.85 920.096 1518.27 Q923.175 1513.66 928.985 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1562.29 1544.91 L1569.93 1544.91 L1569.93 1518.55 L1561.62 1520.21 L1561.62 1515.95 L1569.89 1514.29 L1574.56 1514.29 L1574.56 1544.91 L1582.2 1544.91 L1582.2 1548.85 L1562.29 1548.85 L1562.29 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1601.64 1517.37 Q1598.03 1517.37 1596.21 1520.93 Q1594.4 1524.47 1594.4 1531.6 Q1594.4 1538.71 1596.21 1542.27 Q1598.03 1545.82 1601.64 1545.82 Q1605.28 1545.82 1607.08 1542.27 Q1608.91 1538.71 1608.91 1531.6 Q1608.91 1524.47 1607.08 1520.93 Q1605.28 1517.37 1601.64 1517.37 M1601.64 1513.66 Q1607.45 1513.66 1610.51 1518.27 Q1613.59 1522.85 1613.59 1531.6 Q1613.59 1540.33 1610.51 1544.94 Q1607.45 1549.52 1601.64 1549.52 Q1595.83 1549.52 1592.76 1544.94 Q1589.7 1540.33 1589.7 1531.6 Q1589.7 1522.85 1592.76 1518.27 Q1595.83 1513.66 1601.64 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M1631.81 1517.37 Q1628.2 1517.37 1626.37 1520.93 Q1624.56 1524.47 1624.56 1531.6 Q1624.56 1538.71 1626.37 1542.27 Q1628.2 1545.82 1631.81 1545.82 Q1635.44 1545.82 1637.25 1542.27 Q1639.08 1538.71 1639.08 1531.6 Q1639.08 1524.47 1637.25 1520.93 Q1635.44 1517.37 1631.81 1517.37 M1631.81 1513.66 Q1637.62 1513.66 1640.67 1518.27 Q1643.75 1522.85 1643.75 1531.6 Q1643.75 1540.33 1640.67 1544.94 Q1637.62 1549.52 1631.81 1549.52 Q1626 1549.52 1622.92 1544.94 Q1619.86 1540.33 1619.86 1531.6 Q1619.86 1522.85 1622.92 1518.27 Q1626 1513.66 1631.81 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2250.81 1544.91 L2258.45 1544.91 L2258.45 1518.55 L2250.14 1520.21 L2250.14 1515.95 L2258.4 1514.29 L2263.08 1514.29 L2263.08 1544.91 L2270.72 1544.91 L2270.72 1548.85 L2250.81 1548.85 L2250.81 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2280.21 1514.29 L2298.56 1514.29 L2298.56 1518.22 L2284.49 1518.22 L2284.49 1526.7 Q2285.51 1526.35 2286.53 1526.19 Q2287.55 1526 2288.56 1526 Q2294.35 1526 2297.73 1529.17 Q2301.11 1532.34 2301.11 1537.76 Q2301.11 1543.34 2297.64 1546.44 Q2294.17 1549.52 2287.85 1549.52 Q2285.67 1549.52 2283.4 1549.15 Q2281.16 1548.78 2278.75 1548.04 L2278.75 1543.34 Q2280.83 1544.47 2283.05 1545.03 Q2285.28 1545.58 2287.75 1545.58 Q2291.76 1545.58 2294.1 1543.48 Q2296.43 1541.37 2296.43 1537.76 Q2296.43 1534.15 2294.1 1532.04 Q2291.76 1529.94 2287.75 1529.94 Q2285.88 1529.94 2284 1530.35 Q2282.15 1530.77 2280.21 1531.65 L2280.21 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M2320.32 1517.37 Q2316.71 1517.37 2314.88 1520.93 Q2313.08 1524.47 2313.08 1531.6 Q2313.08 1538.71 2314.88 1542.27 Q2316.71 1545.82 2320.32 1545.82 Q2323.96 1545.82 2325.76 1542.27 Q2327.59 1538.71 2327.59 1531.6 Q2327.59 1524.47 2325.76 1520.93 Q2323.96 1517.37 2320.32 1517.37 M2320.32 1513.66 Q2326.13 1513.66 2329.19 1518.27 Q2332.27 1522.85 2332.27 1531.6 Q2332.27 1540.33 2329.19 1544.94 Q2326.13 1549.52 2320.32 1549.52 Q2314.51 1549.52 2311.43 1544.94 Q2308.38 1540.33 2308.38 1531.6 Q2308.38 1522.85 2311.43 1518.27 Q2314.51 1513.66 2320.32 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  177.871,1486.45 2352.76,1486.45 \n  \"/>\n<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  177.871,1198.61 2352.76,1198.61 \n  \"/>\n<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  177.871,910.766 2352.76,910.766 \n  \"/>\n<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  177.871,622.926 2352.76,622.926 \n  \"/>\n<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  177.871,335.085 2352.76,335.085 \n  \"/>\n<polyline clip-path=\"url(#clip392)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  177.871,47.2441 2352.76,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  177.871,1486.45 177.871,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  177.871,1486.45 196.769,1486.45 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  177.871,1198.61 196.769,1198.61 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  177.871,910.766 196.769,910.766 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  177.871,622.926 196.769,622.926 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  177.871,335.085 196.769,335.085 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  177.871,47.2441 196.769,47.2441 \n  \"/>\n<path clip-path=\"url(#clip390)\" d=\"M50.9921 1486.9 L80.6679 1486.9 L80.6679 1490.83 L50.9921 1490.83 L50.9921 1486.9 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M94.7882 1499.79 L111.108 1499.79 L111.108 1503.73 L89.1632 1503.73 L89.1632 1499.79 Q91.8252 1497.04 96.4085 1492.41 Q101.015 1487.76 102.196 1486.41 Q104.441 1483.89 105.321 1482.15 Q106.223 1480.39 106.223 1478.7 Q106.223 1475.95 104.279 1474.21 Q102.358 1472.48 99.2558 1472.48 Q97.0567 1472.48 94.603 1473.24 Q92.1725 1474.01 89.3947 1475.56 L89.3947 1470.83 Q92.2188 1469.7 94.6724 1469.12 Q97.1261 1468.54 99.1632 1468.54 Q104.534 1468.54 107.728 1471.23 Q110.922 1473.91 110.922 1478.4 Q110.922 1480.53 110.112 1482.45 Q109.325 1484.35 107.219 1486.95 Q106.64 1487.62 103.538 1490.83 Q100.436 1494.03 94.7882 1499.79 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M120.969 1469.17 L139.325 1469.17 L139.325 1473.1 L125.251 1473.1 L125.251 1481.58 Q126.27 1481.23 127.288 1481.07 Q128.307 1480.88 129.325 1480.88 Q135.112 1480.88 138.492 1484.05 Q141.871 1487.22 141.871 1492.64 Q141.871 1498.22 138.399 1501.32 Q134.927 1504.4 128.607 1504.4 Q126.432 1504.4 124.163 1504.03 Q121.918 1503.66 119.51 1502.92 L119.51 1498.22 Q121.594 1499.35 123.816 1499.91 Q126.038 1500.46 128.515 1500.46 Q132.519 1500.46 134.857 1498.36 Q137.195 1496.25 137.195 1492.64 Q137.195 1489.03 134.857 1486.92 Q132.519 1484.82 128.515 1484.82 Q126.64 1484.82 124.765 1485.23 Q122.913 1485.65 120.969 1486.53 L120.969 1469.17 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M129.927 1184.41 Q126.316 1184.41 124.487 1187.97 Q122.682 1191.51 122.682 1198.64 Q122.682 1205.75 124.487 1209.31 Q126.316 1212.85 129.927 1212.85 Q133.561 1212.85 135.367 1209.31 Q137.195 1205.75 137.195 1198.64 Q137.195 1191.51 135.367 1187.97 Q133.561 1184.41 129.927 1184.41 M129.927 1180.7 Q135.737 1180.7 138.793 1185.31 Q141.871 1189.89 141.871 1198.64 Q141.871 1207.37 138.793 1211.98 Q135.737 1216.56 129.927 1216.56 Q124.117 1216.56 121.038 1211.98 Q117.983 1207.37 117.983 1198.64 Q117.983 1189.89 121.038 1185.31 Q124.117 1180.7 129.927 1180.7 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M94.7882 924.111 L111.108 924.111 L111.108 928.046 L89.1632 928.046 L89.1632 924.111 Q91.8252 921.357 96.4085 916.727 Q101.015 912.074 102.196 910.732 Q104.441 908.209 105.321 906.472 Q106.223 904.713 106.223 903.023 Q106.223 900.269 104.279 898.533 Q102.358 896.797 99.2558 896.797 Q97.0567 896.797 94.603 897.56 Q92.1725 898.324 89.3947 899.875 L89.3947 895.153 Q92.2188 894.019 94.6724 893.44 Q97.1261 892.861 99.1632 892.861 Q104.534 892.861 107.728 895.547 Q110.922 898.232 110.922 902.722 Q110.922 904.852 110.112 906.773 Q109.325 908.671 107.219 911.264 Q106.64 911.935 103.538 915.153 Q100.436 918.347 94.7882 924.111 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M120.969 893.486 L139.325 893.486 L139.325 897.422 L125.251 897.422 L125.251 905.894 Q126.27 905.546 127.288 905.384 Q128.307 905.199 129.325 905.199 Q135.112 905.199 138.492 908.371 Q141.871 911.542 141.871 916.958 Q141.871 922.537 138.399 925.639 Q134.927 928.718 128.607 928.718 Q126.432 928.718 124.163 928.347 Q121.918 927.977 119.51 927.236 L119.51 922.537 Q121.594 923.671 123.816 924.227 Q126.038 924.782 128.515 924.782 Q132.519 924.782 134.857 922.676 Q137.195 920.57 137.195 916.958 Q137.195 913.347 134.857 911.241 Q132.519 909.134 128.515 909.134 Q126.64 909.134 124.765 909.551 Q122.913 909.968 120.969 910.847 L120.969 893.486 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M89.8114 605.646 L108.168 605.646 L108.168 609.581 L94.0937 609.581 L94.0937 618.053 Q95.1123 617.706 96.1308 617.544 Q97.1493 617.359 98.1678 617.359 Q103.955 617.359 107.334 620.53 Q110.714 623.701 110.714 629.118 Q110.714 634.696 107.242 637.798 Q103.77 640.877 97.4502 640.877 Q95.2743 640.877 93.0058 640.507 Q90.7604 640.136 88.353 639.395 L88.353 634.696 Q90.4364 635.831 92.6586 636.386 Q94.8808 636.942 97.3576 636.942 Q101.362 636.942 103.7 634.835 Q106.038 632.729 106.038 629.118 Q106.038 625.507 103.7 623.4 Q101.362 621.294 97.3576 621.294 Q95.4826 621.294 93.6076 621.71 Q91.7558 622.127 89.8114 623.007 L89.8114 605.646 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M129.927 608.724 Q126.316 608.724 124.487 612.289 Q122.682 615.831 122.682 622.96 Q122.682 630.067 124.487 633.632 Q126.316 637.173 129.927 637.173 Q133.561 637.173 135.367 633.632 Q137.195 630.067 137.195 622.96 Q137.195 615.831 135.367 612.289 Q133.561 608.724 129.927 608.724 M129.927 605.021 Q135.737 605.021 138.793 609.627 Q141.871 614.21 141.871 622.96 Q141.871 631.687 138.793 636.294 Q135.737 640.877 129.927 640.877 Q124.117 640.877 121.038 636.294 Q117.983 631.687 117.983 622.96 Q117.983 614.21 121.038 609.627 Q124.117 605.021 129.927 605.021 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M89.5799 317.805 L111.802 317.805 L111.802 319.796 L99.2558 352.365 L94.3715 352.365 L106.177 321.74 L89.5799 321.74 L89.5799 317.805 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M120.969 317.805 L139.325 317.805 L139.325 321.74 L125.251 321.74 L125.251 330.212 Q126.27 329.865 127.288 329.703 Q128.307 329.518 129.325 329.518 Q135.112 329.518 138.492 332.689 Q141.871 335.86 141.871 341.277 Q141.871 346.856 138.399 349.957 Q134.927 353.036 128.607 353.036 Q126.432 353.036 124.163 352.666 Q121.918 352.295 119.51 351.555 L119.51 346.856 Q121.594 347.99 123.816 348.545 Q126.038 349.101 128.515 349.101 Q132.519 349.101 134.857 346.995 Q137.195 344.888 137.195 341.277 Q137.195 337.666 134.857 335.559 Q132.519 333.453 128.515 333.453 Q126.64 333.453 124.765 333.87 Q122.913 334.286 120.969 335.166 L120.969 317.805 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M60.4134 60.5889 L68.0522 60.5889 L68.0522 34.2233 L59.7421 35.89 L59.7421 31.6308 L68.0059 29.9641 L72.6818 29.9641 L72.6818 60.5889 L80.3207 60.5889 L80.3207 64.5241 L60.4134 64.5241 L60.4134 60.5889 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M99.765 33.0428 Q96.1539 33.0428 94.3252 36.6076 Q92.5197 40.1492 92.5197 47.2788 Q92.5197 54.3853 94.3252 57.9501 Q96.1539 61.4917 99.765 61.4917 Q103.399 61.4917 105.205 57.9501 Q107.033 54.3853 107.033 47.2788 Q107.033 40.1492 105.205 36.6076 Q103.399 33.0428 99.765 33.0428 M99.765 29.3391 Q105.575 29.3391 108.631 33.9456 Q111.709 38.5289 111.709 47.2788 Q111.709 56.0056 108.631 60.6121 Q105.575 65.1954 99.765 65.1954 Q93.9549 65.1954 90.8762 60.6121 Q87.8206 56.0056 87.8206 47.2788 Q87.8206 38.5289 90.8762 33.9456 Q93.9549 29.3391 99.765 29.3391 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M129.927 33.0428 Q126.316 33.0428 124.487 36.6076 Q122.682 40.1492 122.682 47.2788 Q122.682 54.3853 124.487 57.9501 Q126.316 61.4917 129.927 61.4917 Q133.561 61.4917 135.367 57.9501 Q137.195 54.3853 137.195 47.2788 Q137.195 40.1492 135.367 36.6076 Q133.561 33.0428 129.927 33.0428 M129.927 29.3391 Q135.737 29.3391 138.793 33.9456 Q141.871 38.5289 141.871 47.2788 Q141.871 56.0056 138.793 60.6121 Q135.737 65.1954 129.927 65.1954 Q124.117 65.1954 121.038 60.6121 Q117.983 56.0056 117.983 47.2788 Q117.983 38.5289 121.038 33.9456 Q124.117 29.3391 129.927 29.3391 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip392)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  239.425,1453.21 253.195,1376.3 266.965,1277.72 280.736,1249.05 294.506,1197.56 308.276,1184.42 322.047,1132.65 335.817,1095.64 349.587,1116.31 363.358,694.973 \n  377.128,962.607 390.898,618.186 404.668,1082.21 418.439,748.434 432.209,562.615 445.979,805.547 459.75,1013.15 473.52,1028.75 487.29,780.734 501.061,1149.47 \n  514.831,1164.97 528.601,1158.77 542.372,-708.652 556.142,1150.91 569.912,712.66 583.683,917.216 597.453,1142.41 611.223,1169.89 624.994,1134.29 638.764,995.086 \n  652.534,1021.79 666.305,1092.5 680.075,762.798 693.845,848.931 707.616,804.327 721.386,1012.06 735.156,889.949 748.927,899.297 762.697,885.785 776.467,313.933 \n  790.237,382.722 804.008,230.858 817.778,-517.611 831.548,-1614.57 845.319,-6480.6 859.089,-4672.5 872.859,-7974.17 886.63,901.574 900.4,434.381 914.17,1172.39 \n  927.941,1009.37 941.711,880.081 955.481,981.913 969.252,968.362 983.022,973.75 996.792,972.609 1010.56,936.835 1024.33,1162.7 1038.1,1172.78 1051.87,1169.07 \n  1065.64,1113.25 1079.41,938.593 1093.18,1110.74 1106.95,1095.47 1120.73,1023.16 1134.5,827.083 1148.27,921.283 1162.04,898.61 1175.81,955.199 1189.58,750.017 \n  1203.35,1098.58 1217.12,1073.39 1230.89,758.48 1244.66,860.434 1258.43,1087.26 1272.2,833.415 1285.97,780.551 1299.74,824.185 1313.51,809.965 1327.28,775.683 \n  1341.05,832.108 1354.82,944.134 1368.59,843.445 1382.36,893.932 1396.13,689.462 1409.9,784.237 1423.67,896.623 1437.44,830.79 1451.21,770.066 1464.98,821.389 \n  1478.75,916.866 1492.52,845.44 1506.29,1000.33 1520.06,872.981 1533.83,819.173 1547.61,1075.63 1561.38,797.187 1575.15,1010.59 1588.92,926.916 1602.69,808 \n  1616.46,829.812 1630.23,856.088 1644,784.066 1657.77,871.325 1671.54,876.929 1685.31,856.108 1699.08,852.255 1712.85,851.273 1726.62,832.07 1740.39,804.876 \n  1754.16,772.364 1767.93,716.172 1781.7,763.533 1795.47,762.3 1809.24,788.834 1823.01,877.3 1836.78,774.06 1850.55,722.444 1864.32,701.29 1878.09,734.525 \n  1891.86,817.738 1905.63,971.731 1919.4,681.816 1933.17,1141.79 1946.94,886.908 1960.71,874.364 1974.49,975.974 1988.26,1004.96 2002.03,842.356 2015.8,946.096 \n  2029.57,850.709 2043.34,1011.46 2057.11,715.937 2070.88,896.023 2084.65,880.347 2098.42,890.772 2112.19,616.09 2125.96,703.162 2139.73,782.811 2153.5,448.367 \n  2167.27,161.125 2181.04,816.495 2194.81,822.908 2208.58,371.052 2222.35,438.631 2236.12,654.629 2249.89,586.624 2263.66,847.356 2277.43,796.614 2291.2,539.121 \n  \n  \"/>\n<path clip-path=\"url(#clip390)\" d=\"\nM250.367 198.898 L520.286 198.898 L520.286 95.2176 L250.367 95.2176  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  250.367,198.898 520.286,198.898 520.286,95.2176 250.367,95.2176 250.367,198.898 \n  \"/>\n<polyline clip-path=\"url(#clip390)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  274.533,147.058 419.525,147.058 \n  \"/>\n<path clip-path=\"url(#clip390)\" d=\"M457.533 166.745 Q455.727 171.375 454.015 172.787 Q452.302 174.199 449.431 174.199 L446.028 174.199 L446.028 170.634 L448.528 170.634 Q450.288 170.634 451.26 169.8 Q452.232 168.967 453.413 165.865 L454.177 163.921 L443.691 138.412 L448.204 138.412 L456.306 158.689 L464.408 138.412 L468.922 138.412 L457.533 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip390)\" d=\"M476.213 160.402 L483.852 160.402 L483.852 134.037 L475.542 135.703 L475.542 131.444 L483.806 129.778 L488.482 129.778 L488.482 160.402 L496.121 160.402 L496.121 164.338 L476.213 164.338 L476.213 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plot the stuff\n",
    "plot(episode_test_reward_hook.rewards)\n",
    "\n",
    "plot(episode_test_reward_hook.rewards, ylim=(-25, 100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "close_visualization(); # closes the MeshCat visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
