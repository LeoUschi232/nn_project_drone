{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649b76a",
   "metadata": {},
   "source": [
    "# Init Bionic VTOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96751412",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e4ee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: MeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "│ http://127.0.0.1:8700\n",
      "└ @ MeshCat /Users/hanna/.julia/packages/MeshCat/Ax8pH/src/visualizer.jl:73\n"
     ]
    }
   ],
   "source": [
    "create_visualization();\n",
    "create_VTOL(\"vtol1\", actuators = true, color_vec=[1.0; 1.0; 0.6; 1.0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28bea61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeshCat Visualizer with path /meshcat/vtol1/elevon_large_right at http://127.0.0.1:8700"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the global wind\n",
    "wind_W = [0.0;0.0;0.0];\n",
    "\n",
    "# Set init state \n",
    "# here it would be better to set the status directly in the status of the environoment so that it does not have to be passed globally.\n",
    "global x_W = [0.0; 0.0; 0.0];\n",
    "global v_B = [0.0; 0.0; 0.0];\n",
    "global R_W = UnitQuaternion(RotY(-pi/2.0)*RotX(pi));\n",
    "global ω_B = [0.0; 0.0; 0.0];\n",
    "\n",
    "# Visualize initial state\n",
    "set_transform(\"vtol1\", x_W,QuatRotation(R_W));\n",
    "set_actuators(\"vtol1\", [0.0; 0.0; 0.0; 0.0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411db62",
   "metadata": {},
   "source": [
    "# Create Reinforcement Learning Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72039adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96af6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv\n",
    "    action_space::A\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}}\n",
    "    state::Vector{T}\n",
    "    action::ACT\n",
    "    done::Bool\n",
    "    t::AbstractFloat\n",
    "    rng::R\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a6873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function VtolEnv(;\n",
    "    T = Float64,\n",
    "    continuous = false,\n",
    "    rng = Random.GLOBAL_RNG,\n",
    "    kwargs...\n",
    ")\n",
    "    action_space = Base.OneTo(21) # 21 discrete positions for the flaps\n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            typemin(T)..typemax(T), # rotation arround y\n",
    "            typemin(T)..typemax(T), # rotation velocity arround y\n",
    "            typemin(T)..typemax(T), # world position along x\n",
    "            ], \n",
    "    )\n",
    "    env = VtolEnv(\n",
    "        action_space,\n",
    "        state_space,\n",
    "        zeros(T, 3), # current state, the other variables could go in here.\n",
    "        rand(action_space),\n",
    "        false, # done\n",
    "        0.0, # time\n",
    "        rng,\n",
    "    )\n",
    "    reset!(env)\n",
    "    env\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f822029",
   "metadata": {},
   "outputs": [],
   "source": [
    "VtolEnv{T}(; kwargs...) where {T} = VtolEnv(T = T, kwargs...)\n",
    "\n",
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a91f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = 3 - abs(env.state[1]-pi*0.5) - abs(env.state[3]*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae45ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    \n",
    "    # Set init state\n",
    "    # The controller still contains an error when it starts in the origin.\n",
    "    global x_W = [0.0; 0.0; 0.0];\n",
    "    global v_B = [0.0; 0.0; 0.0];\n",
    "    global R_W = Matrix(UnitQuaternion(RotY(-pi/2.0)*RotX(pi)));\n",
    "    global ω_B = [0.0; 0.0; 0.0];\n",
    "    global t = 0.0;\n",
    "\n",
    "    # Visualize initial state\n",
    "    set_transform(\"vtol1\", x_W,QuatRotation(R_W));\n",
    "\n",
    "\n",
    "    \n",
    "    env.state = [ω_B[2] ,Rotations.params(RotYXZ(R_W))[1], 0.0]\n",
    "    env.t = 0.0\n",
    "    env.action = 0.0\n",
    "    env.done = false\n",
    "    nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cf1a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (env::VtolEnv{<:Base.OneTo{Int}})(a::Int)\n",
    "    @assert a in env.action_space\n",
    "    env.action = a\n",
    "    _step!(env, ((a-11)/10))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e7d4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "function _step!(env::VtolEnv, a)\n",
    "    \n",
    "    Δt = 1e-3; # This could be integrated into generally passed parameters\n",
    "    \n",
    "    action = [0.75,0.75,a,a] # set the propeller trust fix and adujst the two flaps\n",
    "    \n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(v_B, R_W, wind_W)\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = vtol_model(v_in_wind_B, action, eth_vtol_param);\n",
    "    # integrate rigid body dynamics for Δt\n",
    "    global x_W, v_B, R_W, ω_B, time = rigid_body_simple(torque_B, force_B, x_W, v_B, R_W, ω_B, t, Δt, eth_vtol_param)\n",
    "\n",
    "\n",
    "    # Visualize the new state\n",
    "    set_transform(\"vtol1\", x_W, QuatRotation(R_W));\n",
    "    set_actuators(\"vtol1\", action)\n",
    " \n",
    "    #global t += Δt\n",
    "    env.t += Δt\n",
    "    \n",
    "    # State space\n",
    "    rot = Rotations.params(RotYXZ(R_W))[1]\n",
    "    env.state[1] = rot # rotation arround y\n",
    "    env.state[2] = ω_B[2] # rotation velocity arround y\n",
    "    env.state[3] = x_W[1] # world position along x\n",
    "    \n",
    "    # Termination criteria\n",
    "    env.done =\n",
    "        #norm(v_B) > 2.0 || # stop if body is to fast\n",
    "        x_W[3] < -2.0 || # stop if body is below -2m\n",
    "        0.0 > rot || # Stop if the drone is pitched 90°.\n",
    "        rot > pi || # Stop if the drone is pitched 90°.\n",
    "        env.t > 10 # stop after 10s\n",
    "    nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223a31f",
   "metadata": {},
   "source": [
    "Show an overview of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d1887a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# VtolEnv\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                  Value |\n",
       "|:----------------- | ----------------------:|\n",
       "| NumAgentStyle     |          SingleAgent() |\n",
       "| DynamicStyle      |           Sequential() |\n",
       "| InformationStyle  | ImperfectInformation() |\n",
       "| ChanceStyle       |           Stochastic() |\n",
       "| RewardStyle       |           StepReward() |\n",
       "| UtilityStyle      |           GeneralSum() |\n",
       "| ActionStyle       |     MinimalActionSet() |\n",
       "| StateStyle        |     Observation{Any}() |\n",
       "| DefaultStateStyle |     Observation{Any}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Space{Vector{ClosedInterval{Float64}}}(ClosedInterval{Float64}[-Inf..Inf, -Inf..Inf, -Inf..Inf])`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Base.OneTo(21)`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "[0.0, 1.5707963267948966, 0.0]\n",
       "```\n"
      ],
      "text/plain": [
       "# VtolEnv\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                  Value |\n",
       "|:----------------- | ----------------------:|\n",
       "| NumAgentStyle     |          SingleAgent() |\n",
       "| DynamicStyle      |           Sequential() |\n",
       "| InformationStyle  | ImperfectInformation() |\n",
       "| ChanceStyle       |           Stochastic() |\n",
       "| RewardStyle       |           StepReward() |\n",
       "| UtilityStyle      |           GeneralSum() |\n",
       "| ActionStyle       |     MinimalActionSet() |\n",
       "| StateStyle        |     Observation{Any}() |\n",
       "| DefaultStateStyle |     Observation{Any}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Space{Vector{ClosedInterval{Float64}}}(ClosedInterval{Float64}[-Inf..Inf, -Inf..Inf, -Inf..Inf])`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Base.OneTo(21)`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "[0.0, 1.5707963267948966, 0.0]\n",
       "```\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = VtolEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0e4b5",
   "metadata": {},
   "source": [
    "# Setup of a reinforcement learning experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f01c6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "function RL.Experiment(\n",
    "    ::Val{:JuliaRL},\n",
    "    ::Val{:BasicDQN},\n",
    "    ::Val{:Vtol},\n",
    "    ::Nothing;\n",
    "    seed = 123,\n",
    ")\n",
    "    rng = StableRNG(seed)\n",
    "    env = VtolEnv(; T = Float32, rng = rng)\n",
    "    ns, na = length(state(env)), length(action_space(env))\n",
    "\n",
    "    policy = Agent(\n",
    "        policy = QBasedPolicy(\n",
    "            learner = BasicDQNLearner(\n",
    "                approximator = NeuralNetworkApproximator(\n",
    "                    model = Chain(\n",
    "                        Dense(ns, 128, relu; init = glorot_uniform(rng)),\n",
    "                        Dense(128, 128, relu; init = glorot_uniform(rng)),\n",
    "                        Dense(128, na; init = glorot_uniform(rng)),\n",
    "                    ) |> gpu,\n",
    "                    optimizer = ADAM(),\n",
    "                ),\n",
    "                batch_size = 32,\n",
    "                min_replay_history = 1000,\n",
    "                loss_func = huber_loss,\n",
    "                rng = rng,\n",
    "            ),\n",
    "            explorer = EpsilonGreedyExplorer(\n",
    "                kind = :exp,\n",
    "                ϵ_stable = 0.01,\n",
    "                decay_steps = 500,\n",
    "                rng = rng,\n",
    "            ),\n",
    "        ),\n",
    "        trajectory = CircularArraySARTTrajectory(\n",
    "            capacity = 1000,\n",
    "            state = Vector{Float32} => (ns,),\n",
    "        ),\n",
    "    )\n",
    "    stop_condition = StopAfterStep(600_000, is_show_progress=!haskey(ENV, \"CI\"))\n",
    "    hook = TotalRewardPerEpisode()\n",
    "    Experiment(policy, env, stop_condition, hook, \"# BasicDQN <-> Vtol\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8642c818",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @E_cmd not defined\nin expression starting at In[1]:2",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @E_cmd not defined\nin expression starting at In[1]:2",
      ""
     ]
    }
   ],
   "source": [
    "using Plots\n",
    "ex = E`JuliaRL_BasicDQN_Vtol`\n",
    "run(ex)\n",
    "plot(ex.hook.rewards)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10dd0fe6",
   "metadata": {},
   "source": [
    "close_visualization();"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.4",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
